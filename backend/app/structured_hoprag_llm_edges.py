"""
Structured-HopRAG ç²¾ç®€LLMè¾¹ç”Ÿæˆå™¨
ä»…åœ¨è§„åˆ™è¾¹æ— æ³•è¦†ç›–çš„å¤æ‚æƒ…å†µä¸‹ä½¿ç”¨LLM
"""

import asyncio
import json
import numpy as np
from typing import Dict, List, Any, Set, Optional, Tuple

from .structured_hoprag_config import (
    StructuredHopRAGConfig,
    EdgeType,
    DEFAULT_CONFIG
)
from .structured_hoprag_embedding import MultiLevelNode

class LLMEdgeBuilder:
    """LLMè¾¹æ„å»ºå™¨ï¼ˆç²¾ç®€ç‰ˆï¼‰"""
    
    def __init__(self, llm_client, config: StructuredHopRAGConfig = DEFAULT_CONFIG):
        self.llm_client = llm_client
        self.config = config
        self.llm_call_count = 0
        
    async def build_llm_edges(
        self,
        nodes: Dict[str, MultiLevelNode],
        existing_edges: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        æ„å»ºLLMè¾¹ï¼ˆç²¾ç®€ç‰ˆï¼‰
        
        ç­–ç•¥ï¼š
        1. åªé’ˆå¯¹å¶èŠ‚ç‚¹ï¼ˆbasic_unit, basic_unit_component, enumerationï¼‰
        2. æ£€æŸ¥æ¯å¯¹èŠ‚ç‚¹æ˜¯å¦å·²æœ‰è§„åˆ™è¾¹
        3. å¦‚æœæ— è§„åˆ™è¾¹ä¸”ç›¸ä¼¼åº¦<é˜ˆå€¼ï¼ˆå¤æ‚æƒ…å†µï¼‰ï¼Œç”¨LLMç”Ÿæˆ
        4. æ¯ä¸ªèŠ‚ç‚¹æœ€å¤š1-2æ¡LLMè¾¹
        """
        print("ğŸ¤– å¼€å§‹ç²¾ç®€LLMè¾¹æ„å»º...")
        
        if not self.config.enable_llm_edges:
            print("  âš ï¸ LLMè¾¹å·²ç¦ç”¨")
            return []
        
        # ç­›é€‰ç›®æ ‡èŠ‚ç‚¹ï¼ˆä»…å¶èŠ‚ç‚¹ï¼‰
        target_nodes = [
            n for n in nodes.values()
            if n.level in self.config.llm_edge_levels
        ]
        
        print(f"  ğŸ“‹ ç›®æ ‡èŠ‚ç‚¹: {len(target_nodes)} ä¸ª")
        
        # æ„å»ºç°æœ‰è¾¹çš„ç´¢å¼•
        edge_index = self._build_edge_index(existing_edges)
        
        # æ‰¾å‡ºéœ€è¦LLMå¤„ç†çš„å¤æ‚èŠ‚ç‚¹å¯¹
        complex_pairs = self._find_complex_pairs(
            target_nodes, edge_index, nodes
        )
        
        print(f"  ğŸ” å‘ç°å¤æ‚èŠ‚ç‚¹å¯¹: {len(complex_pairs)} å¯¹")
        
        # ä¸ºå¤æ‚èŠ‚ç‚¹å¯¹ç”ŸæˆLLMè¾¹
        llm_edges = await self._generate_llm_edges_for_pairs(
            complex_pairs, nodes
        )
        
        print(f"  âœ… LLMè¾¹æ„å»ºå®Œæˆ: {len(llm_edges)} æ¡")
        print(f"  ğŸ“Š LLMè°ƒç”¨æ¬¡æ•°: {self.llm_call_count}")
        
        return llm_edges
    
    def _build_edge_index(
        self,
        edges: List[Dict[str, Any]]
    ) -> Set[Tuple[str, str]]:
        """æ„å»ºè¾¹ç´¢å¼•ï¼ˆå¿«é€ŸæŸ¥æ‰¾ï¼‰"""
        index = set()
        
        for edge in edges:
            from_node = edge['from_node']
            to_node = edge['to_node']
            
            # åŒå‘ç´¢å¼•
            index.add((from_node, to_node))
            index.add((to_node, from_node))
        
        return index
    
    def _find_complex_pairs(
        self,
        nodes: List[MultiLevelNode],
        edge_index: Set[Tuple[str, str]],
        all_nodes: Dict[str, MultiLevelNode]
    ) -> List[Tuple[MultiLevelNode, MultiLevelNode]]:
        """
        æ‰¾å‡ºéœ€è¦LLMå¤„ç†çš„å¤æ‚èŠ‚ç‚¹å¯¹
        
        åˆ¤æ–­æ ‡å‡†ï¼š
        1. ä¸¤èŠ‚ç‚¹é—´æ— è§„åˆ™è¾¹
        2. embeddingç›¸ä¼¼åº¦ < é˜ˆå€¼ï¼ˆå¤æ‚æƒ…å†µï¼‰
        3. ä½†å†…å®¹å¯èƒ½å­˜åœ¨é€»è¾‘å…³è”
        """
        complex_pairs = []
        
        for i, node_a in enumerate(nodes):
            # é™åˆ¶æ¯ä¸ªèŠ‚ç‚¹çš„LLMè¾¹æ•°é‡
            llm_edge_count = 0
            
            for node_b in nodes[i+1:]:
                # 1. æ£€æŸ¥æ˜¯å¦å·²æœ‰è¾¹
                if (node_a.node_id, node_b.node_id) in edge_index:
                    continue
                
                # 2. è®¡ç®—ç›¸ä¼¼åº¦
                if node_a.final_embedding is None or node_b.final_embedding is None:
                    continue
                
                similarity = self._cosine_similarity(
                    node_a.final_embedding,
                    node_b.final_embedding
                )
                
                # 3. å¤æ‚åˆ¤æ–­ï¼šç›¸ä¼¼åº¦åœ¨ä¸­ç­‰èŒƒå›´ï¼ˆå¯èƒ½æœ‰éšå«å…³è”ï¼‰
                if self.config.llm_edge_only_complex:
                    # ä»…å¤æ‚æƒ…å†µï¼š0.4 < sim < 0.75
                    if not (0.4 < similarity < self.config.llm_complexity_threshold):
                        continue
                else:
                    # æ‰€æœ‰æƒ…å†µï¼šsim < 0.75
                    if similarity >= self.config.llm_complexity_threshold:
                        continue
                
                # 4. å†…å®¹ç›¸å…³æ€§åˆåˆ¤ï¼ˆé¿å…å®Œå…¨æ— å…³ï¼‰
                if not self._has_potential_relevance(node_a, node_b):
                    continue
                
                complex_pairs.append((node_a, node_b))
                llm_edge_count += 1
                
                # é™åˆ¶æ¯ä¸ªèŠ‚ç‚¹çš„LLMè¾¹æ•°é‡
                if llm_edge_count >= self.config.llm_edge_max_per_node:
                    break
        
        return complex_pairs
    
    def _has_potential_relevance(
        self,
        node_a: MultiLevelNode,
        node_b: MultiLevelNode
    ) -> bool:
        """
        åˆåˆ¤ä¸¤èŠ‚ç‚¹æ˜¯å¦æœ‰æ½œåœ¨å…³è”
        
        ç®€å•æ–¹æ³•ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å…±åŒçš„æ³•å¾‹æœ¯è¯­
        """
        common_terms = [
            'æƒåˆ©', 'ä¹‰åŠ¡', 'è´£ä»»', 'ä¾µæƒ', 'èµ”å¿', 'ç½šåˆ™',
            'ç”³è¯·', 'æ‰¹å‡†', 'æ’¤é”€', 'æ— æ•ˆ', 'å¤„ç½š', 'æ²¡æ”¶'
        ]
        
        content_a = node_a.content.lower()
        content_b = node_b.content.lower()
        
        # è‡³å°‘æœ‰ä¸€ä¸ªå…±åŒæœ¯è¯­
        for term in common_terms:
            if term in content_a and term in content_b:
                return True
        
        return False
    
    async def _generate_llm_edges_for_pairs(
        self,
        pairs: List[Tuple[MultiLevelNode, MultiLevelNode]],
        all_nodes: Dict[str, MultiLevelNode]
    ) -> List[Dict[str, Any]]:
        """ä¸ºå¤æ‚èŠ‚ç‚¹å¯¹ç”ŸæˆLLMè¾¹"""
        llm_edges = []
        
        # æ‰¹é‡å¤„ç†ï¼ˆæ§åˆ¶å¹¶å‘ï¼‰
        batch_size = 5
        for i in range(0, len(pairs), batch_size):
            batch = pairs[i:i+batch_size]
            
            # å¹¶å‘ç”Ÿæˆ
            tasks = [
                self._generate_single_llm_edge(node_a, node_b)
                for node_a, node_b in batch
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # å¤„ç†ç»“æœ
            for result in results:
                if isinstance(result, dict) and result:
                    llm_edges.append(result)
        
        return llm_edges
    
    async def _generate_single_llm_edge(
        self,
        node_a: MultiLevelNode,
        node_b: MultiLevelNode
    ) -> Optional[Dict[str, Any]]:
        """
        ä¸ºå•å¯¹èŠ‚ç‚¹ç”ŸæˆLLMè¾¹
        
        ç”Ÿæˆ1ä¸ªpseudo-queryè¿æ¥ä¸¤ä¸ªèŠ‚ç‚¹
        """
        prompt = self._build_llm_prompt(node_a, node_b)
        
        try:
            response = await self.llm_client.generate_async(prompt)
            self.llm_call_count += 1
            
            # è§£æå“åº”
            edge_data = self._parse_llm_response(response, node_a, node_b)
            
            return edge_data
            
        except Exception as e:
            print(f"  âš ï¸ LLMè¾¹ç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    def _build_llm_prompt(
        self,
        node_a: MultiLevelNode,
        node_b: MultiLevelNode
    ) -> str:
        """æ„å»ºLLM prompt"""
        prompt = f"""ä½ æ˜¯ä¸€ä½æ³•å¾‹ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹ä¸¤ä¸ªæ³•å¾‹æ¡æ–‡æ˜¯å¦å­˜åœ¨é€»è¾‘å…³è”ã€‚

æ¡æ–‡Aï¼š
{node_a.content[:300]}

æ¡æ–‡Bï¼š
{node_b.content[:300]}

ä»»åŠ¡ï¼š
1. åˆ¤æ–­è¿™ä¸¤ä¸ªæ¡æ–‡æ˜¯å¦æœ‰é€»è¾‘å…³è”ï¼ˆå¦‚ï¼šå› æœå…³ç³»ã€äº’è¡¥å…³ç³»ã€ä¾‹å¤–å…³ç³»ã€ç¨‹åºå…³è”ç­‰ï¼‰
2. å¦‚æœæœ‰å…³è”ï¼Œç”Ÿæˆ1ä¸ªç²¾ç‚¼çš„è¿æ¥é—®é¢˜ï¼ˆpseudo-queryï¼‰ï¼Œæè¿°è¿™ç§å…³è”

è¦æ±‚ï¼š
- å¦‚æœæ— æ˜æ˜¾å…³è”ï¼Œè¿”å› {{"relevant": false}}
- å¦‚æœæœ‰å…³è”ï¼Œè¿”å› {{"relevant": true, "query": "è¿æ¥é—®é¢˜", "relation_type": "å…³ç³»ç±»å‹"}}
- é—®é¢˜åº”è¯¥ç²¾ç‚¼ï¼ˆ15-30å­—ï¼‰
- å…³ç³»ç±»å‹å¦‚ï¼šå› æœã€äº’è¡¥ã€ä¾‹å¤–ã€ç¨‹åºã€å¼•ç”³ç­‰

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ã€‚
"""
        return prompt
    
    def _parse_llm_response(
        self,
        response: str,
        node_a: MultiLevelNode,
        node_b: MultiLevelNode
    ) -> Optional[Dict[str, Any]]:
        """è§£æLLMå“åº”"""
        try:
            # æ¸…ç†å“åº”
            response = response.strip()
            if response.startswith('```json'):
                response = response[7:]
            if response.endswith('```'):
                response = response[:-3]
            response = response.strip()
            
            # è§£æJSON
            data = json.loads(response)
            
            # æ£€æŸ¥æ˜¯å¦ç›¸å…³
            if not data.get('relevant', False):
                return None
            
            query = data.get('query', '')
            relation_type = data.get('relation_type', 'unknown')
            
            if not query:
                return None
            
            # æ„å»ºè¾¹
            edge = {
                'from_node': node_a.node_id,
                'to_node': node_b.node_id,
                'edge_type': EdgeType.LLM_GENERATED.value,
                'weight': 0.8,  # LLMè¾¹å›ºå®šæƒé‡
                'directed': False,
                'metadata': {
                    'pseudo_query': query,
                    'relation_type': relation_type,
                    'generated_by': 'llm'
                }
            }
            
            return edge
            
        except Exception as e:
            print(f"  âš ï¸ è§£æLLMå“åº”å¤±è´¥: {e}")
            return None
    
    def _cosine_similarity(self, vec_a: np.ndarray, vec_b: np.ndarray) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        dot_product = np.dot(vec_a, vec_b)
        norm_a = np.linalg.norm(vec_a)
        norm_b = np.linalg.norm(vec_b)
        
        if norm_a == 0 or norm_b == 0:
            return 0.0
        
        return float(dot_product / (norm_a * norm_b))
    
    def get_llm_statistics(self) -> Dict[str, Any]:
        """è·å–LLMä½¿ç”¨ç»Ÿè®¡"""
        return {
            'llm_calls': self.llm_call_count,
            'config': {
                'enabled': self.config.enable_llm_edges,
                'only_complex': self.config.llm_edge_only_complex,
                'max_per_node': self.config.llm_edge_max_per_node,
                'complexity_threshold': self.config.llm_complexity_threshold
            }
        }
