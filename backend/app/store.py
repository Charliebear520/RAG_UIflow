"""
æ•¸æ“šå­˜å„²æ¨¡çµ„
"""

import os
import json
import pickle
from typing import Dict, Optional, List, Any
from .models import DocRecord, EvaluationTask, ECUAnnotation


class InMemoryStore:
    """å…§å­˜æ•¸æ“šå­˜å„²"""
    
    def __init__(self) -> None:
        self.docs: Dict[str, DocRecord] = {}
        self.embeddings = None  # matrix for chunks (numpy array or list)
        self.chunk_doc_ids: List[str] = []
        self.chunks_flat: List[str] = []
        self.evaluation_tasks: Dict[str, EvaluationTask] = {}
        
        # å¤šå±¤æ¬¡embeddingå­˜å„²
        self.multi_level_embeddings: Dict[str, Dict[str, Any]] = {}
        self.multi_level_chunk_doc_ids: Dict[str, List[str]] = {}
        self.multi_level_chunks_flat: Dict[str, List[str]] = {}
        self.multi_level_metadata: Dict[str, Dict[str, Any]] = {}  # å­˜å„²æ¨¡å‹ä¿¡æ¯ç­‰å…ƒæ•¸æ“š
        
        # Enhanced metadataå­˜å„²ï¼ˆåœ¨åˆ†å¡Šéšæ®µç”Ÿæˆï¼‰
        self.enhanced_metadata: Dict[str, Dict[str, Any]] = {}  # chunk_id -> enhanced_metadata
        
        # E/C/Uæ¨™è¨»å­˜å„²
        self.annotations: Dict[str, ECUAnnotation] = {}  # annotation_id -> annotation
        
        # æ¼”ç¤ºè³‡æ–™ç®¡ç†
        self.demo_data_deleted = False  # æ¨™è¨˜æ¼”ç¤ºè³‡æ–™æ˜¯å¦å·²è¢«åˆªé™¤
        
        # æŒä¹…åŒ–è¨­ç½®
        self.data_dir = "data"
        self.ensure_data_dir()
        
        # å•Ÿå‹•æ™‚è‡ªå‹•è¼‰å…¥æ•¸æ“š
        self.load_data()

    def reset_embeddings(self):
        """æ¸…é™¤å‘é‡/ç´¢å¼•ç‹€æ…‹ï¼Œä»¥ä¾¿é‡æ–°è¨ˆç®—åµŒå…¥"""
        self.embeddings = None
        self.chunk_doc_ids = []
        self.chunks_flat = []
        
        # æ¸…é™¤å¤šå±¤æ¬¡embedding
        self.multi_level_embeddings = {}
        self.multi_level_chunk_doc_ids = {}
        self.multi_level_chunks_flat = {}
        self.multi_level_metadata = {}
        
        # æ¸…é™¤enhanced metadata
        self.enhanced_metadata = {}
        
        # æ¸…é™¤æ¨™è¨»æ•¸æ“šï¼ˆå¯é¸ï¼Œæ ¹æ“šéœ€è¦ï¼‰
        # self.annotations = {}

    def add_doc(self, doc_record: DocRecord):
        """æ·»åŠ æ–‡æª”è¨˜éŒ„"""
        self.docs[doc_record.id] = doc_record
        self.reset_embeddings()

    def get_doc(self, doc_id: str) -> Optional[DocRecord]:
        """ç²å–æ–‡æª”è¨˜éŒ„"""
        return self.docs.get(doc_id)

    def list_docs(self) -> List[DocRecord]:
        """åˆ—å‡ºæ‰€æœ‰æ–‡æª”è¨˜éŒ„"""
        return list(self.docs.values())

    def delete_doc(self, doc_id: str) -> bool:
        """åˆªé™¤æ–‡æª”è¨˜éŒ„"""
        if doc_id in self.docs:
            del self.docs[doc_id]
            self.reset_embeddings()
            return True
        return False

    def add_evaluation_task(self, task: EvaluationTask):
        """æ·»åŠ è©•ä¼°ä»»å‹™"""
        self.evaluation_tasks[task.id] = task
    
    def ensure_data_dir(self):
        """ç¢ºä¿æ•¸æ“šç›®éŒ„å­˜åœ¨"""
        if not os.path.exists(self.data_dir):
            os.makedirs(self.data_dir)
            print(f"âœ… å‰µå»ºæ•¸æ“šç›®éŒ„: {self.data_dir}")
    
    def save_data(self):
        """ä¿å­˜æ‰€æœ‰æ•¸æ“šåˆ°æ–‡ä»¶"""
        try:
            # æº–å‚™è¦ä¿å­˜çš„æ•¸æ“š
            data_to_save = {
                "docs": {},
                "embeddings": self.embeddings,
                "chunk_doc_ids": self.chunk_doc_ids,
                "chunks_flat": self.chunks_flat,
                "multi_level_embeddings": self.multi_level_embeddings,
                "multi_level_chunk_doc_ids": self.multi_level_chunk_doc_ids,
                "multi_level_chunks_flat": self.multi_level_chunks_flat,
                "multi_level_metadata": self.multi_level_metadata,
                "enhanced_metadata": self.enhanced_metadata,
                "demo_data_deleted": self.demo_data_deleted
            }
            
            # è½‰æ›DocRecordå°è±¡ç‚ºå¯åºåˆ—åŒ–çš„å­—å…¸
            for doc_id, doc in self.docs.items():
                data_to_save["docs"][doc_id] = {
                    "id": doc.id,
                    "filename": doc.filename,
                    "text": doc.text,
                    "chunks": doc.chunks,
                    "chunk_size": doc.chunk_size,
                    "overlap": doc.overlap,
                    "json_data": doc.json_data,
                    "structured_chunks": doc.structured_chunks,
                    "generated_questions": doc.generated_questions,
                    "multi_level_chunks": doc.multi_level_chunks if hasattr(doc, 'multi_level_chunks') else None,
                    "chunking_strategy": doc.chunking_strategy if hasattr(doc, 'chunking_strategy') else None
                }
            
            # ä¿å­˜åˆ°pickleæ–‡ä»¶
            with open(os.path.join(self.data_dir, "store_data.pkl"), "wb") as f:
                pickle.dump(data_to_save, f)
            
            print(f"âœ… æ•¸æ“šå·²ä¿å­˜åˆ° {self.data_dir}/store_data.pkl")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ•¸æ“šå¤±æ•—: {e}")
    
    def load_data(self):
        """å¾æ–‡ä»¶è¼‰å…¥æ•¸æ“š"""
        try:
            data_file = os.path.join(self.data_dir, "store_data.pkl")
            if not os.path.exists(data_file):
                print(f"ğŸ“ æ•¸æ“šæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨ç©ºæ•¸æ“š: {data_file}")
                return
            
            with open(data_file, "rb") as f:
                data = pickle.load(f)
            
            # æ¢å¾©docs
            self.docs = {}
            for doc_id, doc_data in data.get("docs", {}).items():
                self.docs[doc_id] = DocRecord(
                    id=doc_data["id"],
                    filename=doc_data["filename"],
                    text=doc_data["text"],
                    chunks=doc_data["chunks"],
                    chunk_size=doc_data["chunk_size"],
                    overlap=doc_data["overlap"],
                    json_data=doc_data.get("json_data"),
                    structured_chunks=doc_data.get("structured_chunks"),
                    generated_questions=doc_data.get("generated_questions"),
                    multi_level_chunks=doc_data.get("multi_level_chunks"),
                    chunking_strategy=doc_data.get("chunking_strategy")
                )
            
            # æ¢å¾©å…¶ä»–æ•¸æ“š
            self.embeddings = data.get("embeddings")
            self.chunk_doc_ids = data.get("chunk_doc_ids", [])
            self.chunks_flat = data.get("chunks_flat", [])
            self.multi_level_embeddings = data.get("multi_level_embeddings", {})
            self.multi_level_chunk_doc_ids = data.get("multi_level_chunk_doc_ids", {})
            self.multi_level_chunks_flat = data.get("multi_level_chunks_flat", {})
            self.multi_level_metadata = data.get("multi_level_metadata", {})
            self.enhanced_metadata = data.get("enhanced_metadata", {})
            self.demo_data_deleted = data.get("demo_data_deleted", False)
            
            print(f"âœ… æ•¸æ“šå·²å¾ {data_file} è¼‰å…¥")
            print(f"   ğŸ“„ æ–‡æª”æ•¸é‡: {len(self.docs)}")
            print(f"   ğŸ”¢ æ¨™æº–embedding: {'æœ‰' if self.embeddings is not None else 'ç„¡'}")
            print(f"   ğŸ—ï¸ å¤šå±¤æ¬¡embedding: {len(self.multi_level_embeddings)} å€‹å±¤æ¬¡")
            
        except Exception as e:
            print(f"âŒ è¼‰å…¥æ•¸æ“šå¤±æ•—: {e}")
    
    def clear_all_data(self):
        """æ¸…é™¤æ‰€æœ‰æ•¸æ“šä¸¦ä¿å­˜"""
        self.docs = {}
        self.embeddings = None
        self.chunk_doc_ids = []
        self.chunks_flat = []
        self.multi_level_embeddings = {}
        self.multi_level_chunk_doc_ids = {}
        self.multi_level_chunks_flat = {}
        self.multi_level_metadata = {}
        self.demo_data_deleted = False
        self.save_data()
        print("ğŸ—‘ï¸ æ‰€æœ‰æ•¸æ“šå·²æ¸…é™¤")

    def get_evaluation_task(self, task_id: str) -> Optional[EvaluationTask]:
        """ç²å–è©•ä¼°ä»»å‹™"""
        return self.evaluation_tasks.get(task_id)

    def update_evaluation_task(self, task_id: str, **kwargs):
        """æ›´æ–°è©•ä¼°ä»»å‹™"""
        if task_id in self.evaluation_tasks:
            task = self.evaluation_tasks[task_id]
            for key, value in kwargs.items():
                if hasattr(task, key):
                    setattr(task, key, value)

    def list_evaluation_tasks(self) -> List[EvaluationTask]:
        """åˆ—å‡ºæ‰€æœ‰è©•ä¼°ä»»å‹™"""
        return list(self.evaluation_tasks.values())
    
    def set_multi_level_embeddings(self, level_name: str, embeddings: Any, chunks: List[str], doc_ids: List[str], metadata: Dict[str, Any] = None):
        """è¨­ç½®å¤šå±¤æ¬¡embedding"""
        self.multi_level_embeddings[level_name] = embeddings
        self.multi_level_chunks_flat[level_name] = chunks
        self.multi_level_chunk_doc_ids[level_name] = doc_ids
        if metadata:
            self.multi_level_metadata[level_name] = metadata
    
    def get_multi_level_embeddings(self, level_name: str) -> Optional[Dict[str, Any]]:
        """ç²å–æŒ‡å®šå±¤æ¬¡çš„embedding"""
        if level_name in self.multi_level_embeddings:
            return {
                'embeddings': self.multi_level_embeddings[level_name],
                'chunks': self.multi_level_chunks_flat.get(level_name, []),
                'doc_ids': self.multi_level_chunk_doc_ids.get(level_name, []),
                'metadata': self.multi_level_metadata.get(level_name, {})
            }
        return None
    
    def has_multi_level_embeddings(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„å¤šå±¤æ¬¡embedding"""
        return len(self.multi_level_embeddings) > 0
    
    def get_available_levels(self) -> List[str]:
        """ç²å–å¯ç”¨çš„embeddingå±¤æ¬¡"""
        return list(self.multi_level_embeddings.keys())
    
    # E/C/Uæ¨™è¨»ç®¡ç†æ–¹æ³•
    def save_annotation(self, annotation: ECUAnnotation):
        """ä¿å­˜æ¨™è¨»"""
        self.annotations[annotation.annotation_id] = annotation
    
    def get_annotations_for_query(self, query: str) -> List[ECUAnnotation]:
        """ç²å–ç‰¹å®šæŸ¥è©¢çš„æ‰€æœ‰æ¨™è¨»"""
        return [a for a in self.annotations.values() if a.query == query]
    
    def get_all_annotations(self) -> List[ECUAnnotation]:
        """ç²å–æ‰€æœ‰æ¨™è¨»"""
        return list(self.annotations.values())
    
    def delete_annotations_for_query(self, query: str):
        """åˆªé™¤ç‰¹å®šæŸ¥è©¢çš„æ‰€æœ‰æ¨™è¨»"""
        to_delete = [annotation_id for annotation_id, annotation in self.annotations.items() 
                    if annotation.query == query]
        for annotation_id in to_delete:
            del self.annotations[annotation_id]


# storeå¯¦ä¾‹åœ¨main.pyä¸­å‰µå»ºï¼Œé¿å…é‡è¤‡å®šç¾©
