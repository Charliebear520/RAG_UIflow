"""
Structured-HopRAG å»LLMåŒ–æ£€ç´¢å™¨
åŸºäºé¢„è®¡ç®—æƒé‡ + æ³•å¾‹é€»è¾‘æ¨¡æ¿å¯¼èˆª
"""

import time
import numpy as np
import networkx as nx
from typing import Dict, List, Any, Set, Optional, Tuple
from collections import defaultdict

from .structured_hoprag_config import (
    StructuredHopRAGConfig,
    EdgeType,
    LegalLogicTemplate,
    DEFAULT_CONFIG
)
from .structured_hoprag_embedding import MultiLevelNode

class QueryCache:
    """æŸ¥è¯¢è·¯å¾„ç¼“å­˜"""
    
    def __init__(self, max_size: int = 1000, ttl: int = 3600):
        self.cache: Dict[str, Dict[str, Any]] = {}
        self.max_size = max_size
        self.ttl = ttl
        self.hits = 0
        self.misses = 0
    
    def get(self, query: str) -> Optional[List[str]]:
        """è·å–ç¼“å­˜çš„æŸ¥è¯¢ç»“æœ"""
        if query in self.cache:
            entry = self.cache[query]
            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if time.time() - entry['timestamp'] < self.ttl:
                self.hits += 1
                return entry['results']
            else:
                del self.cache[query]
        
        self.misses += 1
        return None
    
    def set(self, query: str, results: List[str]):
        """è®¾ç½®ç¼“å­˜"""
        # å¦‚æœç¼“å­˜æ»¡äº†ï¼Œåˆ é™¤æœ€æ—§çš„æ¡ç›®
        if len(self.cache) >= self.max_size:
            oldest_key = min(self.cache.keys(), 
                           key=lambda k: self.cache[k]['timestamp'])
            del self.cache[oldest_key]
        
        self.cache[query] = {
            'results': results,
            'timestamp': time.time()
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        total = self.hits + self.misses
        hit_rate = self.hits / total if total > 0 else 0
        
        return {
            'hits': self.hits,
            'misses': self.misses,
            'hit_rate': hit_rate,
            'cache_size': len(self.cache)
        }

class TemplateNavigator:
    """æ³•å¾‹é€»è¾‘æ¨¡æ¿å¯¼èˆªå™¨"""
    
    def __init__(self, config: StructuredHopRAGConfig = DEFAULT_CONFIG):
        self.config = config
        self.templates = config.legal_templates
    
    def match_query_template(self, query: str) -> Optional[LegalLogicTemplate]:
        """åŒ¹é…æŸ¥è¯¢çš„é€»è¾‘æ¨¡æ¿"""
        query_lower = query.lower()
        
        # éå†æ‰€æœ‰æ¨¡æ¿ï¼Œè®¡ç®—åŒ¹é…åˆ†æ•°
        best_template = None
        best_score = 0
        
        for template_name, template in self.templates.items():
            score = 0
            
            # å…³é”®è¯åŒ¹é…
            for keyword in template.keywords:
                if keyword in query_lower:
                    score += 1
            
            if score > best_score:
                best_score = score
                best_template = template
        
        # éœ€è¦è‡³å°‘åŒ¹é…2ä¸ªå…³é”®è¯
        if best_score >= 2:
            return best_template
        
        return None
    
    def get_template_path_nodes(
        self,
        template: LegalLogicTemplate,
        nodes: Dict[str, MultiLevelNode],
        initial_nodes: List[str]
    ) -> List[str]:
        """
        æ ¹æ®æ¨¡æ¿è·å–é€»è¾‘è·¯å¾„èŠ‚ç‚¹
        
        ç­–ç•¥ï¼š
        1. ä»åˆå§‹èŠ‚ç‚¹å¼€å§‹
        2. æŒ‰æ¨¡æ¿stagesé¡ºåºæŸ¥æ‰¾ç›¸å…³ç« èŠ‚
        3. è·³è¿‡æ— å…³èŠ‚ç‚¹
        """
        path_nodes = []
        
        # æŒ‰stagesé¡ºåºæŸ¥æ‰¾
        for stage in template.stages:
            stage_nodes = self._find_nodes_by_stage(stage, nodes)
            path_nodes.extend(stage_nodes)
        
        return path_nodes
    
    def _find_nodes_by_stage(
        self,
        stage: str,
        nodes: Dict[str, MultiLevelNode]
    ) -> List[str]:
        """æ ¹æ®stageæŸ¥æ‰¾èŠ‚ç‚¹"""
        matching_nodes = []
        
        for node_id, node in nodes.items():
            # æ£€æŸ¥èŠ‚ç‚¹å†…å®¹æ˜¯å¦åŒ…å«stageå…³é”®è¯
            if stage in node.content or stage in node.metadata.get('chapter_name', ''):
                matching_nodes.append(node_id)
        
        return matching_nodes[:5]  # é™åˆ¶æ•°é‡

class StructuredHopRAGRetriever:
    """Structured-HopRAGæ£€ç´¢å™¨ï¼ˆå»LLMåŒ–ï¼‰"""
    
    def __init__(
        self,
        graph: nx.DiGraph,
        nodes: Dict[str, MultiLevelNode],
        embedding_model,
        config: StructuredHopRAGConfig = DEFAULT_CONFIG
    ):
        self.graph = graph
        self.nodes = nodes
        self.embedding_model = embedding_model
        self.config = config
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.cache = QueryCache(
            max_size=config.cache_max_size,
            ttl=config.cache_ttl
        ) if config.enable_query_cache else None
        
        self.template_navigator = TemplateNavigator(config) \
            if config.enable_template_navigation else None
    
    async def retrieve(
        self,
        query: str,
        initial_nodes: List[str],
        k: int = 5
    ) -> Dict[int, List[str]]:
        """
        æ‰§è¡Œæ£€ç´¢ï¼ˆå»LLMåŒ–ç‰ˆæœ¬ï¼‰
        
        æµç¨‹ï¼š
        1. æ£€æŸ¥ç¼“å­˜
        2. å°è¯•æ¨¡æ¿å¯¼èˆª
        3. åŸºäºæƒé‡çš„å›¾éå†ï¼ˆæ— LLMæ¨ç†ï¼‰
        4. ç¼“å­˜ç»“æœ
        """
        print(f"ğŸ” Structured-HopRAGæ£€ç´¢: '{query}'")
        start_time = time.time()
        
        # 1. æ£€æŸ¥ç¼“å­˜
        if self.cache:
            cached_results = self.cache.get(query)
            if cached_results:
                print(f"  âš¡ ç¼“å­˜å‘½ä¸­ï¼è€—æ—¶: {time.time() - start_time:.3f}ç§’")
                return {0: cached_results[:k]}
        
        # 2. å°è¯•æ¨¡æ¿å¯¼èˆª
        if self.template_navigator:
            template = self.template_navigator.match_query_template(query)
            if template:
                print(f"  ğŸ“‹ ä½¿ç”¨æ¨¡æ¿: {template.name}")
                template_results = self.template_navigator.get_template_path_nodes(
                    template, self.nodes, initial_nodes
                )
                if template_results:
                    # ä¸åˆå§‹èŠ‚ç‚¹åˆå¹¶
                    combined_results = list(set(initial_nodes + template_results))
                    
                    # ç¼“å­˜ç»“æœ
                    if self.cache:
                        self.cache.set(query, combined_results)
                    
                    print(f"  âœ… æ¨¡æ¿å¯¼èˆªå®Œæˆï¼Œè€—æ—¶: {time.time() - start_time:.3f}ç§’")
                    return {0: combined_results[:k]}
        
        # 3. åŸºäºæƒé‡çš„å›¾éå†
        hop_results = await self._weight_based_traverse(query, initial_nodes)
        
        # 4. ç¼“å­˜ç»“æœ
        all_results = []
        for hop_nodes in hop_results.values():
            all_results.extend(hop_nodes)
        all_results = list(set(all_results))  # å»é‡
        
        if self.cache:
            self.cache.set(query, all_results)
        
        print(f"  âœ… æ£€ç´¢å®Œæˆï¼Œè€—æ—¶: {time.time() - start_time:.3f}ç§’")
        return hop_results
    
    async def _weight_based_traverse(
        self,
        query: str,
        initial_nodes: List[str]
    ) -> Dict[int, List[str]]:
        """
        åŸºäºæƒé‡çš„å›¾éå†ï¼ˆæ— LLMæ¨ç†ï¼‰
        
        ç­–ç•¥ï¼š
        1. è·å–æŸ¥è¯¢embedding
        2. æ¯è·³è·å–é‚»å±…å¹¶æŒ‰ç»¼åˆåˆ†æ•°æ’åº
        3. ç»¼åˆåˆ†æ•° = è¾¹æƒé‡ Ã— è¾¹ä¼˜å…ˆçº§ Ã— æŸ¥è¯¢ç›¸ä¼¼åº¦
        """
        # è·å–æŸ¥è¯¢embedding
        query_embedding = self._get_query_embedding(query)
        
        hop_results = {0: initial_nodes}
        visited = set(initial_nodes)
        current_nodes = initial_nodes
        
        for hop in range(1, self.config.max_hops + 1):
            print(f"  ç¬¬ {hop} è·³...")
            
            candidates = []
            
            # è·å–æ‰€æœ‰å€™é€‰é‚»å±…
            for node_id in current_nodes:
                if node_id not in self.graph:
                    continue
                
                # è·å–é‚»å±…
                for neighbor_id in self.graph.neighbors(node_id):
                    if neighbor_id in visited:
                        continue
                    
                    # è®¡ç®—ç»¼åˆåˆ†æ•°
                    score = self._calculate_neighbor_score(
                        node_id,
                        neighbor_id,
                        query_embedding
                    )
                    
                    candidates.append((neighbor_id, score))
            
            if not candidates:
                print(f"  ç¬¬ {hop} è·³æ— æ–°èŠ‚ç‚¹")
                break
            
            # æŒ‰åˆ†æ•°æ’åº
            candidates.sort(key=lambda x: x[1], reverse=True)
            
            # å–top-k
            next_nodes = [node_id for node_id, _ in candidates[:self.config.top_k_per_hop]]
            
            hop_results[hop] = next_nodes
            visited.update(next_nodes)
            current_nodes = next_nodes
            
            print(f"  ç¬¬ {hop} è·³æ‰¾åˆ° {len(next_nodes)} ä¸ªèŠ‚ç‚¹")
        
        return hop_results
    
    def _calculate_neighbor_score(
        self,
        from_node_id: str,
        to_node_id: str,
        query_embedding: Optional[np.ndarray]
    ) -> float:
        """
        è®¡ç®—é‚»å±…èŠ‚ç‚¹çš„ç»¼åˆåˆ†æ•°
        
        ç»¼åˆåˆ†æ•° = (è¾¹æƒé‡ Ã— è¾¹ä¼˜å…ˆçº§) Ã— w1 + æŸ¥è¯¢ç›¸ä¼¼åº¦ Ã— w2
        """
        # 1. è·å–è¾¹æ•°æ®
        edge_data = self.graph[from_node_id][to_node_id]
        edge_weight = edge_data.get('weight', 0.5)
        edge_type = edge_data.get('edge_type', EdgeType.LLM_GENERATED.value)
        
        # 2. è¾¹ä¼˜å…ˆçº§
        edge_priority = self.config.edge_priority.get_priority(edge_type)
        
        # 3. è¾¹åˆ†æ•°
        edge_score = edge_weight * edge_priority
        
        # 4. æŸ¥è¯¢ç›¸ä¼¼åº¦
        query_sim = 0.0
        if query_embedding is not None and to_node_id in self.nodes:
            to_node = self.nodes[to_node_id]
            if to_node.final_embedding is not None:
                query_sim = self._cosine_similarity(
                    query_embedding,
                    to_node.final_embedding
                )
        
        # 5. ç»¼åˆåˆ†æ•°
        if self.config.traversal_strategy == "priority_weighted":
            score = (edge_score * self.config.edge_weight_in_traversal + 
                    query_sim * self.config.query_similarity_weight)
        else:  # similarity_only
            score = query_sim
        
        return score
    
    def _get_query_embedding(self, query: str) -> Optional[np.ndarray]:
        """è·å–æŸ¥è¯¢embedding"""
        try:
            if hasattr(self.embedding_model, 'encode'):
                return self.embedding_model.encode([query])[0]
            else:
                return None
        except Exception as e:
            print(f"  âš ï¸ æŸ¥è¯¢embeddingå¤±è´¥: {e}")
            return None
    
    def _cosine_similarity(self, vec_a: np.ndarray, vec_b: np.ndarray) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        dot_product = np.dot(vec_a, vec_b)
        norm_a = np.linalg.norm(vec_a)
        norm_b = np.linalg.norm(vec_b)
        
        if norm_a == 0 or norm_b == 0:
            return 0.0
        
        return float(dot_product / (norm_a * norm_b))
    
    def get_retrieval_stats(self) -> Dict[str, Any]:
        """è·å–æ£€ç´¢ç»Ÿè®¡"""
        stats = {
            'config': {
                'max_hops': self.config.max_hops,
                'top_k_per_hop': self.config.top_k_per_hop,
                'enable_template_navigation': self.config.enable_template_navigation,
                'enable_query_cache': self.config.enable_query_cache,
                'llm_reasoning_enabled': self.config.enable_llm_reasoning
            }
        }
        
        if self.cache:
            stats['cache'] = self.cache.get_stats()
        
        return stats
