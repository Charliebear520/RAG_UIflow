"""
APIè·¯ç”±æ¨¡çµ„
"""

import uuid
import json
from datetime import datetime
from typing import List, Dict, Any
import re
from fastapi import APIRouter, UploadFile, File, Form, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

from .models import (
    DocRecord, EvaluationTask, ChunkConfig, EvaluationRequest, 
    GenerateQuestionsRequest
)
from pydantic import BaseModel
from typing import List, Optional, Dict, Any, Tuple
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor
from .store import InMemoryStore
from .pdf_processor import convert_pdf_to_text, convert_pdf_fallback
from .chunking import chunk_text
from .evaluation import evaluate_chunk_config
from .qa_converter import convert_qa_set_with_law_data
# from .question_generator import generate_questions  # ä½¿ç”¨main.pyä¸­çš„å‡½æ•¸

# å‰µå»ºè·¯ç”±å™¨
router = APIRouter()

# ä½¿ç”¨main.pyä¸­çš„storeå¯¦ä¾‹
from .main import store

# ç°¡å–®çš„ä»»å‹™ç‹€æ…‹å­˜å„²
task_status_store = {}

# æ‰¹é‡åˆ†å¡Šä»»å‹™å­˜å„²
chunking_task_store = {}


class EvaluationMetrics(BaseModel):
    precision_omega: float  # PrecisionÎ© - æœ€å¤§æº–ç¢ºç‡
    precision_at_k: Dict[int, float]  # k -> precision score
    recall_at_k: Dict[int, float]  # k -> recall score
    chunk_count: int
    avg_chunk_length: float
    length_variance: float
# === Helper: æ§‹å»ºæ–‡å­—ä¾†æºè‡ª JSONï¼ˆç¢ºä¿ä»¥ç•¶å‰ JSON ç‚ºæº–ï¼‰ ===
def build_text_from_json(json_data: Dict[str, Any]) -> str:
    """å°‡æ³•æ¢ JSON çµæ§‹åºåˆ—åŒ–ç‚ºç·šæ€§æ–‡å­—ï¼Œä¾›éçµæ§‹åŒ–ç­–ç•¥ï¼ˆå¦‚ fixed_sizeï¼‰ä½¿ç”¨ã€‚

    æ³¨æ„ï¼šæ­¤è™•åƒ…ä¸²æ¥å¯è¦‹å…§å®¹æ¬„ä½ï¼Œç¢ºä¿ä½¿ç”¨è€…åœ¨ä¸Šå‚³é é¢åˆªé™¤çš„å…§å®¹ä¸å†å‡ºç¾åœ¨åˆ†å¡Šä¸­ã€‚
    """
    if not json_data or not isinstance(json_data, dict):
        return ""

    parts: list[str] = []
    for law in (json_data.get("laws") or []):
        law_name = law.get("law_name") or ""
        if law_name:
            parts.append(str(law_name))
        for chapter in (law.get("chapters") or []):
            chapter_title = chapter.get("chapter") or ""
            if chapter_title:
                parts.append(str(chapter_title))
            for section in (chapter.get("sections") or []):
                section_title = section.get("section") or ""
                if section_title:
                    parts.append(str(section_title))
                for article in (section.get("articles") or []):
                    # æ¢æ–‡æ¨™é¡Œèˆ‡å…§å®¹
                    article_title = article.get("article") or ""
                    if article_title:
                        parts.append(str(article_title))
                    article_content = article.get("content") or ""
                    if article_content:
                        parts.append(str(article_content))

                    # æ–°éµ paragraphs æˆ–èˆŠéµ items
                    paragraphs = article.get("paragraphs") or []
                    items = article.get("items") or []
                    items_to_process = paragraphs if paragraphs else items
                    for item in items_to_process:
                        item_title = item.get("paragraph") or item.get("item") or ""
                        if item_title:
                            parts.append(str(item_title))
                        item_content = item.get("content") or ""
                        if item_content:
                            parts.append(str(item_content))

                        # æ–°éµ subparagraphs æˆ–èˆŠéµ sub_items
                        subparagraphs = item.get("subparagraphs") or []
                        old_sub_items = item.get("sub_items") or []
                        sub_items_to_process = subparagraphs if subparagraphs else old_sub_items
                        for sub in sub_items_to_process:
                            sub_title = sub.get("subparagraph") or sub.get("sub_item") or ""
                            if sub_title:
                                parts.append(str(sub_title))
                            sub_content = sub.get("content") or ""
                            if sub_content:
                                parts.append(str(sub_content))

                            # ç¬¬ä¸‰å±¤ itemsï¼ˆç›®ï¼‰
                            third_items = sub.get("items") or []
                            for t in third_items:
                                third_title = t.get("item") or ""
                                if third_title:
                                    parts.append(str(third_title))
                                third_content = t.get("content") or ""
                                if third_content:
                                    parts.append(str(third_content))

    # ä½¿ç”¨æ›è¡Œé€£æ¥ï¼Œåˆ©æ–¼ä¹‹å¾Œçš„å›ºå®šå¤§å°/æ»‘å‹•çª—å£ç­‰ç­–ç•¥é‚Šç•Œæ„ŸçŸ¥
    return "\n\n".join([p for p in parts if isinstance(p, str) and p.strip()])


# === Normalization helpers (add minimal keys for evaluation/alignment) ===
def _nfkc(s: str) -> str:
    try:
        import unicodedata
        return unicodedata.normalize('NFKC', s or '')
    except Exception:
        return s or ''


def _to_int_cn_num_local(s: Any) -> int | None:  # type: ignore[valid-type]
    if s is None:
        return None
    t = _nfkc(str(s))
    if t.isdigit():
        try:
            return int(t)
        except Exception:
            return None
    mapping = {'é›¶':0,'ã€‡':0,'ä¸€':1,'äºŒ':2,'å…©':2,'ä¸‰':3,'å››':4,'äº”':5,'å…­':6,'ä¸ƒ':7,'å…«':8,'ä¹':9,'å':10,'ç™¾':100,'åƒ':1000}
    total, section, num = 0, 0, 0
    found = False
    for ch in t:
        if ch in mapping:
            v = mapping[ch]
            if v < 10:
                num = v
                found = True
            else:
                if num == 0:
                    num = 1
                section += num * v
                num = 0
                found = True
    total += section + num
    return total if found else None


def _parse_article_label(label: str) -> tuple[int | None, int | None]:
    t = _nfkc(label)
    m = re.search(r"ç¬¬([0-9ä¸€äºŒå…©ä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒã€‡é›¶]+)æ¢ä¹‹([0-9ä¸€äºŒå…©ä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒã€‡é›¶]+)", t)
    if m:
        return (_to_int_cn_num_local(m.group(1)), _to_int_cn_num_local(m.group(2)))
    m = re.search(r"ç¬¬([0-9ä¸€äºŒå…©ä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒã€‡é›¶]+)-([0-9ä¸€äºŒå…©ä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒã€‡é›¶]+)æ¢", t)
    if m:
        return (_to_int_cn_num_local(m.group(1)), _to_int_cn_num_local(m.group(2)))
    m = re.search(r"ç¬¬([0-9ä¸€äºŒå…©ä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒã€‡é›¶]+)æ¢", t)
    if m:
        return (_to_int_cn_num_local(m.group(1)), None)
    return (None, None)


def normalize_corpus_metadata(corpus: Dict[str, Any]) -> Dict[str, Any]:
    try:
        def _strip_keys(obj: Any, keys: set[str]):  # type: ignore[valid-type]
            if isinstance(obj, dict):
                # å…ˆåˆªé™¤ç›®æ¨™éµ
                for k in list(obj.keys()):
                    if k in keys:
                        del obj[k]
                # éè¿´è™•ç†å­ç¯€é»
                for v in list(obj.values()):
                    _strip_keys(v, keys)
            elif isinstance(obj, list):
                for v in obj:
                    _strip_keys(v, keys)

        def _filter_metadata(md: Dict[str, Any]) -> Dict[str, Any]:
            allowed = {
                'id',
                'category',
                'article_label',
                'article_number',
                'article_suffix',
                'item_number',
                'clause_type',
                'clause_number',
                'clause_sub_number',
            }
            # åˆªé™¤ spans / global_span / page / page_range / note / matched_keywords / confidence / found
            for drop in ['spans', 'global_span', 'page', 'page_range', 'note', 'matched_keywords', 'confidence', 'found']:
                if drop in md:
                    md.pop(drop, None)
            # åƒ…ä¿ç•™å¿…è¦éµ
            return {k: v for k, v in md.items() if k in allowed}

        for law in corpus.get('laws', []) or []:
            law_name = law.get('law_name') or ''
            clean_law = law_name.replace('æ³•è¦åç¨±ï¼š', '')
            # è¦†å¯« law_nameï¼Œå»æ‰å‰ç¶´
            law['law_name'] = clean_law
            # æ§‹å»ºæ–°ç« ç¯€ï¼ˆéæ¿¾æ‰æœªåˆ†é¡ç« /æœªæ¨™ç¤ºæ¢æ–‡ï¼‰
            new_chapters = []
            for chapter in (law.get('chapters', []) or []):
                new_sections = []
                for section in (chapter.get('sections', []) or []):
                    new_articles = []
                    for article in (section.get('articles', []) or []):
                        # åƒ…ä¿ç•™å¿…è¦çš„æ–‡ç« å±¤éµ
                        a_label = article.get('article') or ''
                        a_num, a_suf = _parse_article_label(a_label)
                        md = article.get('metadata') or {}
                        md['category'] = clean_law
                        md['article_label'] = a_label
                        md['article_number'] = a_num
                        md['article_suffix'] = a_suf
                        # æ¸…ç† id å‰ç¶´
                        if 'id' in md and isinstance(md['id'], str):
                            md['id'] = md['id'].replace('æ³•è¦åç¨±ï¼š', '')
                        # éæ¿¾ç‚ºæœ€å° metadata
                        article['metadata'] = _filter_metadata(md)
                        # åˆªé™¤æ–‡ç« å±¤éå¿…è¦éµï¼ˆå¦‚ spans ç­‰ï¼‰ï¼›ä¿ç•™ article/content/items/metadata
                        for drop_key in list(article.keys()):
                            if drop_key not in {'article', 'content', 'items', 'metadata'}:
                                article.pop(drop_key, None)

                        # éæ¿¾æ‰ PDF é¦–é æè¿°é¡çš„å‡æ¢æ–‡ï¼šarticle == 'æœªæ¨™ç¤ºæ¢æ–‡' æˆ– article_number ç‚º None ä¸”å…§å®¹æ˜¯æ³•è¦æè¿°
                        if article.get('article') == 'æœªæ¨™ç¤ºæ¢æ–‡':
                            continue
                        if article['metadata'].get('article_number') is None and 'æ³•è¦åç¨±' in (article.get('content') or ''):
                            # é€²ä¸€æ­¥é˜²å®ˆï¼šè‹¥æ˜¯ç´”æè¿°ä¹Ÿéæ¿¾
                            continue

                        for item in article.get('items', []) or []:
                            # åƒ…ä¿ç•™å¿…è¦çš„é …å±¤éµ
                            md_i = item.get('metadata') or {}
                            md_i['category'] = clean_law
                            md_i['article_label'] = a_label
                            md_i['article_number'] = a_num
                            md_i['article_suffix'] = a_suf
                            md_i['item_number'] = _to_int_cn_num_local(item.get('item'))
                            if 'id' in md_i and isinstance(md_i['id'], str):
                                md_i['id'] = md_i['id'].replace('æ³•è¦åç¨±ï¼š', '')
                            item['metadata'] = _filter_metadata(md_i)
                            # åˆªé™¤é …å±¤éå¿…è¦éµï¼ˆä¿ç•™ item/content/sub_items/metadataï¼‰
                            for drop_key in list(item.keys()):
                                if drop_key not in {'item', 'content', 'sub_items', 'metadata'}:
                                    item.pop(drop_key, None)
                            for sub in item.get('sub_items', []) or []:
                                # åƒ…ä¿ç•™å¿…è¦çš„å­é …å±¤éµ
                                md_s = sub.get('metadata') or {}
                                md_s['category'] = clean_law
                                md_s['article_label'] = a_label
                                md_s['article_number'] = a_num
                                md_s['article_suffix'] = a_suf
                                md_s['clause_type'] = 'ç›®'
                                md_s['clause_number'] = _to_int_cn_num_local(sub.get('sub_item'))
                                md_s['clause_sub_number'] = None
                                if 'id' in md_s and isinstance(md_s['id'], str):
                                    md_s['id'] = md_s['id'].replace('æ³•è¦åç¨±ï¼š', '')
                                sub['metadata'] = _filter_metadata(md_s)
                                # åˆªé™¤å­é …å±¤éå¿…è¦éµï¼ˆä¿ç•™ sub_item/content/metadataï¼‰
                                for drop_key in list(sub.keys()):
                                    if drop_key not in {'sub_item', 'content', 'metadata'}:
                                        sub.pop(drop_key, None)
                        # ä¿ç•™è™•ç†å¾Œçš„æ¢æ–‡
                        new_articles.append(article)

                    # è‹¥è©²ç¯€å­˜åœ¨æœ‰æ•ˆæ¢æ–‡æ‰ä¿ç•™
                    if new_articles:
                        section['articles'] = new_articles
                        new_sections.append(section)
                # è‹¥è©²ç« å­˜åœ¨æœ‰æ•ˆç¯€æ‰ä¿ç•™
                if new_sections:
                    chapter['sections'] = new_sections
                    new_chapters.append(chapter)
            # è¦†å¯«ç« ç¯€
            law['chapters'] = new_chapters
        return corpus
    except Exception:
        return corpus


# === New: Evaluate with qa_gold (no mapping, regex-based relevance) ===
@router.post("/evaluate/gold")
async def evaluate_with_gold(payload: Dict[str, Any]):
    """
    ä»¥ qa_gold èˆ‡ chunking_results è¨ˆç®— P@K / R@K / PrecisionÎ©ï¼ˆç°¡åŒ–ç‰ˆï¼‰
    payload = {
      doc_id: str,
      qa_gold: [ { query, label, gold: { law, article_number, article_suffix, ... } }, ... ],
      chunking_results: [ { strategy, config: { chunk_size, overlap_ratio, ... }, chunks: [text], ... }, ... ],
      k_values: [int]
    }
    """
    try:
        doc_id = payload.get('doc_id')
        qa_gold = payload.get('qa_gold') or []
        chunking_results = payload.get('chunking_results') or []
        k_values = payload.get('k_values') or [1, 3, 5, 10]

        if not isinstance(qa_gold, list) or not isinstance(chunking_results, list):
            return JSONResponse(status_code=400, content={"error": "qa_gold æˆ– chunking_results æ ¼å¼éŒ¯èª¤"})

        # åƒ…å–æ­£ä¾‹ï¼ˆå¤§å°å¯«å¯¬é¬†ï¼‰
        positives = [
            q for q in qa_gold
            if str(q.get('label', '')).strip().lower() == 'yes'
        ]
        if not positives:
            return {"results": [], "summary": {"message": "æ²’æœ‰æ­£ä¾‹å¯ä¾›è©•æ¸¬"}}

        def is_chunk_relevant(chunk_content: str, gold_info: Dict[str, Any]) -> bool:
            """åˆ¤æ–·chunkæ˜¯å¦èˆ‡goldæ¨™æº–ç›¸é—œï¼ˆä½¿ç”¨çµ±ä¸€çš„è©•æ¸¬é‚è¼¯ï¼‰"""
            from .main import is_relevant_chunk
            return is_relevant_chunk(chunk_content, gold_info)

        # é¡¯ç¤ºè©•æ¸¬é…ç½®ä¿¡æ¯
        print(f"ğŸ”§ è©•æ¸¬é…ç½®:")
        print(f"   æ–‡æª”ID: {doc_id}")
        print(f"   QAæ•¸æ“šæ•¸é‡: {len(qa_gold)}")
        print(f"   æ­£ä¾‹æ•¸é‡: {len(positives)}")
        print(f"   åˆ†å¡Šç­–ç•¥æ•¸é‡: {len(chunking_results)}")
        print(f"   Kå€¼: {k_values}")
        
        results = []
        for cr in chunking_results:
            # å…¼å®¹ä¸åŒå­—æ®µå‘½åï¼šchunks / all_chunks / chunks_with_span
            chunks_raw = (
                cr.get('chunks')
                or cr.get('all_chunks')
                or cr.get('chunks_with_span')
                or []
            )
            chunks: list[str] = []
            if isinstance(chunks_raw, list):
                for c in chunks_raw:
                    if isinstance(c, str):
                        chunks.append(c)
                    elif isinstance(c, dict):
                        # å˜—è©¦å¤šå€‹å¸¸è¦‹éµ
                        text = (
                            c.get('content')
                            or c.get('text')
                            or c.get('chunk')
                            or ''
                        )
                        if isinstance(text, str) and text:
                            chunks.append(text)
            # è‹¥ä»ç‚ºç©ºï¼Œä¿åº•ç‚ºç©ºåˆ—è¡¨
            # ä½¿ç”¨èˆ‡å¯¦éš›æª¢ç´¢ç›¸åŒçš„embeddingç­–ç•¥
            print(f"ğŸ”„ é–‹å§‹ç‚ºç­–ç•¥ '{cr.get('strategy')}' é€²è¡Œembedding...")
            
            # æª¢æŸ¥æ˜¯å¦æœ‰ç¾æœ‰çš„embedding
            from .main import store
            current_embeddings = store.embeddings
            current_chunks = store.chunks_flat
            current_doc_ids = store.chunk_doc_ids
            
            # å¦‚æœchunksä¸åŒï¼Œéœ€è¦é‡æ–°è¨ˆç®—embedding
            chunks_changed = (len(chunks) != len(current_chunks) or 
                            any(c1 != c2 for c1, c2 in zip(chunks, current_chunks)))
            
            if chunks_changed:
                print(f"ğŸ“Š Chunkså·²æ”¹è®Šï¼Œé‡æ–°è¨ˆç®—embedding...")
                # è‡¨æ™‚æ›´æ–°storeä¸­çš„chunks
                store.chunks_flat = chunks
                store.chunk_doc_ids = [doc_id] * len(chunks)  # å‡è¨­æ‰€æœ‰chunkséƒ½ä¾†è‡ªåŒä¸€å€‹doc
                
                # é‡æ–°è¨ˆç®—embedding
                try:
                    import asyncio
                    from .main import embed_bge_m3, embed_gemini
                    import os
                    
                    # æ ¹æ“šé…ç½®é¸æ“‡embeddingæ–¹æ³•
                    if os.getenv('USE_BGE_M3_EMBEDDING', 'False').lower() == 'true':
                        print(f"ğŸ”§ ä½¿ç”¨BGE-M3 embedding...")
                        embeddings = embed_bge_m3(chunks)
                    elif os.getenv('USE_GEMINI_EMBEDDING', 'False').lower() == 'true':
                        print(f"ğŸ”§ ä½¿ç”¨Gemini embedding...")
                        embeddings = asyncio.run(embed_gemini(chunks))
                    else:
                        raise Exception("æ²’æœ‰å•Ÿç”¨ä»»ä½•embeddingæ–¹æ³•")
                    
                    import numpy as np
                    embeddings = np.array(embeddings)
                    store.embeddings = embeddings
                    print(f"âœ… Embeddingè¨ˆç®—å®Œæˆï¼Œç¶­åº¦: {embeddings.shape}")
                except Exception as e:
                    print(f"âŒ Embeddingè¨ˆç®—å¤±æ•—: {e}")
                    # å›é€€åˆ°TF-IDF
                    try:
                        vec = TfidfVectorizer()
                        mat = vec.fit_transform(chunks) if chunks else None
                        print(f"âš ï¸  å›é€€åˆ°TF-IDFæª¢ç´¢")
                    except Exception:
                        vec, mat = None, None
                        print(f"âŒ TF-IDFä¹Ÿå¤±æ•—äº†")
            else:
                if current_embeddings is not None:
                    if hasattr(current_embeddings, 'shape'):
                        print(f"âœ… ä½¿ç”¨ç¾æœ‰embeddingï¼Œç¶­åº¦: {current_embeddings.shape}")
                    else:
                        print(f"âœ… ä½¿ç”¨ç¾æœ‰embeddingï¼Œé¡å‹: {type(current_embeddings)}")
                    embeddings = current_embeddings
                else:
                    print(f"âš ï¸  æ²’æœ‰ç¾æœ‰embeddingï¼Œè·³éæ­¤ç­–ç•¥")
                    continue

            # é€é¡Œè¨ˆç®—
            per_k_precisions: Dict[int, list] = {k: [] for k in k_values}
            per_k_recalls: Dict[int, list] = {k: [] for k in k_values}

            for q in positives:
                query = q.get('query', '')
                gold_info = q.get('gold', {}) or {}
                
                # æª¢æŸ¥æ˜¯å¦æœ‰æ³•æ¢è™Ÿç¢¼
                if gold_info.get('article_number') is None:
                    continue  # è·³éæ²’æœ‰æ³•æ¢è™Ÿç¢¼çš„é¡Œç›®
                
                print(f"ğŸ” è©•æ¸¬æŸ¥è©¢: '{query[:50]}...'")
                print(f"ğŸ“‹ Goldæ¨™æº–: {gold_info}")

                # ä½¿ç”¨çµ±ä¸€çš„ç›¸é—œæ€§åˆ¤æ–·é‚è¼¯
                gold_unit_hits = set()
                for idx, text in enumerate(chunks):
                    if not isinstance(text, str):
                        continue
                    if is_chunk_relevant(text, gold_info):
                        gold_unit_hits.add(idx)
                        print(f"   âœ… Chunk {idx+1} ç›¸é—œ: {text[:50]}...")
                
                if not gold_unit_hits:
                    print(f"   âŒ æ²’æœ‰æ‰¾åˆ°ç›¸é—œchunks")
                    continue
                
                print(f"ğŸ“Š æ‰¾åˆ° {len(gold_unit_hits)} å€‹ç›¸é—œchunks: {list(gold_unit_hits)}")

                # ä½¿ç”¨èˆ‡å¯¦éš›æª¢ç´¢ç›¸åŒçš„ç­–ç•¥ï¼ˆHybridRAGæˆ–å¯†é›†å‘é‡ï¼‰
                retrieved_order = []
                
                if 'embeddings' in locals() and embeddings is not None:
                    print(f"ğŸ” ä½¿ç”¨HybridRAGæª¢ç´¢...")
                    try:
                        # ä½¿ç”¨HybridRAGæª¢ç´¢é‚è¼¯
                        from .main import rank_with_dense_vectors, hybrid_rank
                        from .hybrid_search import HybridConfig
                        
                        # æ§‹å»ºnodesæ ¼å¼
                        nodes = []
                        for i, chunk in enumerate(chunks):
                            # å˜—è©¦å¾chunking_resultsä¸­ç²å–metadata
                            metadata = {}
                            if 'chunks_with_span' in cr and i < len(cr['chunks_with_span']):
                                chunk_data = cr['chunks_with_span'][i]
                                if isinstance(chunk_data, dict):
                                    metadata = chunk_data.get('metadata', {})
                            
                            nodes.append({
                                "content": chunk,
                                "metadata": metadata,
                                "doc_id": doc_id,
                                "chunk_index": i
                            })
                        
                        # ä½¿ç”¨å¯†é›†å‘é‡æª¢ç´¢
                        max_k = max(k_values)
                        dense_top_k = min(len(nodes), max_k * 4)
                        all_vec_idxs, all_vec_sims = rank_with_dense_vectors(query, k=len(nodes))
                        
                        # æ˜ å°„å‘é‡åˆ†æ•¸
                        node_vector_scores = [0.0] * len(nodes)
                        for rank_idx, node_idx in enumerate(all_vec_idxs):
                            node_vector_scores[node_idx] = float(all_vec_sims[rank_idx])
                        
                        # å–å‰dense_top_kå€‹å€™é¸
                        top_vec_pairs = sorted(
                            [(i, s) for i, s in enumerate(node_vector_scores)], 
                            key=lambda x: x[1], reverse=True
                        )[:dense_top_k]
                        
                        candidate_nodes = [nodes[i] for i, _ in top_vec_pairs]
                        candidate_scores = [s for _, s in top_vec_pairs]
                        
                        # ä½¿ç”¨HybridRAGæ’åº
                        config = HybridConfig(
                            alpha=0.8,
                            w_law_match=0.15,
                            w_article_match=0.15,
                            w_keyword_hit=0.05,
                            max_bonus=0.4
                        )
                        
                        hybrid_results = hybrid_rank(
                            query, candidate_nodes, k=max_k, config=config, vector_scores=candidate_scores
                        )
                        
                        # æå–æª¢ç´¢é †åº
                        retrieved_order = [result['chunk_index'] for result in hybrid_results]
                        print(f"ğŸ” HybridRAGæª¢ç´¢å®Œæˆï¼Œæª¢ç´¢é †åº: {retrieved_order[:10]}...")
                        
                    except Exception as e:
                        print(f"âš ï¸  HybridRAGæª¢ç´¢å¤±æ•—: {e}ï¼Œå›é€€åˆ°å¯†é›†å‘é‡æª¢ç´¢")
                        try:
                            from .main import rank_with_dense_vectors
                            max_k = max(k_values)
                            idxs, sims = rank_with_dense_vectors(query, k=max_k)
                            retrieved_order = idxs
                            print(f"ğŸ” ä½¿ç”¨å¯†é›†å‘é‡æª¢ç´¢ï¼Œæª¢ç´¢é †åº: {retrieved_order[:10]}...")
                        except Exception as e2:
                            print(f"âš ï¸  å¯†é›†å‘é‡æª¢ç´¢ä¹Ÿå¤±æ•—: {e2}ï¼Œä½¿ç”¨é †åºæª¢ç´¢")
                            retrieved_order = list(range(len(chunks)))
                
                elif 'vec' in locals() and vec is not None and 'mat' in locals() and mat is not None:
                    print(f"ğŸ” ä½¿ç”¨TF-IDFæª¢ç´¢...")
                    try:
                        qv = vec.transform([query])
                        sims = cosine_similarity(qv, mat).flatten()
                        order = sims.argsort()[::-1]
                        retrieved_order = list(order)
                        print(f"ğŸ” TF-IDFæª¢ç´¢å®Œæˆï¼Œæª¢ç´¢é †åº: {retrieved_order[:10]}...")
                    except Exception as e:
                        print(f"âš ï¸  TF-IDFæª¢ç´¢å¤±æ•—: {e}ï¼Œä½¿ç”¨é †åºæª¢ç´¢")
                        retrieved_order = list(range(len(chunks)))
                else:
                    print("âš ï¸  æ²’æœ‰å¯ç”¨çš„æª¢ç´¢æ–¹æ³•ï¼Œä½¿ç”¨é †åºæª¢ç´¢")
                    retrieved_order = list(range(len(chunks)))

                for k in k_values:
                    topk = set(retrieved_order[:k])
                    # P@K: å‘½ä¸­æ¯”ä¾‹
                    prec = (len(topk & gold_unit_hits) / k) if k > 0 else 0.0
                    # R@K: è¦†è“‹æ¯”ä¾‹
                    rec = (len(topk & gold_unit_hits) / len(gold_unit_hits)) if gold_unit_hits else 0.0
                    per_k_precisions[k].append(prec)
                    per_k_recalls[k].append(rec)
                    print(f"   ğŸ“ˆ P@{k}={prec:.3f}, R@{k}={rec:.3f}")

            # æ¢å¾©åŸå§‹storeç‹€æ…‹
            if chunks_changed:
                store.chunks_flat = current_chunks
                store.chunk_doc_ids = current_doc_ids
                store.embeddings = current_embeddings
                print(f"ğŸ”„ å·²æ¢å¾©åŸå§‹storeç‹€æ…‹")

            # åŒ¯ç¸½
            result_entry = {
                "strategy": cr.get('strategy'),
                "config": cr.get('config'),
                "chunk_count": cr.get('chunk_count'),
                "metrics": {
                    "precision_at_k": {k: (sum(v)/len(v) if v else 0.0) for k, v in per_k_precisions.items()},
                    "recall_at_k": {k: (sum(v)/len(v) if v else 0.0) for k, v in per_k_recalls.items()},
                }
            }
            results.append(result_entry)

        # ç°¡å–®æ‘˜è¦ï¼šä»¥ P@5 æ’åº
        best = None
        if results:
            best = max(results, key=lambda r: r["metrics"]["precision_at_k"].get(5, 0))

        return {
            "results": results,
            "summary": {
                "best_by_p_at_5": best
            }
        }
    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})


class EvaluationResult(BaseModel):
    config: Dict[str, Any]  # æ”¹ç‚ºå­—å…¸ä»¥æ”¯æ´å‹•æ…‹åƒæ•¸
    metrics: EvaluationMetrics
    test_queries: List[str]
    retrieval_results: Dict[str, List[Dict]]  # query -> results
    timestamp: datetime


@dataclass
class EvaluationTask:
    id: str
    doc_id: str
    configs: List[ChunkConfig]
    test_queries: List[str]
    k_values: List[int]
    status: str  # "pending", "running", "completed", "failed"
    results: List[EvaluationResult]
    created_at: datetime
    progress: float = 0.0  # æ–°å¢ï¼šé€²åº¦ 0.0 to 1.0
    completed_at: Optional[datetime] = None
    error_message: Optional[str] = None
    strategy: str = "fixed_size"  # æ–°å¢ï¼šåˆ†å‰²ç­–ç•¥


class EvaluationStore:
    def __init__(self) -> None:
        self.tasks: Dict[str, EvaluationTask] = {}
        self.executor = ThreadPoolExecutor(max_workers=2)

    def create_task(self, doc_id: str, configs: List[ChunkConfig], 
                   test_queries: List[str], k_values: List[int], 
                   strategy: str = "fixed_size") -> str:
        task_id = str(uuid.uuid4())
        task = EvaluationTask(
            id=task_id,
            doc_id=doc_id,
            configs=configs,
            test_queries=test_queries,
            k_values=k_values,
            strategy=strategy,
            status="pending",
            results=[],
            created_at=datetime.now()
        )
        self.tasks[task_id] = task
        return task_id

    def get_task(self, task_id: str) -> Optional[EvaluationTask]:
        return self.tasks.get(task_id)

    def update_task_status(self, task_id: str, status: str, 
                          results: Optional[List[EvaluationResult]] = None,
                          error_message: Optional[str] = None,
                          progress: Optional[float] = None):
        if task_id in self.tasks:
            self.tasks[task_id].status = status
            if results is not None:
                self.tasks[task_id].results = results
            if error_message is not None:
                self.tasks[task_id].error_message = error_message
            if progress is not None:
                self.tasks[task_id].progress = progress
            if status == "completed":
                self.tasks[task_id].completed_at = datetime.now()
                self.tasks[task_id].progress = 1.0


class QASetItem(BaseModel):
    query: str
    label: str
    answer: str
    snippets: Optional[List[Dict[str, Any]]] = []
    spans: Optional[List[Dict[str, Any]]] = []
    article_metadata: Optional[Dict[str, Any]] = None
    relevant_chunks: Optional[List[str]] = []  # æ˜ å°„å¾Œçš„chunk IDs


class QASetUploadRequest(BaseModel):
    doc_id: str
    chunk_sizes: List[int] = [300, 500, 800]
    overlap_ratios: List[float] = [0.0, 0.1, 0.2]
    strategy: str = "fixed_size"
    k_values: List[int] = [1, 3, 5, 10]


class ChunkMappingResult(BaseModel):
    task_id: str
    status: str
    qa_set: List[QASetItem]
    chunk_configs: List[Dict[str, Any]]
    mapping_results: Dict[str, Dict[str, List[str]]]  # config_id -> question_id -> chunk_ids


class MultipleChunkingRequest(BaseModel):
    doc_id: str
    strategies: List[str] = ["fixed_size"]
    chunk_sizes: List[int] = [300, 500, 800]
    overlap_ratios: List[float] = [0.0, 0.1, 0.2]


class StrategyEvaluationRequest(BaseModel):
    doc_id: str
    chunking_results: List[Dict[str, Any]]
    qa_mapping_result: Dict[str, Any]
    test_queries: List[str]
    k_values: List[int] = [1, 3, 5, 10]


class FixedSizeEvaluationRequest(BaseModel):
    doc_id: str
    chunk_sizes: List[int] = [300, 500, 800]
    overlap_ratios: List[float] = [0.0, 0.1, 0.2]
    strategy: str = "fixed_size"  # æ–°å¢ï¼šåˆ†å‰²ç­–ç•¥
    test_queries: List[str] = [
        "è‘—ä½œæ¬Šçš„å®šç¾©æ˜¯ä»€éº¼ï¼Ÿ",
        "ä»€éº¼æƒ…æ³ä¸‹å¯ä»¥åˆç†ä½¿ç”¨ä»–äººä½œå“ï¼Ÿ",
        "ä¾µçŠ¯è‘—ä½œæ¬Šçš„æ³•å¾‹å¾Œæœæ˜¯ä»€éº¼ï¼Ÿ",
        "è‘—ä½œæ¬Šçš„ä¿è­·æœŸé™æ˜¯å¤šä¹…ï¼Ÿ",
        "å¦‚ä½•ç”³è«‹è‘—ä½œæ¬Šç™»è¨˜ï¼Ÿ"
    ]
    k_values: List[int] = [1, 3, 5, 10]
    
    # ç­–ç•¥ç‰¹å®šåƒæ•¸é¸é … - é è¨­åŒ…å«æ‰€æœ‰æ’åˆ—çµ„åˆ
    chunk_by_options: List[str] = ["article", "item", "section", "chapter"]  # çµæ§‹åŒ–å±¤æ¬¡åˆ†å‰²é¸é …
    preserve_structure_options: List[bool] = [True, False]  # RCTSå±¤æ¬¡åˆ†å‰²é¸é …
    level_depth_options: List[int] = [2, 3, 4]  # å±¤æ¬¡åˆ†å‰²é¸é …
    similarity_threshold_options: List[float] = [0.5, 0.6, 0.7]  # èªç¾©åˆ†å‰²é¸é …
    semantic_threshold_options: List[float] = [0.6, 0.7, 0.8]  # LLMèªç¾©åˆ†å‰²é¸é …
    switch_threshold_options: List[float] = [0.3, 0.5, 0.7]  # æ··åˆåˆ†å‰²é¸é …
    min_chunk_size_options: List[int] = [100, 200, 300]  # å±¤æ¬¡åˆ†å‰²é¸é …
    context_window_options: List[int] = [50, 100, 150]  # èªç¾©åˆ†å‰²é¸é …
    step_size_options: List[int] = [200, 250, 300]  # æ»‘å‹•è¦–çª—é¸é …
    window_size_options: List[int] = [400, 500, 600, 800]  # æ»‘å‹•è¦–çª—é¸é …
    boundary_aware_options: List[bool] = [True, False]  # æ»‘å‹•è¦–çª—é¸é …
    preserve_sentences_options: List[bool] = [True, False]  # æ»‘å‹•è¦–çª—é¸é …
    min_chunk_size_options_sw: List[int] = [50, 100, 150]  # æ»‘å‹•è¦–çª—å°ˆç”¨é¸é …
    max_chunk_size_options_sw: List[int] = [800, 1000, 1200]  # æ»‘å‹•è¦–çª—å°ˆç”¨é¸é …
    secondary_size_options: List[int] = [300, 400, 500]  # æ··åˆåˆ†å‰²é¸é …


# å‰µå»ºè©•ä¼°å­˜å„²å¯¦ä¾‹
eval_store = EvaluationStore()


def calculate_iou(span1: Tuple[int, int], span2: Tuple[int, int]) -> float:
    """è¨ˆç®—å…©å€‹spançš„IoU (Intersection over Union)"""
    start1, end1 = span1
    start2, end2 = span2
    
    # è¨ˆç®—äº¤é›†
    intersection_start = max(start1, start2)
    intersection_end = min(end1, end2)
    intersection_length = max(0, intersection_end - intersection_start)
    
    # è¨ˆç®—è¯é›†
    union_length = (end1 - start1) + (end2 - start2) - intersection_length
    
    if union_length == 0:
        return 0.0
    
    return intersection_length / union_length


def map_spans_to_chunks(qa_items: List[Dict], chunks_with_span: List[Dict[str, Any]], iou_threshold: float = 0.05, overlap_threshold: float = 0.3) -> List[Dict]:
    """
    å°‡QA setä¸­çš„spansæ˜ å°„åˆ°chunksï¼ˆä½¿ç”¨å¸¶spanä¿¡æ¯çš„chunksï¼‰
    ä½¿ç”¨æ›´æ™ºèƒ½çš„æ˜ å°„ç­–ç•¥ä¾†æé«˜æˆåŠŸç‡åˆ°90%-95%
    
    ä¸»è¦æ”¹é€²ï¼š
    1. é™ä½IoUé–¾å€¼åˆ°0.05ï¼Œå› ç‚ºå°spanèˆ‡å¤§chunkçš„IoUå¤©ç„¶è¼ƒä½
    2. ä½¿ç”¨å¤šç¨®åŒ¹é…ç­–ç•¥ï¼šIoUã€é‡ç–Šç‡ã€åŒ…å«é—œä¿‚ã€é„°è¿‘åŒ¹é…
    3. å°å°spané€²è¡Œç‰¹æ®Šè™•ç†
    
    åƒæ•¸:
    - qa_items: QA seté …ç›®åˆ—è¡¨
    - chunks_with_span: å¸¶spanä¿¡æ¯çš„chunkåˆ—è¡¨ [{"content": str, "span": {"start": int, "end": int}, "chunk_id": str, "metadata": dict}, ...]
    - iou_threshold: IoUé–¾å€¼ï¼Œé»˜èªç‚º0.05ï¼ˆå¤§å¹…é™ä½ï¼‰
    - overlap_threshold: é‡ç–Šé–¾å€¼ï¼Œé»˜èªç‚º0.3ï¼ˆé™ä½ï¼‰
    
    è¿”å›:
    - æ˜ å°„å¾Œçš„QA itemsï¼ŒåŒ…å«relevant_chunkså­—æ®µ
    """
    mapped_qa_items = []
    mapped_count = 0
    positive_qa_count = 0
    
    print(f"é–‹å§‹æ˜ å°„: {len(qa_items)} å€‹QAé …ç›®, {len(chunks_with_span)} å€‹chunks")
    print(f"IoUé–¾å€¼: {iou_threshold}, é‡ç–Šé–¾å€¼: {overlap_threshold}")
    
    for qa_item in qa_items:
        mapped_item = qa_item.copy()
        relevant_chunks = []
        
        # åªè™•ç†Labelç‚º"Yes"çš„QAé …ç›®
        if qa_item.get('label', '').lower() != 'yes':
            mapped_item['relevant_chunks'] = []
            mapped_qa_items.append(mapped_item)
            continue
        
        positive_qa_count += 1
        print(f"è™•ç†æ­£ä¾‹å•é¡Œ {positive_qa_count}: '{qa_item.get('query', '')[:50]}...'")
        
        # è™•ç†snippetså­—æ®µï¼ˆå„ªå…ˆä½¿ç”¨snippetsï¼Œå› ç‚ºå®ƒæ›´æº–ç¢ºï¼‰
        if 'snippets' in qa_item and qa_item['snippets']:
            snippet = qa_item['snippets'][0]  # ä½¿ç”¨ç¬¬ä¸€å€‹snippet
            if 'span' in snippet and len(snippet['span']) == 2:
                qa_span = snippet['span']
                qa_span_length = qa_span[1] - qa_span[0]
                print(f"  QA span: [{qa_span[0]}-{qa_span[1]}] (é•·åº¦: {qa_span_length})")
                print(f"  æª¢æŸ¥ {len(chunks_with_span)} å€‹chunks...")
                
                # ä½¿ç”¨å¤šç¨®åŒ¹é…ç­–ç•¥
                for chunk_info in chunks_with_span:
                    chunk_span = chunk_info['span']
                    chunk_start = chunk_span['start']
                    chunk_end = chunk_span['end']
                    chunk_id = chunk_info['chunk_id']
                    chunk_length = chunk_end - chunk_start
                    
                    # ç­–ç•¥1: è¨ˆç®—IoU
                    iou = calculate_iou(qa_span, (chunk_start, chunk_end))
                    
                    # ç­–ç•¥2: è¨ˆç®—é‡ç–Šç‡ï¼ˆchunkè¦†è“‹qa_spançš„æ¯”ä¾‹ï¼‰
                    overlap_start = max(qa_span[0], chunk_start)
                    overlap_end = min(qa_span[1], chunk_end)
                    if overlap_end > overlap_start:
                        overlap_length = overlap_end - overlap_start
                        overlap_ratio = overlap_length / qa_span_length if qa_span_length > 0 else 0
                    else:
                        overlap_ratio = 0
                    
                    # ç­–ç•¥3: æª¢æŸ¥åŒ…å«é—œä¿‚ï¼ˆchunkå®Œå…¨åŒ…å«qa_spanï¼‰
                    chunk_contains_qa = chunk_start <= qa_span[0] and chunk_end >= qa_span[1]
                    
                    # ç­–ç•¥4: æª¢æŸ¥é„°è¿‘é—œä¿‚ï¼ˆqa_spanåœ¨chunké™„è¿‘ï¼Œè·é›¢å°æ–¼chunké•·åº¦çš„10%ï¼‰
                    if qa_span[0] > chunk_end:
                        distance_to_chunk = qa_span[0] - chunk_end
                    elif qa_span[1] < chunk_start:
                        distance_to_chunk = chunk_start - qa_span[1]
                    else:
                        distance_to_chunk = 0  # æœ‰é‡ç–Š
                    nearby_threshold = chunk_length * 0.1  # chunké•·åº¦çš„10%
                    is_nearby = distance_to_chunk <= nearby_threshold
                    
                    # ç­–ç•¥5: å°æ–¼ç‰¹åˆ¥å°çš„spanï¼ˆ<100å­—ç¬¦ï¼‰ï¼Œä½¿ç”¨æ›´å¯¬é¬†çš„æ¢ä»¶
                    is_small_span = qa_span_length < 100
                    
                    # ç¶œåˆåŒ¹é…æ¢ä»¶ - ä½¿ç”¨æ›´å¯¬é¬†çš„æ¢ä»¶
                    match_found = False
                    match_reason = ""
                    
                    if iou > iou_threshold:
                        match_found = True
                        match_reason = f"IoUåŒ¹é… (IoU: {iou:.3f})"
                    elif chunk_contains_qa:
                        match_found = True
                        match_reason = f"åŒ…å«é—œä¿‚ (IoU: {iou:.3f})"
                    elif overlap_ratio > overlap_threshold:
                        match_found = True
                        match_reason = f"é‡ç–Šç‡åŒ¹é… (é‡ç–Šç‡: {overlap_ratio:.3f}, IoU: {iou:.3f})"
                    elif is_small_span and (overlap_ratio > 0.05 or iou > 0.005):
                        # å°å°spanä½¿ç”¨æ›´å¯¬é¬†çš„æ¢ä»¶
                        match_found = True
                        match_reason = f"å°spanå¯¬é¬†åŒ¹é… (é‡ç–Šç‡: {overlap_ratio:.3f}, IoU: {iou:.3f})"
                    elif is_nearby and iou > 0.005:
                        # é„°è¿‘åŒ¹é…
                        match_found = True
                        match_reason = f"é„°è¿‘åŒ¹é… (è·é›¢: {distance_to_chunk}, IoU: {iou:.3f})"
                    elif is_small_span and is_nearby:
                        # å°spanä¸”é„°è¿‘ï¼Œä½¿ç”¨æœ€å¯¬é¬†çš„æ¢ä»¶
                        match_found = True
                        match_reason = f"å°spané„°è¿‘åŒ¹é… (è·é›¢: {distance_to_chunk}, IoU: {iou:.3f})"
                    
                    if match_found and chunk_id not in relevant_chunks:
                        relevant_chunks.append(chunk_id)
                        print(f"    æ‰¾åˆ°åŒ¹é…chunk: {chunk_id} - {match_reason}")
        
        # å¦‚æœæ²’æœ‰snippetsï¼Œå˜—è©¦ä½¿ç”¨spanså­—æ®µ
        elif 'spans' in qa_item and qa_item['spans']:
            span = qa_item['spans'][0]  # ä½¿ç”¨ç¬¬ä¸€å€‹span
            span_start = span.get('start_char', 0)
            span_end = span.get('end_char', span_start)
            qa_span = (span_start, span_end)
            qa_span_length = qa_span[1] - qa_span[0]
            print(f"  QA span: [{qa_span[0]}-{qa_span[1]}] (é•·åº¦: {qa_span_length})")
            
            # ä½¿ç”¨ç›¸åŒçš„å¤šç¨®åŒ¹é…ç­–ç•¥
            for chunk_info in chunks_with_span:
                chunk_span = chunk_info['span']
                chunk_start = chunk_span['start']
                chunk_end = chunk_span['end']
                chunk_id = chunk_info['chunk_id']
                chunk_length = chunk_end - chunk_start
                
                # è¨ˆç®—å„ç¨®æŒ‡æ¨™
                iou = calculate_iou(qa_span, (chunk_start, chunk_end))
                
                overlap_start = max(qa_span[0], chunk_start)
                overlap_end = min(qa_span[1], chunk_end)
                if overlap_end > overlap_start:
                    overlap_length = overlap_end - overlap_start
                    overlap_ratio = overlap_length / qa_span_length if qa_span_length > 0 else 0
                else:
                    overlap_ratio = 0
                
                chunk_contains_qa = chunk_start <= qa_span[0] and chunk_end >= qa_span[1]
                
                if qa_span[0] > chunk_end:
                    distance_to_chunk = qa_span[0] - chunk_end
                elif qa_span[1] < chunk_start:
                    distance_to_chunk = chunk_start - qa_span[1]
                else:
                    distance_to_chunk = 0  # æœ‰é‡ç–Š
                nearby_threshold = chunk_length * 0.1
                is_nearby = distance_to_chunk <= nearby_threshold
                is_small_span = qa_span_length < 100
                
                # ç¶œåˆåŒ¹é…æ¢ä»¶ - ä½¿ç”¨æ›´å¯¬é¬†çš„æ¢ä»¶
                match_found = False
                match_reason = ""
                
                if iou > iou_threshold:
                    match_found = True
                    match_reason = f"IoUåŒ¹é… (IoU: {iou:.3f})"
                elif chunk_contains_qa:
                    match_found = True
                    match_reason = f"åŒ…å«é—œä¿‚ (IoU: {iou:.3f})"
                elif overlap_ratio > overlap_threshold:
                    match_found = True
                    match_reason = f"é‡ç–Šç‡åŒ¹é… (é‡ç–Šç‡: {overlap_ratio:.3f}, IoU: {iou:.3f})"
                elif is_small_span and (overlap_ratio > 0.05 or iou > 0.005):
                    # å°å°spanä½¿ç”¨æ›´å¯¬é¬†çš„æ¢ä»¶
                    match_found = True
                    match_reason = f"å°spanå¯¬é¬†åŒ¹é… (é‡ç–Šç‡: {overlap_ratio:.3f}, IoU: {iou:.3f})"
                elif is_nearby and iou > 0.005:
                    # é„°è¿‘åŒ¹é…
                    match_found = True
                    match_reason = f"é„°è¿‘åŒ¹é… (è·é›¢: {distance_to_chunk}, IoU: {iou:.3f})"
                elif is_small_span and is_nearby:
                    # å°spanä¸”é„°è¿‘ï¼Œä½¿ç”¨æœ€å¯¬é¬†çš„æ¢ä»¶
                    match_found = True
                    match_reason = f"å°spané„°è¿‘åŒ¹é… (è·é›¢: {distance_to_chunk}, IoU: {iou:.3f})"
                
                if match_found and chunk_id not in relevant_chunks:
                    relevant_chunks.append(chunk_id)
                    print(f"    æ‰¾åˆ°åŒ¹é…chunk: {chunk_id} - {match_reason}")
        
        # çµ±è¨ˆæ˜ å°„æˆåŠŸçš„æ•¸é‡
        if relevant_chunks:
            mapped_count += 1
        else:
            print(f"  è­¦å‘Š: æ­£ä¾‹å•é¡Œæ²’æœ‰æ‰¾åˆ°ç›¸é—œchunksï¼Œå˜—è©¦fallbackç­–ç•¥")
            
            # Fallbackç­–ç•¥ï¼šæ‰¾åˆ°è·é›¢æœ€è¿‘çš„chunk
            min_distance = float('inf')
            closest_chunk_id = None
            
            if 'snippets' in qa_item and qa_item['snippets']:
                snippet = qa_item['snippets'][0]
                if 'span' in snippet and len(snippet['span']) == 2:
                    qa_span = snippet['span']
                    
                    for chunk_info in chunks_with_span:
                        chunk_span = chunk_info['span']
                        chunk_start = chunk_span['start']
                        chunk_end = chunk_span['end']
                        chunk_id = chunk_info['chunk_id']
                        
                        # è¨ˆç®—è·é›¢
                        if qa_span[0] > chunk_end:
                            distance = qa_span[0] - chunk_end
                        elif qa_span[1] < chunk_start:
                            distance = chunk_start - qa_span[1]
                        else:
                            distance = 0  # æœ‰é‡ç–Š
                        
                        if distance < min_distance:
                            min_distance = distance
                            closest_chunk_id = chunk_id
            
            # ç­–ç•¥2: å¦‚æœæ²’æœ‰spanä¿¡æ¯æˆ–è·é›¢å¤ªé ï¼Œä½¿ç”¨å…§å®¹åŒ¹é…
            if not closest_chunk_id or min_distance >= 1000:
                print(f"    å˜—è©¦å…§å®¹åŒ¹é…ç­–ç•¥")
                
                query = qa_item.get('query', '')
                answer = qa_item.get('answer', '')
                
                # æå–é—œéµè©
                import re
                keywords = set()
                
                # å¾å•é¡Œå’Œç­”æ¡ˆä¸­æå–æ³•æ¢è™Ÿç¢¼
                article_patterns = [
                    r"ç¬¬(\d+)æ¢",
                    r"ç¬¬(\d+)æ¢ä¹‹(\d+)",
                    r"ç¬¬(\d+)-(\d+)æ¢"
                ]
                
                for pattern in article_patterns:
                    for text in [query, answer]:
                        matches = re.findall(pattern, text)
                        for match in matches:
                            if isinstance(match, tuple):
                                keywords.add(f"ç¬¬{match[0]}æ¢")
                            else:
                                keywords.add(f"ç¬¬{match}æ¢")
                
                # æ·»åŠ å…¶ä»–é—œéµè©
                keywords.update(query.split()[:5])  # å‰5å€‹è©
                keywords.update(answer.split()[:5])  # å‰5å€‹è©
                
                print(f"    æå–çš„é—œéµè©: {list(keywords)[:10]}")
                
                # ä½¿ç”¨TF-IDFé€²è¡Œå…§å®¹åŒ¹é…
                if keywords and chunks_with_span:
                    try:
                        from sklearn.feature_extraction.text import TfidfVectorizer
                        from sklearn.metrics.pairwise import cosine_similarity
                        
                        # æº–å‚™æ–‡æœ¬æ•¸æ“š
                        texts = [query + " " + answer] + [chunk_info['content'] for chunk_info in chunks_with_span]
                        
                        vectorizer = TfidfVectorizer(
                            max_features=1000,
                            stop_words=None,
                            ngram_range=(1, 2)
                        )
                        
                        tfidf_matrix = vectorizer.fit_transform(texts)
                        cosine_similarities = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])
                        
                        # æ‰¾åˆ°ç›¸ä¼¼åº¦è¶…éé–¾å€¼çš„chunks
                        similarity_threshold = 0.1  # é™ä½é–¾å€¼
                        best_similarity = 0
                        best_chunk_id = None
                        
                        for i, similarity in enumerate(cosine_similarities[0]):
                            if similarity > similarity_threshold and similarity > best_similarity:
                                best_similarity = similarity
                                best_chunk_id = chunks_with_span[i]['chunk_id']
                        
                        if best_chunk_id:
                            relevant_chunks.append(best_chunk_id)
                            print(f"    å…§å®¹åŒ¹é…æ‰¾åˆ°chunk: {best_chunk_id} (ç›¸ä¼¼åº¦: {best_similarity:.3f})")
                        
                    except Exception as e:
                        print(f"    TF-IDFåŒ¹é…å¤±æ•—: {e}")
                        
                        # å›é€€åˆ°ç°¡å–®é—œéµè©åŒ¹é…
                        for chunk_info in chunks_with_span:
                            chunk_content = chunk_info['content']
                            chunk_id = chunk_info['chunk_id']
                            
                            # æª¢æŸ¥é—œéµè©åŒ¹é…
                            keyword_matches = sum(1 for keyword in keywords if keyword in chunk_content)
                            
                            if keyword_matches > 0:
                                relevant_chunks.append(chunk_id)
                                print(f"    é—œéµè©åŒ¹é…æ‰¾åˆ°chunk: {chunk_id} (åŒ¹é…æ•¸: {keyword_matches})")
                                break
            
            # ç­–ç•¥3: å¦‚æœé‚„æ˜¯æ²’æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨æœ€è¿‘çš„chunk
            if not relevant_chunks and closest_chunk_id and min_distance < 2000:  # æ”¾å¯¬è·é›¢é™åˆ¶
                relevant_chunks.append(closest_chunk_id)
                print(f"    ä½¿ç”¨æœ€è¿‘chunk: {closest_chunk_id} (è·é›¢: {min_distance})")
            
            # å¦‚æœä»ç„¶æ²’æœ‰æ‰¾åˆ°
            if not relevant_chunks:
                print(f"    è©²å•é¡Œç„¡æ³•æ‰¾åˆ°åˆé©çš„chunk")
                if 'snippets' in qa_item and qa_item['snippets']:
                    print(f"    è©²å•é¡Œæœ‰ {len(qa_item['snippets'])} å€‹snippetsä½†æœªåŒ¹é…åˆ°ä»»ä½•chunk")
                elif 'spans' in qa_item and qa_item['spans']:
                    print(f"    è©²å•é¡Œæœ‰ {len(qa_item['spans'])} å€‹spansä½†æœªåŒ¹é…åˆ°ä»»ä½•chunk")
                else:
                    print(f"    è©²å•é¡Œæ²’æœ‰snippetsæˆ–spansä¿¡æ¯ï¼Œä¸”å…§å®¹åŒ¹é…å¤±æ•—")
        
        mapped_item['relevant_chunks'] = relevant_chunks
        mapped_qa_items.append(mapped_item)
    
    # è¨ˆç®—æ˜ å°„æˆåŠŸç‡
    success_rate = mapped_count / positive_qa_count if positive_qa_count > 0 else 0
    print(f"æ˜ å°„å®Œæˆ: {mapped_count}/{positive_qa_count} å€‹æ­£ä¾‹å•é¡Œæœ‰ç›¸é—œchunks")
    print(f"æ˜ å°„æˆåŠŸç‡: {success_rate*100:.2f}%")
    
    return mapped_qa_items


def map_spans_to_chunks_legacy(qa_items: List[Dict], chunks: List[str], chunk_size: int, overlap: int, strategy: str = "fixed_size") -> List[Dict]:
    """
    å°‡QA setä¸­çš„spansæ˜ å°„åˆ°chunksï¼ˆèˆŠç‰ˆæœ¬ï¼Œå‘å¾Œå…¼å®¹ï¼‰
    
    åƒæ•¸:
    - qa_items: QA seté …ç›®åˆ—è¡¨
    - chunks: åˆ†å¡Šå¾Œçš„æ–‡æœ¬åˆ—è¡¨
    - chunk_size: åˆ†å¡Šå¤§å°
    - overlap: é‡ç–Šå¤§å°
    - strategy: åˆ†å¡Šç­–ç•¥
    
    è¿”å›:
    - æ˜ å°„å¾Œçš„QA itemsï¼ŒåŒ…å«relevant_chunkså­—æ®µ
    """
    # è¨ˆç®—æ¯å€‹chunkçš„å­—ç¬¦ç¯„åœ
    chunk_ranges = []
    current_pos = 0
    
    for i, chunk in enumerate(chunks):
        chunk_start = current_pos
        chunk_end = current_pos + len(chunk)
        chunk_ranges.append((chunk_start, chunk_end, f"chunk_{i+1:03d}"))
        
        # è¨ˆç®—ä¸‹ä¸€å€‹chunkçš„èµ·å§‹ä½ç½®ï¼ˆè€ƒæ…®é‡ç–Šï¼‰
        current_pos = chunk_end - overlap
    
    mapped_qa_items = []
    
    for qa_item in qa_items:
        mapped_item = qa_item.copy()
        relevant_chunks = []
        
        # è™•ç†spanså­—æ®µ
        if 'spans' in qa_item and qa_item['spans']:
            for span in qa_item['spans']:
                span_start = span.get('start_char', 0)
                span_end = span.get('end_char', span_start)
                
                # æ‰¾åˆ°èˆ‡æ­¤spanæœ‰IoU > 0.5çš„chunks
                for chunk_start, chunk_end, chunk_id in chunk_ranges:
                    iou = calculate_iou((span_start, span_end), (chunk_start, chunk_end))
                    if iou > 0.5:
                        if chunk_id not in relevant_chunks:
                            relevant_chunks.append(chunk_id)
        
        # è™•ç†snippetså­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'snippets' in qa_item and qa_item['snippets']:
            for snippet in qa_item['snippets']:
                if 'span' in snippet:
                    span_start, span_end = snippet['span']
                    
                    # æ‰¾åˆ°èˆ‡æ­¤spanæœ‰IoU > 0.5çš„chunks
                    for chunk_start, chunk_end, chunk_id in chunk_ranges:
                        iou = calculate_iou((span_start, span_end), (chunk_start, chunk_end))
                        if iou > 0.5:
                            if chunk_id not in relevant_chunks:
                                relevant_chunks.append(chunk_id)
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°ç›¸é—œchunksï¼Œæª¢æŸ¥æ˜¯å¦ç‚ºè² ä¾‹
        if not relevant_chunks and qa_item.get('label', '').lower() == 'no':
            # è² ä¾‹ä¸éœ€è¦ç›¸é—œchunks
            pass
        elif not relevant_chunks:
            # æ­£ä¾‹ä½†æ²’æœ‰æ‰¾åˆ°ç›¸é—œchunksï¼Œå¯èƒ½éœ€è¦èª¿æ•´IoUé–¾å€¼æˆ–æª¢æŸ¥æ•¸æ“š
            print(f"è­¦å‘Š: å•é¡Œ '{qa_item.get('query', '')[:50]}...' æ²’æœ‰æ‰¾åˆ°ç›¸é—œchunks")
        
        mapped_item['relevant_chunks'] = relevant_chunks
        mapped_qa_items.append(mapped_item)
    
    return mapped_qa_items


def generate_text_from_merged_doc(merged_doc: Dict[str, Any]) -> str:
    """
    å¾åˆä½µçš„æ³•å¾‹æ–‡æª”JSONçµæ§‹ç”Ÿæˆæ–‡æœ¬å…§å®¹
    
    åƒæ•¸:
    - merged_doc: åˆä½µå¾Œçš„æ³•å¾‹æ–‡æª”JSONçµæ§‹
    
    è¿”å›:
    - ç”Ÿæˆçš„æ–‡æœ¬å…§å®¹
    """
    if not merged_doc or "laws" not in merged_doc:
        return ""
    
    text_parts = []
    
    for law in merged_doc["laws"]:
        law_name = law.get("law_name", "æœªå‘½åæ³•è¦")
        text_parts.append(f"=== {law_name} ===\n")
        
        chapters = law.get("chapters", [])
        for chapter in chapters:
            chapter_name = chapter.get("chapter", "")
            if chapter_name:
                text_parts.append(f"\n{chapter_name}\n")
            
            sections = chapter.get("sections", [])
            for section in sections:
                section_name = section.get("section", "")
                if section_name:
                    text_parts.append(f"\n{section_name}\n")
                
                articles = section.get("articles", [])
                for article in articles:
                    article_name = article.get("article", "")
                    article_content = article.get("content", "")
                    
                    if article_name:
                        text_parts.append(f"\n{article_name}")
                        if article_content:
                            text_parts.append(f" {article_content}")
                        text_parts.append("\n")
                    
                    # è™•ç†é …ç›® - æ”¯æ´æ–°çµæ§‹ (paragraphs) å’ŒèˆŠçµæ§‹ (items)
                    paragraphs = article.get("paragraphs", [])
                    items = article.get("items", [])
                    
                    # ä½¿ç”¨ paragraphs å¦‚æœå­˜åœ¨ï¼Œå¦å‰‡ä½¿ç”¨ items
                    items_to_process = paragraphs if paragraphs else items
                    
                    for item in items_to_process:
                        # æ”¯æ´æ–°çµæ§‹çš„éµå
                        item_name = item.get("paragraph", item.get("item", ""))
                        item_content = item.get("content", "")
                        
                        if item_name and item_content:
                            text_parts.append(f"{item_name} {item_content}\n")
                        
                        # è™•ç†å­é …ç›® - æ”¯æ´æ–°çµæ§‹ (subparagraphs) å’ŒèˆŠçµæ§‹ (sub_items)
                        subparagraphs = item.get("subparagraphs", [])
                        sub_items = item.get("sub_items", [])
                        
                        # ä½¿ç”¨ subparagraphs å¦‚æœå­˜åœ¨ï¼Œå¦å‰‡ä½¿ç”¨ sub_items
                        sub_items_to_process = subparagraphs if subparagraphs else sub_items
                        
                        for sub_item in sub_items_to_process:
                            # æ”¯æ´æ–°çµæ§‹çš„éµå
                            sub_item_name = sub_item.get("subparagraph", sub_item.get("sub_item", ""))
                            sub_item_content = sub_item.get("content", "")
                            
                            if sub_item_name and sub_item_content:
                                text_parts.append(f"{sub_item_name} {sub_item_content}\n")
                            
                            # è™•ç†ç¬¬ä¸‰å±¤é …ç›® (items)
                            third_level_items = sub_item.get("items", [])
                            for third_item in third_level_items:
                                third_item_name = third_item.get("item", "")
                                third_item_content = third_item.get("content", "")
                                
                                if third_item_name and third_item_content:
                                    text_parts.append(f"{third_item_name} {third_item_content}\n")
        
        text_parts.append("\n" + "="*50 + "\n")
    
    return "\n".join(text_parts)


def run_evaluation_task(task_id: str):
    """
    åœ¨å¾Œå°é‹è¡Œè©•æ¸¬ä»»å‹™
    """
    task = eval_store.get_task(task_id)
    if not task:
        return
    
    try:
        eval_store.update_task_status(task_id, "running")
        
        doc = store.docs.get(task.doc_id)
        if not doc:
            eval_store.update_task_status(task_id, "failed", error_message="Document not found")
            return
        
        results = []
        total_configs = len(task.configs)
        
        for i, config in enumerate(task.configs):
            # æº–å‚™ç­–ç•¥åƒæ•¸
            strategy_kwargs = {}
            if hasattr(config, 'strategy'):
                strategy = config.strategy
            else:
                strategy = "fixed_size"
            
            # æ ¹æ“šç­–ç•¥æ·»åŠ ç‰¹å®šåƒæ•¸
            if strategy == "sliding_window" and hasattr(config, 'step_size'):
                strategy_kwargs['step_size'] = config.step_size
                if hasattr(config, 'window_size'):
                    strategy_kwargs['window_size'] = config.window_size
                if hasattr(config, 'boundary_aware'):
                    strategy_kwargs['boundary_aware'] = config.boundary_aware
                if hasattr(config, 'preserve_sentences'):
                    strategy_kwargs['preserve_sentences'] = config.preserve_sentences
                if hasattr(config, 'min_chunk_size_sw'):
                    strategy_kwargs['min_chunk_size_sw'] = config.min_chunk_size_sw
                if hasattr(config, 'max_chunk_size_sw'):
                    strategy_kwargs['max_chunk_size_sw'] = config.max_chunk_size_sw
            elif strategy == "hierarchical" and hasattr(config, 'level_depth'):
                strategy_kwargs['level_depth'] = config.level_depth
            elif strategy == "semantic" and hasattr(config, 'similarity_threshold'):
                strategy_kwargs['similarity_threshold'] = config.similarity_threshold
            elif strategy == "structured_hierarchical" and hasattr(config, 'chunk_by'):
                strategy_kwargs['chunk_by'] = config.chunk_by
            
            result = evaluate_chunk_config(
                doc.text, 
                task.test_queries, 
                config.chunk_size, 
                config.overlap_ratio,
                strategy=strategy,
                **strategy_kwargs
            )
            results.append(result)
            
            # æ›´æ–°é€²åº¦
            progress = (i + 1) / total_configs
            eval_store.update_task_status(task_id, "running", progress=progress)
        
        eval_store.update_task_status(task_id, "completed", results=results)
        
    except Exception as e:
        eval_store.update_task_status(task_id, "failed", error_message=str(e))


@router.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥"""
    return {"status": "healthy", "message": "RAG API é‹è¡Œæ­£å¸¸"}


@router.get("/docs")
async def list_documents():
    """åˆ—å‡ºæ‰€æœ‰æ–‡æª”"""
    docs = store.list_docs()
    return {
        "docs": [
            {
                "id": doc.id,
                "filename": doc.filename,
                "text_length": len(doc.text) if doc.text else 0,
                "has_json_data": bool(doc.json_data),
                "chunks_count": len(doc.chunks) if doc.chunks else 0,
                "chunk_size": doc.chunk_size,
                "overlap": doc.overlap,
                "chunking_strategy": getattr(doc, 'chunking_strategy', None),
                "structured_chunks": getattr(doc, 'structured_chunks', None)
            }
            for doc in docs
        ],
        "total": len(docs)
    }


# PDF è½‰æ›è·¯ç”±
@router.post("/upload-json")
async def upload_json(file: UploadFile = File(...)):
    """ä¸Šå‚³JSONæ–‡ä»¶"""
    try:
        # é©—è­‰æ–‡ä»¶æ ¼å¼
        if not file.filename or not file.filename.lower().endswith('.json'):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒJSONæ ¼å¼æ–‡ä»¶")
        
        # è®€å–æ–‡ä»¶å…§å®¹
        file_content = await file.read()
        
        # è§£æJSONå…§å®¹
        try:
            json_data = json.loads(file_content.decode('utf-8'))
        except json.JSONDecodeError as e:
            raise HTTPException(status_code=400, detail=f"JSONæ ¼å¼éŒ¯èª¤: {str(e)}")
        
        # ç”Ÿæˆæ–‡æª”ID
        doc_id = str(uuid.uuid4())
        
        # å¾JSONçµæ§‹ç”Ÿæˆæ–‡æœ¬å…§å®¹
        # å¦‚æœæ˜¯æ³•æ¢JSONæ ¼å¼ï¼ˆåŒ…å«lawså­—æ®µï¼‰ï¼Œä½¿ç”¨å°ˆé–€çš„å‡½æ•¸
        if isinstance(json_data, dict) and "laws" in json_data:
            text_content = generate_text_from_merged_doc(json_data)
        else:
            # å°æ–¼å…¶ä»–JSONæ ¼å¼ï¼Œç›´æ¥è½‰æ›ç‚ºå­—ç¬¦ä¸²
            text_content = json.dumps(json_data, ensure_ascii=False, indent=2)
        
        if not text_content or not text_content.strip():
            raise HTTPException(status_code=400, detail="JSONæ–‡ä»¶ä¸­æ²’æœ‰å¯ç”¨çš„æ–‡æœ¬å…§å®¹")
        
        # å‰µå»ºæ–‡æª”è¨˜éŒ„
        doc_record = DocRecord(
            id=doc_id,
            filename=file.filename,
            text=text_content,
            chunks=[],
            chunk_size=0,
            overlap=0,
            json_data=json_data
        )
        
        # å­˜å„²æ–‡æª”
        store.add_doc(doc_record)
        
        # è¨ˆç®—éŸ¿æ‡‰æ•¸æ“š
        response_data = {
            "doc_id": doc_id,
            "filename": file.filename,
            "text_length": len(text_content),
            "metadata": json_data,  # æ·»åŠ JSONæ•¸æ“šåˆ°éŸ¿æ‡‰ä¸­
            "message": "JSONæ–‡ä»¶ä¸Šå‚³æˆåŠŸ"
        }
        
        # å¦‚æœæ˜¯æ³•æ¢JSONï¼Œæ·»åŠ laws_count
        if isinstance(json_data, dict) and "laws" in json_data:
            response_data["laws_count"] = len(json_data.get("laws", []))
        
        return response_data
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/convert")
async def convert_pdf(
    file: UploadFile = File(...),
    metadata_options: str = Form("{}"),
    background_tasks: BackgroundTasks = None
):
    """è½‰æ›PDFæ–‡æª”"""
    try:
        # ä½¿ç”¨ main.py ä¸­çš„çµæ§‹åŒ–è§£æ
        from .main import convert_pdf_structured, MetadataOptions
        
        # è§£æå…ƒæ•¸æ“šé¸é …
        try:
            metadata_config = json.loads(metadata_options)
            options = MetadataOptions(**metadata_config)
        except:
            options = MetadataOptions()
        
        # é©—è­‰æ–‡ä»¶é¡å‹
        if not file.filename or not file.filename.lower().endswith('.pdf'):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒPDFæ–‡ä»¶æ ¼å¼")
        
        # è®€å–æ–‡ä»¶å…§å®¹
        file_content = await file.read()
        
        # è½‰æ›PDFç‚ºçµæ§‹åŒ–æ ¼å¼
        result = convert_pdf_structured(file_content, file.filename, options)
        
        # æª¢æŸ¥è½‰æ›æ˜¯å¦æˆåŠŸ
        if not result.get("success", False):
            error_msg = result.get("error", "PDFè½‰æ›å¤±æ•—")
            print(f"PDFè½‰æ›å¤±æ•—: {error_msg}")
            raise HTTPException(status_code=400, detail=f"PDFè½‰æ›å¤±æ•—: {error_msg}")
        
        # æª¢æŸ¥æå–çš„æ–‡æœ¬æ˜¯å¦ç‚ºç©º
        extracted_text = result.get("text", "")
        if not extracted_text or not extracted_text.strip():
            error_msg = "PDFè½‰æ›æˆåŠŸä½†æ²’æœ‰æå–åˆ°æ–‡æœ¬å…§å®¹ï¼Œå¯èƒ½æ˜¯æƒæç‰ˆPDFæˆ–æ–‡æœ¬è¢«åŠ å¯†"
            print(f"æ–‡æœ¬æå–ç‚ºç©º: {error_msg}")
            raise HTTPException(status_code=400, detail=error_msg)
        
        print(f"PDFè½‰æ›æˆåŠŸï¼Œæå–æ–‡æœ¬é•·åº¦: {len(extracted_text)} å­—ç¬¦")
        
        # ç”Ÿæˆæ–‡æª”ID
        doc_id = str(uuid.uuid4())
        
        # æ­£è¦åŒ– metadataï¼ˆè£œé½Šè©•æ¸¬æœ€å°å¿…è¦éµï¼Œä¸å—å‰ç«¯å‹¾é¸å½±éŸ¿ï¼‰
        try:
            normalized_metadata = normalize_corpus_metadata(result["metadata"]) if isinstance(result.get("metadata"), dict) else result.get("metadata")
        except Exception:
            normalized_metadata = result.get("metadata")

        # å‰µå»ºæ–‡æª”è¨˜éŒ„
        doc_record = DocRecord(
            id=doc_id,
            filename=file.filename,
            text=extracted_text,
            chunks=[],
            chunk_size=0,
            overlap=0,
            json_data=normalized_metadata
        )
        
        # å­˜å„²æ–‡æª”
        store.add_doc(doc_record)
        
        return {
            "doc_id": doc_id,
            "filename": file.filename,
            "text_length": len(result["text"]),
            "metadata": normalized_metadata,
            "processing_time": result["processing_time"]
        }
        
    except HTTPException:
        # é‡æ–°æ‹‹å‡ºHTTPExceptionï¼Œä¸è¦è½‰æ›ç‚º500éŒ¯èª¤
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# åˆ†å¡Šè·¯ç”±
@router.post("/chunk")
async def chunk_document(request: ChunkConfig):
    """åˆ†å¡Šæ–‡æª”"""
    try:
        # ä½¿ç”¨è«‹æ±‚ä¸­çš„doc_idç²å–æ–‡æª”
        doc = store.get_doc(request.doc_id)
        if not doc:
            raise HTTPException(status_code=404, detail=f"æ–‡æª” {request.doc_id} ä¸å­˜åœ¨")
        
        # æ·»åŠ èª¿è©¦ä¿¡æ¯
        print(f"æ–‡æª”ID: {request.doc_id}")
        print(f"æ–‡æª”æ–‡ä»¶å: {doc.filename}")
        print(f"æ–‡æª”æ–‡æœ¬é•·åº¦: {len(doc.text) if doc.text else 0}")
        print(f"æ–‡æª”æ˜¯å¦æœ‰JSONæ•¸æ“š: {bool(doc.json_data)}")
        
        # æª¢æŸ¥æ–‡æª”æ˜¯å¦æœ‰æ–‡æœ¬å…§å®¹
        if not doc.text or not doc.text.strip():
            # æä¾›æ›´è©³ç´°çš„éŒ¯èª¤ä¿¡æ¯
            error_detail = f"æ–‡æª”æ²’æœ‰æ–‡æœ¬å…§å®¹ï¼Œç„¡æ³•é€²è¡Œåˆ†å¡Šã€‚æ–‡æª”ID: {request.doc_id}, æ–‡ä»¶å: {doc.filename}"
            if doc.json_data:
                error_detail += f", JSONæ•¸æ“šå­˜åœ¨: {bool(doc.json_data)}"
            print(f"åˆ†å¡ŠéŒ¯èª¤: {error_detail}")
            raise HTTPException(status_code=400, detail=error_detail)
        
        # æº–å‚™åˆ†å¡Šåƒæ•¸
        chunk_kwargs = {
            "chunk_size": request.chunk_size if request.strategy == "fixed_size" else request.chunk_size,
            "max_chunk_size": request.chunk_size,
            "overlap_ratio": request.overlap_ratio
        }
        
        # å¦‚æœæ˜¯çµæ§‹åŒ–å±¤æ¬¡åˆ†å‰²ï¼Œæ·»åŠ é¡å¤–åƒæ•¸ä¸¦é©—è­‰ JSON çµæ§‹
        if request.strategy == "structured_hierarchical":
            chunk_kwargs["chunk_by"] = request.chunk_by
            # å¼·åŒ–é©—è­‰ï¼šjson_data å¿…é ˆå­˜åœ¨ä¸”ç‚ºåˆæ³•çµæ§‹ï¼ˆåŒ…å« laws æˆ– chaptersï¼‰
            if not doc.json_data or not isinstance(doc.json_data, dict) or not (
                (doc.json_data.get("laws") or []) or (doc.json_data.get("chapters") or [])
            ):
                return JSONResponse(status_code=400, content={
                    "error": "å¤šå±¤ç´šçµæ§‹åŒ–åˆ†å‰²éœ€è¦åˆæ³•çš„ JSONï¼ˆéœ€åŒ…å« laws é™£åˆ—æˆ– chapters é™£åˆ—ï¼‰ã€‚è«‹æ–¼ä¸Šå‚³é ä¿å­˜æ­£ç¢ºçš„ JSON å¾Œå†è©¦ã€‚"
                })
        
        # è‹¥ç‚ºçµæ§‹åŒ–å±¤æ¬¡åˆ†å‰²ä½†æœªæä¾›å·²ä¿å­˜çš„ JSONï¼Œæ˜ç¢ºæ‹’çµ•ï¼Œé¿å…å›é€€åˆ°ç´”æ–‡å­—å°è‡´å±¤ç´šéºå¤±
        if request.strategy == "structured_hierarchical" and not doc.json_data:
            return JSONResponse(status_code=400, content={
                "error": "è«‹å…ˆæ–¼ä¸Šå‚³é ä¿å­˜çµæ§‹åŒ–JSONï¼ˆupdate-jsonï¼‰ï¼Œå†åŸ·è¡Œå¤šå±¤ç´šçµæ§‹åŒ–åˆ†å‰²ã€‚ç•¶å‰æ–‡æª”æœªæª¢æ¸¬åˆ° json_dataã€‚"
            })

        # ç”Ÿæˆåˆ†å¡Š - ä½¿ç”¨chunk_with_spanä¾†ç²å–çµæ§‹åŒ–ä¿¡æ¯
        from .chunking import chunk_text_with_span

        # ç•¶å­˜åœ¨ json_data æ™‚ï¼Œå°é structured_hierarchical ç­–ç•¥ä¹Ÿæ”¹ç”¨ç”± JSON æ§‹å»ºçš„æ–‡å­—ä¾†æº
        effective_text = doc.text
        if doc.json_data and request.strategy != "structured_hierarchical":
            try:
                effective_text = build_text_from_json(doc.json_data)
            except Exception:
                # ä¿åº•ï¼šè‹¥æ§‹å»ºå¤±æ•—ï¼Œä»å›é€€åˆ° doc.text
                effective_text = doc.text
        
        chunks_with_span = chunk_text_with_span(
            effective_text,
            strategy=request.strategy,
            json_data=doc.json_data,
            **chunk_kwargs
        )
        
        # æå–ç´”æ–‡æœ¬chunks
        chunks = [chunk["content"] for chunk in chunks_with_span]
        
        # æ›´æ–°æ–‡æª”è¨˜éŒ„
        doc.chunks = chunks
        doc.chunk_size = request.chunk_size
        doc.overlap = int(request.chunk_size * request.overlap_ratio)
        doc.structured_chunks = chunks_with_span  # ä¿å­˜çµæ§‹åŒ–åˆ†å¡Šä¿¡æ¯
        doc.chunking_strategy = request.strategy  # ä¿å­˜åˆ†å¡Šç­–ç•¥
        store.add_doc(doc)
        
        # é‡ç½®åµŒå…¥
        store.reset_embeddings()
        
        # è¨ˆç®—chunkçµ±è¨ˆä¿¡æ¯
        chunk_lengths = [len(chunk) for chunk in chunks] if chunks else []
        avg_chunk_length = sum(chunk_lengths) / len(chunk_lengths) if chunk_lengths else 0
        min_length = min(chunk_lengths) if chunk_lengths else 0
        max_length = max(chunk_lengths) if chunk_lengths else 0
        
        # è¨ˆç®—é•·åº¦æ–¹å·®
        if chunk_lengths:
            variance = sum((length - avg_chunk_length) ** 2 for length in chunk_lengths) / len(chunk_lengths)
        else:
            variance = 0
        
        # è¨ˆç®—é‡ç–Šç‡
        overlap_rate = request.overlap_ratio if hasattr(request, 'overlap_ratio') else 0
        
        # æº–å‚™è¿”å›çš„chunksï¼ˆå‰å¹¾å€‹ä½œç‚ºsampleï¼‰
        sample_chunks = chunks[:3] if chunks else []
        
        return {
            "chunks": chunks,
            "num_chunks": len(chunks),
            "chunk_count": len(chunks),
            "strategy": request.strategy,
            "chunk_size": request.chunk_size,
            "overlap_ratio": request.overlap_ratio,
            "chunk_by": request.chunk_by if request.strategy == "structured_hierarchical" else None,
            "avg_chunk_length": avg_chunk_length,
            "chunk_lengths": chunk_lengths,
            # å‰ç«¯æœŸæœ›çš„æ•¸æ“šçµæ§‹
            "metrics": {
                "avg_length": avg_chunk_length,
                "length_variance": variance,
                "overlap_rate": overlap_rate,
                "min_length": min_length,
                "max_length": max_length,
            },
            "sample": sample_chunks,
            "all_chunks": chunks,
            "overlap": int(request.chunk_size * request.overlap_ratio)
        }
        
    except HTTPException:
        # é‡æ–°æ‹‹å‡ºHTTPExceptionï¼Œä¸è¦è½‰æ›ç‚º500éŒ¯èª¤
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# å•é¡Œç”Ÿæˆè·¯ç”±
@router.post("/generate-questions")
async def generate_questions_endpoint(request: GenerateQuestionsRequest):
    """ç”Ÿæˆå•é¡Œ"""
    try:
        # ç²å–æ–‡æª”
        doc = store.get_doc(request.doc_id)
        if not doc:
            raise HTTPException(status_code=404, detail="æ–‡æª”ä¸å­˜åœ¨")
        
        # ç²å–main.pyä¸­çš„å‡½æ•¸
        from .main import generate_questions_with_gemini
        
        questions = generate_questions_with_gemini(
            doc.text,
            request.num_questions,
            request.question_types,
            request.difficulty_levels
        )
        
        # æå–å•é¡Œæ–‡æœ¬ä¸¦å­˜å„²åˆ°æ–‡æª”è¨˜éŒ„ä¸­
        question_texts = [q.question for q in questions]
        doc.generated_questions = question_texts
        store.add_doc(doc)
        
        return {
            "success": True,
            "result": {
                "doc_id": request.doc_id,
                "questions": [
                    {
                        "question": q.question,
                        "references": q.references,
                        "question_type": q.question_type,
                        "difficulty": q.difficulty,
                        "keywords": q.keywords,
                        "estimated_tokens": q.estimated_tokens
                    }
                    for q in questions
                ],
                "total_generated": len(questions)
            }
        }
        
    except HTTPException:
        # é‡æ–°æ‹‹å‡ºHTTPExceptionï¼Œä¸è¦è½‰æ›ç‚º500éŒ¯èª¤
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# å›ºå®šå¤§å°è©•ä¼°è·¯ç”±
@router.post("/evaluate/fixed-size")
async def start_fixed_size_evaluation(req: FixedSizeEvaluationRequest, background_tasks: BackgroundTasks):
    """
    é–‹å§‹å›ºå®šå¤§å°åˆ†å‰²ç­–ç•¥è©•æ¸¬
    """
    doc = store.docs.get(req.doc_id)
    if not doc:
        return JSONResponse(status_code=404, content={"error": "Document not found"})
    
    # æª¢æŸ¥æ˜¯å¦å·²æœ‰ç”Ÿæˆçš„å•é¡Œ
    if not hasattr(doc, 'generated_questions') or not doc.generated_questions:
        return JSONResponse(
            status_code=400, 
            content={"error": "è«‹å…ˆä½¿ç”¨ã€Œç”Ÿæˆå•é¡Œã€åŠŸèƒ½ç‚ºæ–‡æª”ç”Ÿæˆæ¸¬è©¦å•é¡Œï¼Œç„¶å¾Œå†é€²è¡Œè©•æ¸¬"}
        )
    
    # ä½¿ç”¨æ–‡æª”ä¸­å­˜å„²çš„å•é¡Œè€Œä¸æ˜¯é è¨­å•é¡Œ
    req.test_queries = doc.generated_questions
    
    # ç”Ÿæˆæ‰€æœ‰é…ç½®çµ„åˆï¼ŒåŒ…æ‹¬ç­–ç•¥ç‰¹å®šåƒæ•¸
    configs = []
    for chunk_size in req.chunk_sizes:
        for overlap_ratio in req.overlap_ratios:
            overlap = int(chunk_size * overlap_ratio)
            
            # æ ¹æ“šç­–ç•¥ç”Ÿæˆä¸åŒçš„åƒæ•¸çµ„åˆ
            if req.strategy == "structured_hierarchical":
                for chunk_by in req.chunk_by_options:
                    config = ChunkConfig(
                        chunk_size=chunk_size,
                        overlap=overlap,
                        overlap_ratio=overlap_ratio,
                        chunk_by=chunk_by
                    )
                    configs.append(config)
            elif req.strategy == "rcts_hierarchical":
                for preserve_structure in req.preserve_structure_options:
                    config = ChunkConfig(
                        chunk_size=chunk_size,
                        overlap=overlap,
                        overlap_ratio=overlap_ratio,
                        preserve_structure=preserve_structure,
                        chunk_by="article"  # é»˜èªå€¼
                    )
                    configs.append(config)
            elif req.strategy == "hierarchical":
                for level_depth in req.level_depth_options:
                    for min_chunk_size in req.min_chunk_size_options:
                        config = ChunkConfig(
                            chunk_size=chunk_size,
                            overlap=overlap,
                            overlap_ratio=overlap_ratio,
                            level_depth=level_depth,
                            min_chunk_size=min_chunk_size,
                            chunk_by="article"  # é»˜èªå€¼
                        )
                        configs.append(config)
            elif req.strategy == "semantic":
                for similarity_threshold in req.similarity_threshold_options:
                    for context_window in req.context_window_options:
                        config = ChunkConfig(
                            chunk_size=chunk_size,
                            overlap=overlap,
                            overlap_ratio=overlap_ratio,
                            similarity_threshold=similarity_threshold,
                            context_window=context_window,
                            chunk_by="article"  # é»˜èªå€¼
                        )
                        configs.append(config)
            elif req.strategy == "llm_semantic":
                for semantic_threshold in req.semantic_threshold_options:
                    for context_window in req.context_window_options:
                        config = ChunkConfig(
                            chunk_size=chunk_size,
                            overlap=overlap,
                            overlap_ratio=overlap_ratio,
                            semantic_threshold=semantic_threshold,
                            context_window=context_window,
                            chunk_by="article"  # é»˜èªå€¼
                        )
                        configs.append(config)
            elif req.strategy == "sliding_window":
                for window_size in req.window_size_options:
                    for step_size in req.step_size_options:
                        for boundary_aware in req.boundary_aware_options:
                            for preserve_sentences in req.preserve_sentences_options:
                                for min_chunk_size_sw in req.min_chunk_size_options_sw:
                                    for max_chunk_size_sw in req.max_chunk_size_options_sw:
                                        config = ChunkConfig(
                                            chunk_size=window_size,  # ä½¿ç”¨window_sizeä½œç‚ºchunk_size
                                            overlap=overlap,
                                            overlap_ratio=overlap_ratio,
                                            strategy="sliding_window",
                                            step_size=step_size,
                                            window_size=window_size,
                                            boundary_aware=boundary_aware,
                                            preserve_sentences=preserve_sentences,
                                            min_chunk_size_sw=min_chunk_size_sw,
                                            max_chunk_size_sw=max_chunk_size_sw,
                                            chunk_by="article"  # é»˜èªå€¼
                                        )
                                        configs.append(config)
            elif req.strategy == "hybrid":
                for switch_threshold in req.switch_threshold_options:
                    for secondary_size in req.secondary_size_options:
                        config = ChunkConfig(
                            chunk_size=chunk_size,
                            overlap=overlap,
                            overlap_ratio=overlap_ratio,
                            switch_threshold=switch_threshold,
                            secondary_size=secondary_size,
                            chunk_by="article"  # é»˜èªå€¼
                        )
                        configs.append(config)
            else:
                # é»˜èªé…ç½®ï¼ˆfixed_sizeç­‰ï¼‰
                config = ChunkConfig(
                    chunk_size=chunk_size,
                    overlap=overlap,
                    overlap_ratio=overlap_ratio,
                    chunk_by="article"  # é»˜èªå€¼
                )
                configs.append(config)
    
    # ç²å–åˆ†å‰²ç­–ç•¥ï¼ˆå¾è«‹æ±‚ä¸­ç²å–ï¼Œé»˜èªç‚ºfixed_sizeï¼‰
    strategy = getattr(req, 'strategy', 'fixed_size')
    
    # å‰µå»ºè©•æ¸¬ä»»å‹™
    task_id = eval_store.create_task(
        doc_id=req.doc_id,
        configs=configs,
        test_queries=req.test_queries,
        k_values=req.k_values,
        strategy=strategy
    )
    
    # åœ¨å¾Œå°é‹è¡Œè©•æ¸¬
    background_tasks.add_task(run_evaluation_task, task_id)
    
    return {
        "task_id": task_id,
        "status": "started",
        "total_configs": len(configs),
        "message": "è©•æ¸¬ä»»å‹™å·²é–‹å§‹ï¼Œè«‹ä½¿ç”¨task_idæŸ¥è©¢é€²åº¦"
    }


@router.get("/evaluate/status/{task_id}")
async def get_evaluation_status(task_id: str):
    """
    ç²å–è©•æ¸¬ä»»å‹™ç‹€æ…‹
    """
    task = eval_store.get_task(task_id)
    if not task:
        return JSONResponse(status_code=404, content={"error": "Task not found"})
    
    total_configs = len(task.configs)
    completed_configs = int(task.progress * total_configs) if task.progress > 0 else 0
    
    return {
        "task_id": task_id,
        "status": task.status,
        "created_at": task.created_at.isoformat(),
        "completed_at": task.completed_at.isoformat() if task.completed_at else None,
        "error_message": task.error_message,
        "total_configs": total_configs,
        "completed_configs": completed_configs,
        "progress": task.progress  # ä½¿ç”¨ä»»å‹™å°è±¡ä¸­çš„progresså­—æ®µ
    }


@router.get("/evaluate/results/{task_id}")
async def get_evaluation_results(task_id: str):
    """
    ç²å–è©•æ¸¬çµæœ
    """
    task = eval_store.get_task(task_id)
    if not task:
        return JSONResponse(status_code=404, content={"error": "Task not found"})
    
    if task.status != "completed":
        return JSONResponse(status_code=400, content={"error": "Task not completed yet"})
    
    # è½‰æ›çµæœç‚ºå¯åºåˆ—åŒ–çš„æ ¼å¼
    results = []
    for result in task.results:
        result_dict = {
            "config": result.config,  # ç¾åœ¨ config å·²ç¶“æ˜¯å­—å…¸äº†
            "metrics": {
                "precision_omega": result.metrics.precision_omega,
                "precision_at_k": result.metrics.precision_at_k,
                "recall_at_k": result.metrics.recall_at_k,
                "chunk_count": result.metrics.chunk_count,
                "avg_chunk_length": result.metrics.avg_chunk_length,
                "length_variance": result.metrics.length_variance
            },
            "test_queries": result.test_queries,
            "retrieval_results": result.retrieval_results,
            "timestamp": result.timestamp.isoformat()
        }
        results.append(result_dict)
    
    # è¨ˆç®—æ‘˜è¦çµ±è¨ˆï¼Œè™•ç†ç©ºçµæœçš„æƒ…æ³
    summary = {
        "total_configs": len(results),
        "best_precision_omega": 0,
        "best_precision_at_5": 0,
        "best_recall_at_5": 0,
        "avg_chunk_count": 0,
        "avg_chunk_length": 0
    }
    
    if results:
        summary.update({
            "best_precision_omega": max(r["metrics"]["precision_omega"] for r in results),
            "best_precision_at_5": max(r["metrics"]["precision_at_k"].get(5, 0) for r in results),
            "best_recall_at_5": max(r["metrics"]["recall_at_k"].get(5, 0) for r in results),
            "avg_chunk_count": sum(r["metrics"]["chunk_count"] for r in results) / len(results),
            "avg_chunk_length": sum(r["metrics"]["avg_chunk_length"] for r in results) / len(results)
        })
    
    return {
        "task_id": task_id,
        "status": task.status,
        "results": results,
        "summary": summary
    }


@router.get("/evaluate/comparison/{task_id}")
async def get_evaluation_comparison(task_id: str):
    """
    ç²å–è©•æ¸¬å°æ¯”åˆ†æ
    """
    task = eval_store.get_task(task_id)
    if not task:
        return JSONResponse(status_code=404, content={"error": "Task not found"})
    
    if task.status != "completed":
        return JSONResponse(status_code=400, content={"error": "Task not completed"})
    
    # åˆ†æçµæœ
    chunk_size_analysis = {}
    overlap_analysis = {}
    strategy_specific_analysis = {}
    
    for result in task.results:
        config = result.config
        metrics = result.metrics
        
        # åˆ†æchunk size
        chunk_size = config.get("chunk_size", 0)
        if chunk_size not in chunk_size_analysis:
            chunk_size_analysis[chunk_size] = {
                "precision_at_k": {},
                "recall_at_k": {},
                "precision_omega": 0,
                "count": 0
            }
        
        chunk_size_analysis[chunk_size]["count"] += 1
        chunk_size_analysis[chunk_size]["precision_omega"] = max(
            chunk_size_analysis[chunk_size]["precision_omega"],
            metrics.precision_omega
        )
        
        for k, precision in metrics.precision_at_k.items():
            if k not in chunk_size_analysis[chunk_size]["precision_at_k"]:
                chunk_size_analysis[chunk_size]["precision_at_k"][k] = 0
            chunk_size_analysis[chunk_size]["precision_at_k"][k] = max(
                chunk_size_analysis[chunk_size]["precision_at_k"][k],
                precision
            )
        
        for k, recall in metrics.recall_at_k.items():
            if k not in chunk_size_analysis[chunk_size]["recall_at_k"]:
                chunk_size_analysis[chunk_size]["recall_at_k"][k] = 0
            chunk_size_analysis[chunk_size]["recall_at_k"][k] = max(
                chunk_size_analysis[chunk_size]["recall_at_k"][k],
                recall
            )
        
        # åˆ†æoverlap ratio
        overlap_ratio = config.get("overlap_ratio", 0)
        if overlap_ratio not in overlap_analysis:
            overlap_analysis[overlap_ratio] = {
                "precision_at_k": {},
                "recall_at_k": {},
                "precision_omega": 0,
                "count": 0
            }
        
        overlap_analysis[overlap_ratio]["count"] += 1
        overlap_analysis[overlap_ratio]["precision_omega"] = max(
            overlap_analysis[overlap_ratio]["precision_omega"],
            metrics.precision_omega
        )
        
        for k, precision in metrics.precision_at_k.items():
            if k not in overlap_analysis[overlap_ratio]["precision_at_k"]:
                overlap_analysis[overlap_ratio]["precision_at_k"][k] = 0
            overlap_analysis[overlap_ratio]["precision_at_k"][k] = max(
                overlap_analysis[overlap_ratio]["precision_at_k"][k],
                precision
            )
        
        for k, recall in metrics.recall_at_k.items():
            if k not in overlap_analysis[overlap_ratio]["recall_at_k"]:
                overlap_analysis[overlap_ratio]["recall_at_k"][k] = 0
            overlap_analysis[overlap_ratio]["recall_at_k"][k] = max(
                overlap_analysis[overlap_ratio]["recall_at_k"][k],
                recall
            )
        
        # åˆ†æç­–ç•¥ç‰¹å®šåƒæ•¸
        if task.strategy == "structured_hierarchical":
            chunk_by = config.get("chunk_by", "article")
            param_key = f"chunk_by_{chunk_by}"
            if param_key not in strategy_specific_analysis:
                strategy_specific_analysis[param_key] = {
                    "precision_at_k": {},
                    "recall_at_k": {},
                    "precision_omega": 0,
                    "count": 0
                }
            
            strategy_specific_analysis[param_key]["count"] += 1
            strategy_specific_analysis[param_key]["precision_omega"] = max(
                strategy_specific_analysis[param_key]["precision_omega"],
                metrics.precision_omega
            )
            
            for k, precision in metrics.precision_at_k.items():
                if k not in strategy_specific_analysis[param_key]["precision_at_k"]:
                    strategy_specific_analysis[param_key]["precision_at_k"][k] = 0
                strategy_specific_analysis[param_key]["precision_at_k"][k] = max(
                    strategy_specific_analysis[param_key]["precision_at_k"][k],
                    precision
                )
            
            for k, recall in metrics.recall_at_k.items():
                if k not in strategy_specific_analysis[param_key]["recall_at_k"]:
                    strategy_specific_analysis[param_key]["recall_at_k"][k] = 0
                strategy_specific_analysis[param_key]["recall_at_k"][k] = max(
                    strategy_specific_analysis[param_key]["recall_at_k"][k],
                    recall
                )
    
    # ç”Ÿæˆæ¨è–¦
    recommendations = []
    if chunk_size_analysis:
        best_chunk_size = max(chunk_size_analysis.keys(), 
                            key=lambda x: chunk_size_analysis[x]["precision_omega"])
        recommendations.append(f"æœ€ä½³åˆ†å¡Šå¤§å°: {best_chunk_size} å­—ç¬¦")
    
    if overlap_analysis:
        best_overlap = max(overlap_analysis.keys(), 
                         key=lambda x: overlap_analysis[x]["precision_omega"])
        recommendations.append(f"æœ€ä½³é‡ç–Šæ¯”ä¾‹: {best_overlap:.1%}")
    
    if strategy_specific_analysis:
        best_param = max(strategy_specific_analysis.keys(), 
                        key=lambda x: strategy_specific_analysis[x]["precision_omega"])
        recommendations.append(f"æœ€ä½³ç­–ç•¥åƒæ•¸: {best_param}")
    
    return {
        "task_id": task_id,
        "chunk_size_analysis": chunk_size_analysis,
        "overlap_analysis": overlap_analysis,
        "strategy_specific_analysis": strategy_specific_analysis,
        "recommendations": recommendations
    }


# è©•ä¼°è·¯ç”±
@router.post("/evaluate")
async def evaluate_chunking(request: EvaluationRequest):
    """è©•ä¼°åˆ†å¡Šç­–ç•¥"""
    try:
        # ç²å–æ–‡æª”
        doc = store.get_doc(request.doc_id)
        if not doc:
            raise HTTPException(status_code=404, detail="æ–‡æª”ä¸å­˜åœ¨")
        
        # æª¢æŸ¥æ˜¯å¦å·²æœ‰ç”Ÿæˆçš„å•é¡Œ
        if not hasattr(doc, 'generated_questions') or not doc.generated_questions:
            raise HTTPException(
                status_code=400, 
                detail="è«‹å…ˆä½¿ç”¨ã€Œç”Ÿæˆå•é¡Œã€åŠŸèƒ½ç‚ºæ–‡æª”ç”Ÿæˆæ¸¬è©¦å•é¡Œï¼Œç„¶å¾Œå†é€²è¡Œè©•æ¸¬"
            )
        
        questions = doc.generated_questions
        
        # å‰µå»ºè©•ä¼°ä»»å‹™
        task_id = str(uuid.uuid4())
        task = EvaluationTask(
            id=task_id,
            doc_id=request.doc_id,
            status="pending",
            progress=0.0,
            configs=[],
            created_at=datetime.now().isoformat()
        )
        
        # ç”Ÿæˆé…ç½®çµ„åˆ
        configs = []
        for chunk_size in request.chunk_sizes:
            for overlap_ratio in request.overlap_ratios:
                configs.append({
                    "chunk_size": chunk_size,
                    "overlap_ratio": overlap_ratio
                })
        
        task.configs = configs
        store.add_evaluation_task(task)
        
        return {
            "task_id": task_id,
            "total_configs": len(configs),
            "questions_generated": len(questions)
        }
        
    except HTTPException:
        # é‡æ–°æ‹‹å‡ºHTTPExceptionï¼Œä¸è¦è½‰æ›ç‚º500éŒ¯èª¤
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/evaluate/task/{task_id}")
async def get_evaluation_task(task_id: str):
    """ç²å–è©•ä¼°ä»»å‹™ç‹€æ…‹"""
    task = store.get_evaluation_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")
    
    return {
        "task_id": task_id,
        "status": task.status,
        "progress": task.progress,
        "total_configs": len(task.configs),
        "completed_configs": len(task.results) if task.results else 0,
        "error_message": task.error_message
    }


@router.post("/evaluate/run/{task_id}")
async def run_evaluation(task_id: str, background_tasks: BackgroundTasks):
    """åŸ·è¡Œè©•ä¼°ä»»å‹™"""
    task = store.get_evaluation_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")
    
    if task.status != "pending":
        raise HTTPException(status_code=400, detail="ä»»å‹™å·²é–‹å§‹æˆ–å®Œæˆ")
    
    # æ›´æ–°ä»»å‹™ç‹€æ…‹
    store.update_evaluation_task(task_id, status="running", progress=0.0)
    
    # åœ¨å¾Œå°åŸ·è¡Œè©•ä¼°
    background_tasks.add_task(execute_evaluation_task, task_id)
    
    return {"message": "è©•ä¼°ä»»å‹™å·²é–‹å§‹"}


async def execute_evaluation_task(task_id: str):
    """åŸ·è¡Œè©•ä¼°ä»»å‹™çš„å¾Œå°å‡½æ•¸"""
    try:
        task = store.get_evaluation_task(task_id)
        if not task:
            return
        
        # ç²å–æ–‡æª”
        doc = store.get_doc(task.doc_id)
        if not doc:
            store.update_evaluation_task(task_id, status="failed", error_message="æ–‡æª”ä¸å­˜åœ¨")
            return
        
        # æª¢æŸ¥æ˜¯å¦å·²æœ‰ç”Ÿæˆçš„å•é¡Œ
        if not hasattr(doc, 'generated_questions') or not doc.generated_questions:
            store.update_evaluation_task(task_id, status="failed", error_message="è«‹å…ˆç”Ÿæˆå•é¡Œå†é€²è¡Œè©•æ¸¬")
            return
        
        questions = doc.generated_questions
        results = []
        
        # è©•ä¼°æ¯å€‹é…ç½®
        for i, config in enumerate(task.configs):
            try:
                result = evaluate_chunk_config(
                    doc.text,
                    questions,
                    config["chunk_size"],
                    config["overlap_ratio"]
                )
                
                # è½‰æ›ç‚ºå­—å…¸æ ¼å¼
                result_dict = {
                    "config": result.config,
                    "metrics": {
                        "precision_omega": result.metrics.precision_omega,
                        "precision_at_k": result.metrics.precision_at_k,
                        "recall_at_k": result.metrics.recall_at_k,
                        "chunk_count": result.metrics.chunk_count,
                        "avg_chunk_length": result.metrics.avg_chunk_length,
                        "length_variance": result.metrics.length_variance
                    }
                }
                
                results.append(result_dict)
                
                # æ›´æ–°é€²åº¦
                progress = (i + 1) / len(task.configs)
                store.update_evaluation_task(task_id, progress=progress)
                
            except Exception as e:
                print(f"è©•ä¼°é…ç½® {config} æ™‚å‡ºéŒ¯: {e}")
                continue
        
        # å®Œæˆä»»å‹™
        store.update_evaluation_task(
            task_id,
            status="completed",
            progress=1.0,
            results=results,
            completed_at=datetime.now().isoformat()
        )
        
    except Exception as e:
        store.update_evaluation_task(task_id, status="failed", error_message=str(e))


@router.get("/evaluate/results/{task_id}")
async def get_evaluation_results(task_id: str):
    """ç²å–è©•ä¼°çµæœ"""
    task = store.get_evaluation_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")
    
    if task.status != "completed":
        raise HTTPException(status_code=400, detail="ä»»å‹™æœªå®Œæˆ")
    
    # è¨ˆç®—æœ€ä½³é…ç½®
    best_config = None
    best_score = -1
    
    for result in task.results:
        # ç¶œåˆè©•åˆ†
        score = (
            result["metrics"]["precision_omega"] * 0.4 +
            result["metrics"]["precision_at_k"].get(5, 0) * 0.3 +
            result["metrics"]["recall_at_k"].get(5, 0) * 0.3
        )
        
        if score > best_score:
            best_score = score
            best_config = result
    
    return {
        "task_id": task_id,
        "status": task.status,
        "results": task.results,
        "summary": {
            "best_config": best_config,
            "total_configs": len(task.results),
            "best_precision_omega": max(r["metrics"]["precision_omega"] for r in task.results),
            "best_precision_at_5": max(r["metrics"]["precision_at_k"].get(5, 0) for r in task.results),
            "best_recall_at_5": max(r["metrics"]["recall_at_k"].get(5, 0) for r in task.results)
        }
    }


@router.post("/convert-multiple")
async def convert_multiple_pdfs(
    background_tasks: BackgroundTasks,
    files: List[UploadFile] = File(...),
    metadata_options: str = Form("{}")
):
    """è½‰æ›å¤šå€‹PDFæ–‡æª”ä¸¦æ•´åˆæˆä¸€å€‹æ³•å¾‹JSON"""
    try:
        # è§£æå…ƒæ•¸æ“šé¸é …
        try:
            metadata_config = json.loads(metadata_options)
            from .main import MetadataOptions
            options = MetadataOptions(**metadata_config)
        except:
            from .main import MetadataOptions
            options = MetadataOptions()
        
        # é©—è­‰æ–‡ä»¶é¡å‹
        for file in files:
            if not file.filename or not file.filename.lower().endswith('.pdf'):
                raise HTTPException(status_code=400, detail=f"æ–‡ä»¶ {file.filename} ä¸æ˜¯PDFæ ¼å¼")
        
        # å‰µå»ºä»»å‹™ID
        task_id = str(uuid.uuid4())
        
        # åœ¨å¾Œå°è™•ç†è½‰æ›ä¹‹å‰ï¼Œå…ˆè®€å–æ‰€æœ‰æ–‡ä»¶å…§å®¹
        file_contents = []
        for file in files:
            content = await file.read()
            file_contents.append({
                'content': content,
                'filename': file.filename or 'unknown.pdf'
            })
        
        background_tasks.add_task(process_multiple_pdf_conversion, task_id, file_contents, options)
        
        return {"task_id": task_id, "status": "processing"}
        
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": f"å¤šæ–‡ä»¶è½‰æ›å¤±æ•—: {str(e)}"}
        )


@router.get("/convert-multiple/status/{task_id}")
async def get_multiple_convert_status(task_id: str):
    """ç²å–å¤šæ–‡ä»¶è½‰æ›ç‹€æ…‹"""
    try:
        if task_id not in task_status_store:
            return JSONResponse(
                status_code=404,
                content={"error": "ä»»å‹™ä¸å­˜åœ¨"}
            )
        
        status_info = task_status_store[task_id]
        return {
            "task_id": task_id,
            "status": status_info["status"],
            "progress": status_info.get("progress", 0.0),
            "result": status_info.get("result"),
            "error": status_info.get("error")
        }
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": f"ç²å–ç‹€æ…‹å¤±æ•—: {str(e)}"}
        )


# QA Setä¸Šå‚³å’Œæ˜ å°„ç›¸é—œçš„å­˜å„²
qa_mapping_store = {}

# æ–°å¢ï¼šQAæ˜ å°„è«‹æ±‚æ¨¡å‹
class QAMappingRequest(BaseModel):
    doc_id: str
    qa_set: List[Dict[str, Any]]
    chunking_results: List[Dict[str, Any]]  # ä¾†è‡ªæ‰¹é‡åˆ†å¡Šçš„çµæœ
    iou_threshold: Optional[float] = 0.5  # IoUé–¾å€¼

@router.post("/upload-qa-set")
async def upload_qa_set(
    file: UploadFile = File(...),
    doc_id: str = Form(...),
    chunk_sizes: str = Form("[300, 500, 800]"),
    overlap_ratios: str = Form("[0.0, 0.1, 0.2]"),
    strategy: str = Form("fixed_size"),
    background_tasks: BackgroundTasks = None
):
    """ä¸Šå‚³QA setä¸¦é€²è¡Œchunkæ˜ å°„"""
    try:
        # é©—è­‰æ–‡æª”æ˜¯å¦å­˜åœ¨
        doc = store.get_doc(doc_id)
        if not doc:
            raise HTTPException(status_code=404, detail="æ–‡æª”ä¸å­˜åœ¨")
        
        # é©—è­‰æ–‡ä»¶æ ¼å¼
        if not file.filename or not file.filename.lower().endswith('.json'):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒJSONæ ¼å¼çš„QA setæ–‡ä»¶")
        
        # è®€å–ä¸¦è§£æQA setæ–‡ä»¶
        file_content = await file.read()
        try:
            qa_set = json.loads(file_content.decode('utf-8'))
        except json.JSONDecodeError as e:
            raise HTTPException(status_code=400, detail=f"JSONæ ¼å¼éŒ¯èª¤: {str(e)}")
        
        # é©—è­‰QA setæ ¼å¼
        if not isinstance(qa_set, list):
            raise HTTPException(status_code=400, detail="QA setå¿…é ˆæ˜¯ä¸€å€‹åˆ—è¡¨")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æ³•æ¢JSONæ•¸æ“šç”¨æ–¼è½‰æ›
        law_json_data = doc.json_data if hasattr(doc, 'json_data') and doc.json_data else None
        
        # è½‰æ›QA setï¼Œè£œå……ç¼ºå¤±çš„spanä¿¡æ¯
        if law_json_data:
            print(f"é–‹å§‹è½‰æ›QA setï¼ŒåŸå§‹é …ç›®æ•¸: {len(qa_set)}")
            try:
                converted_qa_set, conversion_stats = convert_qa_set_with_law_data(qa_set, law_json_data)
                print(f"QA setè½‰æ›å®Œæˆ:")
                print(f"  - ç¸½é …ç›®æ•¸: {conversion_stats['total_items']}")
                print(f"  - æœ‰snippetsçš„é …ç›®: {conversion_stats['items_with_snippets']}")
                print(f"  - æœ‰æœ‰æ•ˆspançš„é …ç›®: {conversion_stats['items_with_valid_spans']}")
                print(f"  - æœ‰file_pathçš„é …ç›®: {conversion_stats['items_with_file_path']}")
                print(f"  - snippetè¦†è“‹ç‡: {conversion_stats['snippet_coverage']:.2%}")
                print(f"  - spanè¦†è“‹ç‡: {conversion_stats['span_coverage']:.2%}")
                print(f"  - file_pathè¦†è“‹ç‡: {conversion_stats['file_path_coverage']:.2%}")
                qa_set = converted_qa_set
            except Exception as e:
                print(f"QA setè½‰æ›å¤±æ•—: {e}")
                # è½‰æ›å¤±æ•—æ™‚ç¹¼çºŒä½¿ç”¨åŸå§‹QA set
        else:
            print("æ²’æœ‰æ³•æ¢JSONæ•¸æ“šï¼Œè·³éQA setè½‰æ›")
        
        # è§£æé…ç½®åƒæ•¸
        try:
            chunk_sizes_list = json.loads(chunk_sizes)
            overlap_ratios_list = json.loads(overlap_ratios)
        except json.JSONDecodeError:
            chunk_sizes_list = [300, 500, 800]
            overlap_ratios_list = [0.0, 0.1, 0.2]
        
        # å‰µå»ºä»»å‹™ID
        task_id = str(uuid.uuid4())
        
        # æº–å‚™è¿”å›çš„çµ±è¨ˆä¿¡æ¯
        response_data = {
            "task_id": task_id,
            "status": "processing",
            "message": "QA setä¸Šå‚³æˆåŠŸï¼Œæ­£åœ¨é€²è¡Œchunkæ˜ å°„...",
            "original_qa_set": qa_set
        }
        
        # å¦‚æœæœ‰è½‰æ›çµ±è¨ˆä¿¡æ¯ï¼Œæ·»åŠ åˆ°éŸ¿æ‡‰ä¸­
        if law_json_data:
            try:
                _, conversion_stats = convert_qa_set_with_law_data(qa_set, law_json_data)
                response_data["conversion_stats"] = conversion_stats
            except Exception as e:
                print(f"ç²å–è½‰æ›çµ±è¨ˆå¤±æ•—: {e}")
        
        # åœ¨å¾Œå°è™•ç†æ˜ å°„
        background_tasks.add_task(
            process_qa_mapping,
            task_id,
            doc_id,
            qa_set,
            chunk_sizes_list,
            overlap_ratios_list,
            strategy
        )
        
        return response_data
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/map-qa-set")
async def map_qa_set(
    file: UploadFile = File(...),
    doc_id: str = Form(...)
):
    """ç›´æ¥æ˜ å°„QA setåˆ°æ³•æ¢JSONï¼Œä¸é€²è¡Œåˆ†å¡Šè™•ç†"""
    try:
        # é©—è­‰æ–‡æª”æ˜¯å¦å­˜åœ¨
        doc = store.get_doc(doc_id)
        if not doc:
            raise HTTPException(status_code=404, detail="æ–‡æª”ä¸å­˜åœ¨")
        
        # é©—è­‰æ–‡ä»¶æ ¼å¼
        if not file.filename or not file.filename.lower().endswith('.json'):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒJSONæ ¼å¼çš„QA setæ–‡ä»¶")
        
        # è®€å–ä¸¦è§£æQA setæ–‡ä»¶
        file_content = await file.read()
        try:
            qa_set = json.loads(file_content.decode('utf-8'))
        except json.JSONDecodeError as e:
            raise HTTPException(status_code=400, detail=f"JSONæ ¼å¼éŒ¯èª¤: {str(e)}")
        
        # é©—è­‰QA setæ ¼å¼
        if not isinstance(qa_set, list):
            raise HTTPException(status_code=400, detail="QA setå¿…é ˆæ˜¯ä¸€å€‹åˆ—è¡¨")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æ³•æ¢JSONæ•¸æ“šç”¨æ–¼è½‰æ›
        law_json_data = doc.json_data if hasattr(doc, 'json_data') and doc.json_data else None
        
        # è½‰æ›QA setï¼Œè£œå……ç¼ºå¤±çš„spanä¿¡æ¯
        if law_json_data:
            print(f"é–‹å§‹æ˜ å°„QA setï¼ŒåŸå§‹é …ç›®æ•¸: {len(qa_set)}")
            try:
                converted_qa_set, conversion_stats = convert_qa_set_with_law_data(qa_set, law_json_data)
                print(f"QA setæ˜ å°„å®Œæˆ:")
                print(f"  - ç¸½é …ç›®æ•¸: {conversion_stats['total_items']}")
                print(f"  - æœ‰snippetsçš„é …ç›®: {conversion_stats['items_with_snippets']}")
                print(f"  - æœ‰æœ‰æ•ˆspançš„é …ç›®: {conversion_stats['items_with_valid_spans']}")
                print(f"  - snippetè¦†è“‹ç‡: {conversion_stats['snippet_coverage']:.2%}")
                print(f"  - spanè¦†è“‹ç‡: {conversion_stats['span_coverage']:.2%}")
                
                # åªè¿”å›æ¨™æº–æ ¼å¼çš„QA Setï¼Œä¸åŒ…å«é¡å¤–çš„metadata
                return converted_qa_set
            except Exception as e:
                print(f"QA setæ˜ å°„å¤±æ•—: {e}")
                raise HTTPException(status_code=500, detail=f"QA setæ˜ å°„å¤±æ•—: {str(e)}")
        else:
            raise HTTPException(status_code=400, detail="æ²’æœ‰æ³•æ¢JSONæ•¸æ“šï¼Œç„¡æ³•é€²è¡Œæ˜ å°„")
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/qa-mapping/status/{task_id}")
async def get_qa_mapping_status(task_id: str):
    """ç²å–QAæ˜ å°„ä»»å‹™ç‹€æ…‹"""
    if task_id not in qa_mapping_store:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")
    
    status_info = qa_mapping_store[task_id]
    return {
        "task_id": task_id,
        "status": status_info["status"],
        "progress": status_info.get("progress", 0.0),
        "result": status_info.get("result"),
        "error": status_info.get("error")
    }


@router.get("/qa-mapping/result/{task_id}")
async def get_qa_mapping_result(task_id: str):
    """ç²å–QAæ˜ å°„çµæœ"""
    if task_id not in qa_mapping_store:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")
    
    status_info = qa_mapping_store[task_id]
    if status_info["status"] != "completed":
        raise HTTPException(status_code=400, detail="ä»»å‹™æœªå®Œæˆ")
    
    return status_info["result"]


# èª¿è©¦ç«¯é»ï¼šæ¸¬è©¦QAæ˜ å°„è«‹æ±‚
@router.post("/qa-mapping/debug")
async def debug_qa_mapping(req: dict):
    """èª¿è©¦QAæ˜ å°„è«‹æ±‚"""
    try:
        print("èª¿è©¦QAæ˜ å°„è«‹æ±‚:")
        print(f"- è«‹æ±‚é¡å‹: {type(req)}")
        print(f"- è«‹æ±‚éµ: {list(req.keys()) if isinstance(req, dict) else 'Not a dict'}")
        
        if isinstance(req, dict):
            print(f"- doc_id: {req.get('doc_id')}")
            print(f"- qa_seté¡å‹: {type(req.get('qa_set'))}")
            print(f"- qa_seté•·åº¦: {len(req.get('qa_set', []))}")
            print(f"- chunking_resultsé¡å‹: {type(req.get('chunking_results'))}")
            print(f"- chunking_resultsé•·åº¦: {len(req.get('chunking_results', []))}")
            print(f"- iou_threshold: {req.get('iou_threshold')}")
            
            # æª¢æŸ¥chunking_resultsçµæ§‹
            chunking_results = req.get('chunking_results', [])
            if chunking_results:
                print(f"- ç¬¬ä¸€å€‹chunking_resultéµ: {list(chunking_results[0].keys()) if isinstance(chunking_results[0], dict) else 'Not a dict'}")
                if isinstance(chunking_results[0], dict):
                    print(f"- æ˜¯å¦æœ‰chunks_with_span: {'chunks_with_span' in chunking_results[0]}")
                    if 'chunks_with_span' in chunking_results[0]:
                        print(f"- chunks_with_spané•·åº¦: {len(chunking_results[0]['chunks_with_span'])}")
        
        return {"status": "debug_success", "message": "èª¿è©¦ä¿¡æ¯å·²è¼¸å‡ºåˆ°æ§åˆ¶å°"}
        
    except Exception as e:
        print(f"èª¿è©¦ç«¯é»éŒ¯èª¤: {e}")
        return {"status": "debug_error", "error": str(e)}


# æ–°å¢ï¼šç›´æ¥é€²è¡ŒQAæ˜ å°„çš„APIç«¯é»
@router.post("/qa-mapping/map")
async def map_qa_to_chunks(req: QAMappingRequest, background_tasks: BackgroundTasks):
    """
    å°‡QA setæ˜ å°„åˆ°åˆ†å¡Šçµæœ
    
    é€™å€‹APIæ¥æ”¶QA setå’Œåˆ†å¡Šçµæœï¼Œé€²è¡Œæ˜ å°„ä¸¦è¿”å›çµæœ
    """
    try:
        # æ·»åŠ èª¿è©¦ä¿¡æ¯
        print(f"QAæ˜ å°„è«‹æ±‚ - doc_id: {req.doc_id}")
        print(f"QAæ˜ å°„è«‹æ±‚ - qa_seté•·åº¦: {len(req.qa_set) if req.qa_set else 0}")
        print(f"QAæ˜ å°„è«‹æ±‚ - chunking_resultsé•·åº¦: {len(req.chunking_results) if req.chunking_results else 0}")
        print(f"QAæ˜ å°„è«‹æ±‚ - iou_threshold: {req.iou_threshold}")
        
        # é©—è­‰è¼¸å…¥æ•¸æ“š
        if not req.qa_set:
            raise HTTPException(status_code=400, detail="QA setä¸èƒ½ç‚ºç©º")
        
        if not req.chunking_results:
            raise HTTPException(status_code=400, detail="åˆ†å¡Šçµæœä¸èƒ½ç‚ºç©º")
        
        # é©—è­‰æ–‡æª”æ˜¯å¦å­˜åœ¨
        doc = store.get_doc(req.doc_id)
        if not doc:
            raise HTTPException(status_code=404, detail="æ–‡æª”ä¸å­˜åœ¨")
        
        # å‰µå»ºä»»å‹™ID
        task_id = str(uuid.uuid4())
        
        # åœ¨å¾Œå°è™•ç†æ˜ å°„
        background_tasks.add_task(
            process_qa_mapping_with_chunks,
            task_id,
            req.doc_id,
            req.qa_set,
            req.chunking_results,
            req.iou_threshold
        )
        
        return {
            "task_id": task_id,
            "status": "processing",
            "message": "QAæ˜ å°„ä»»å‹™å·²é–‹å§‹"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"QAæ˜ å°„APIéŒ¯èª¤: {e}")
        raise HTTPException(status_code=500, detail=f"QAæ˜ å°„å¤±æ•—: {str(e)}")


async def process_qa_mapping_with_chunks(
    task_id: str,
    doc_id: str,
    qa_set: List[Dict],
    chunking_results: List[Dict[str, Any]],
    iou_threshold: float
):
    """è™•ç†QAæ˜ å°„çš„å¾Œå°ä»»å‹™ï¼ˆä½¿ç”¨å·²ç”Ÿæˆçš„åˆ†å¡Šçµæœï¼‰"""
    try:
        # åˆå§‹åŒ–ä»»å‹™ç‹€æ…‹
        qa_mapping_store[task_id] = {
            "status": "processing",
            "progress": 0.0
        }
        
        # ç²å–æ–‡æª”
        doc = store.get_doc(doc_id)
        if not doc:
            qa_mapping_store[task_id] = {
                "status": "failed",
                "error": "æ–‡æª”ä¸å­˜åœ¨"
            }
            return
        
        total_configs = len(chunking_results)
        mapping_results = {}
        
        # ç‚ºæ¯å€‹åˆ†å¡Šé…ç½®é€²è¡Œæ˜ å°„
        for i, chunking_result in enumerate(chunking_results):
            try:
                # ç²å–å¸¶spanä¿¡æ¯çš„chunks
                chunks_with_span = chunking_result.get('chunks_with_span', [])
                
                if not chunks_with_span:
                    print(f"è­¦å‘Š: é…ç½® {i} æ²’æœ‰chunks_with_spanä¿¡æ¯ï¼Œè·³é")
                    continue
                
                # æ˜ å°„spansåˆ°chunks
                mapped_qa_set = map_spans_to_chunks(
                    qa_set,
                    chunks_with_span,
                    iou_threshold,
                    0.3  # overlap_threshold (é™ä½åˆ°0.3)
                )
                
                # å­˜å„²æ˜ å°„çµæœ
                config_id = f"config_{i+1:03d}_{chunking_result['strategy']}_{chunking_result['config']['chunk_size']}_{chunking_result['config']['overlap_ratio']}"
                mapping_results[config_id] = {
                    "config": chunking_result['config'],
                    "strategy": chunking_result['strategy'],
                    "chunks_with_span": chunks_with_span,
                    "mapped_qa_set": mapped_qa_set,
                    "chunk_count": chunking_result['chunk_count'],
                    "mapping_stats": _calculate_mapping_stats(mapped_qa_set)
                }
                
                # æ›´æ–°é€²åº¦
                progress = (i + 1) / total_configs
                qa_mapping_store[task_id]["progress"] = progress
                
            except Exception as e:
                print(f"é…ç½® {i} æ˜ å°„å¤±æ•—: {e}")
                continue
        
        # å®Œæˆä»»å‹™
        qa_mapping_store[task_id] = {
            "status": "completed",
            "progress": 1.0,
            "result": {
                "task_id": task_id,
                "doc_id": doc_id,
                "original_qa_set": qa_set,
                "chunking_results": chunking_results,
                "mapping_results": mapping_results,
                "total_configs": len(chunking_results),
                "iou_threshold": iou_threshold,
                "mapping_summary": _generate_mapping_summary(mapping_results)
            }
        }
        
    except Exception as e:
        qa_mapping_store[task_id] = {
            "status": "failed",
            "error": str(e)
        }
        print(f"QAæ˜ å°„å¤±æ•—: {e}")


def evaluate_chunk_config_with_mapped_qa(text: str, mapped_qa_set: List[Dict], chunk_size: int, 
                                       overlap_ratio: float, strategy: str = "fixed_size", **kwargs) -> EvaluationResult:
    """
    ä½¿ç”¨æ˜ å°„çš„QA Seté€²è¡Œåˆ†å¡Šé…ç½®è©•ä¼°
    """
    from .main import calculate_precision_at_k, calculate_recall_at_k, calculate_precision_omega
    
    # ç”Ÿæˆåˆ†å¡Š
    from .chunking import chunk_text
    chunks = chunk_text(text, strategy=strategy, chunk_size=chunk_size, overlap_ratio=overlap_ratio, **kwargs)
    
    # æº–å‚™è©•ä¼°æ•¸æ“š
    k_values = [1, 3, 5, 10]
    precision_at_k_scores = {k: [] for k in k_values}
    recall_at_k_scores = {k: [] for k in k_values}
    precision_omega_scores = []
    
    # åªè©•ä¼°æ­£ä¾‹å•é¡Œ
    positive_qa_items = [item for item in mapped_qa_set if item.get('label', '').lower() == 'yes']
    
    if not positive_qa_items:
        # å¦‚æœæ²’æœ‰æ­£ä¾‹å•é¡Œï¼Œè¿”å›é›¶åˆ†
        metrics = EvaluationMetrics(
            precision_omega=0.0,
            precision_at_k={k: 0.0 for k in k_values},
            recall_at_k={k: 0.0 for k in k_values},
            chunk_count=len(chunks),
            avg_chunk_length=sum(len(chunk) for chunk in chunks) / len(chunks) if chunks else 0,
            length_variance=0.0
        )
        return EvaluationResult(
            config={"chunk_size": chunk_size, "overlap_ratio": overlap_ratio, "strategy": strategy, **kwargs},
            metrics=metrics,
            test_queries=[],
            retrieval_results={},
            timestamp=datetime.now()
        )
    
    # ç‚ºæ¯å€‹æ­£ä¾‹å•é¡Œè¨ˆç®—æŒ‡æ¨™
    for qa_item in positive_qa_items:
        query = qa_item.get('query', '')
        ground_truth_chunks = qa_item.get('relevant_chunks', [])
        
        if not ground_truth_chunks:
            # å¦‚æœæ²’æœ‰ground truth chunksï¼Œè·³é
            continue
        
        # ä½¿ç”¨ç°¡å–®çš„é—œéµè©åŒ¹é…ä¾†æ¨¡æ“¬æª¢ç´¢
        # é€™è£¡å¯ä»¥æ”¹é€²ç‚ºæ›´è¤‡é›œçš„æª¢ç´¢é‚è¼¯
        retrieved_chunks = []
        query_keywords = set(query.split())
        
        for i, chunk in enumerate(chunks):
            chunk_keywords = set(chunk.split())
            # è¨ˆç®—é—œéµè©é‡ç–Šåº¦
            overlap = len(query_keywords & chunk_keywords)
            if overlap > 0:
                retrieved_chunks.append((i, chunk, overlap))
        
        # æŒ‰é‡ç–Šåº¦æ’åº
        retrieved_chunks.sort(key=lambda x: x[2], reverse=True)
        retrieved_chunk_ids = [f"chunk_{i:03d}" for i, _, _ in retrieved_chunks]
        
        # è¨ˆç®—å„ç¨®æŒ‡æ¨™
        for k in k_values:
            precision = calculate_precision_at_k(retrieved_chunk_ids, query, k)
            recall = calculate_recall_at_k(retrieved_chunk_ids, query, k, ground_truth_chunks)
            precision_at_k_scores[k].append(precision)
            recall_at_k_scores[k].append(recall)
        
        precision_omega = calculate_precision_omega(retrieved_chunk_ids, query)
        precision_omega_scores.append(precision_omega)
    
    # è¨ˆç®—å¹³å‡æŒ‡æ¨™
    avg_precision_at_k = {k: sum(scores) / len(scores) if scores else 0.0 for k, scores in precision_at_k_scores.items()}
    avg_recall_at_k = {k: sum(scores) / len(scores) if scores else 0.0 for k, scores in recall_at_k_scores.items()}
    avg_precision_omega = sum(precision_omega_scores) / len(precision_omega_scores) if precision_omega_scores else 0.0
    
    metrics = EvaluationMetrics(
        precision_omega=avg_precision_omega,
        precision_at_k=avg_precision_at_k,
        recall_at_k=avg_recall_at_k,
        chunk_count=len(chunks),
        avg_chunk_length=sum(len(chunk) for chunk in chunks) / len(chunks) if chunks else 0,
        length_variance=0.0  # ç°¡åŒ–è¨ˆç®—
    )
    
    return EvaluationResult(
        config={"chunk_size": chunk_size, "overlap_ratio": overlap_ratio, "strategy": strategy, **kwargs},
        metrics=metrics,
        test_queries=[item.get('query', '') for item in positive_qa_items],
        retrieval_results={},
        timestamp=datetime.now()
    )


def _calculate_mapping_stats(mapped_qa_set: List[Dict]) -> Dict[str, Any]:
    """è¨ˆç®—æ˜ å°„çµ±è¨ˆä¿¡æ¯"""
    total_questions = len(mapped_qa_set)
    questions_with_chunks = sum(1 for item in mapped_qa_set if item.get('relevant_chunks'))
    positive_questions = sum(1 for item in mapped_qa_set if item.get('label', '').lower() == 'yes')
    negative_questions = total_questions - positive_questions
    
    # è¨ˆç®—æ˜ å°„æˆåŠŸç‡ï¼šæœ‰æ˜ å°„çš„æ­£ä¾‹å•é¡Œæ•¸ / ç¸½æ­£ä¾‹å•é¡Œæ•¸
    positive_questions_with_chunks = sum(1 for item in mapped_qa_set 
                                       if item.get('label', '').lower() == 'yes' and item.get('relevant_chunks'))
    mapping_success_rate = (positive_questions_with_chunks / positive_questions * 100) if positive_questions > 0 else 0
    
    return {
        "total_questions": total_questions,
        "questions_with_chunks": questions_with_chunks,
        "mapping_coverage": questions_with_chunks / total_questions if total_questions > 0 else 0,
        "mapping_success_rate": mapping_success_rate,  # æ–°å¢ï¼šæ˜ å°„æˆåŠŸç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
        "positive_questions": positive_questions,
        "negative_questions": negative_questions,
        "avg_chunks_per_question": sum(len(item.get('relevant_chunks', [])) for item in mapped_qa_set) / total_questions if total_questions > 0 else 0
    }


def _generate_mapping_summary(mapping_results: Dict[str, Dict]) -> Dict[str, Any]:
    """ç”Ÿæˆæ˜ å°„æ‘˜è¦"""
    if not mapping_results:
        return {}
    
    best_coverage = 0
    best_config = None
    
    for config_id, result in mapping_results.items():
        coverage = result['mapping_stats']['mapping_coverage']
        if coverage > best_coverage:
            best_coverage = coverage
            best_config = config_id
    
    return {
        "best_config": best_config,
        "best_coverage": best_coverage,
        "total_configs": len(mapping_results),
        "avg_coverage": sum(result['mapping_stats']['mapping_coverage'] for result in mapping_results.values()) / len(mapping_results)
    }


async def process_qa_mapping(
    task_id: str,
    doc_id: str,
    qa_set: List[Dict],
    chunk_sizes: List[int],
    overlap_ratios: List[float],
    strategy: str
):
    """è™•ç†QAæ˜ å°„çš„å¾Œå°ä»»å‹™"""
    try:
        # åˆå§‹åŒ–ä»»å‹™ç‹€æ…‹
        qa_mapping_store[task_id] = {
            "status": "processing",
            "progress": 0.0
        }
        
        # ç²å–æ–‡æª”
        doc = store.get_doc(doc_id)
        if not doc:
            qa_mapping_store[task_id] = {
                "status": "failed",
                "error": "æ–‡æª”ä¸å­˜åœ¨"
            }
            return
        
        # ç”Ÿæˆæ‰€æœ‰é…ç½®çµ„åˆ
        configs = []
        for chunk_size in chunk_sizes:
            for overlap_ratio in overlap_ratios:
                overlap = int(chunk_size * overlap_ratio)
                configs.append({
                    "chunk_size": chunk_size,
                    "overlap_ratio": overlap_ratio,
                    "overlap": overlap,
                    "strategy": strategy
                })
        
        total_configs = len(configs)
        mapping_results = {}
        
        # ç‚ºæ¯å€‹é…ç½®é€²è¡Œæ˜ å°„
        for i, config in enumerate(configs):
            try:
                # ç”Ÿæˆåˆ†å¡Š
                chunks = chunk_text(
                    doc.text,
                    strategy=strategy,
                    chunk_size=config["chunk_size"],
                    overlap_ratio=config["overlap_ratio"]
                )
                
                # æ˜ å°„spansåˆ°chunks
                mapped_qa_set = map_spans_to_chunks(
                    qa_set,
                    chunks,
                    config["chunk_size"],
                    config["overlap"],
                    strategy
                )
                
                # å­˜å„²æ˜ å°„çµæœ
                config_id = f"config_{i+1:03d}_{config['chunk_size']}_{config['overlap_ratio']}"
                mapping_results[config_id] = {
                    "config": config,
                    "chunks": chunks,
                    "mapped_qa_set": mapped_qa_set,
                    "chunk_count": len(chunks)
                }
                
                # æ›´æ–°é€²åº¦
                progress = (i + 1) / total_configs
                qa_mapping_store[task_id]["progress"] = progress
                
            except Exception as e:
                print(f"é…ç½® {config} æ˜ å°„å¤±æ•—: {e}")
                continue
        
        # å®Œæˆä»»å‹™
        qa_mapping_store[task_id] = {
            "status": "completed",
            "progress": 1.0,
            "result": {
                "task_id": task_id,
                "doc_id": doc_id,
                "original_qa_set": qa_set,
                "configs": configs,
                "mapping_results": mapping_results,
                "total_configs": len(configs)
            }
        }
        
    except Exception as e:
        qa_mapping_store[task_id] = {
            "status": "failed",
            "error": str(e)
        }
        print(f"QAæ˜ å°„å¤±æ•—: {e}")


async def process_multiple_chunking(
    task_id: str,
    doc_id: str,
    strategies: List[str],
    chunk_sizes: List[int],
    overlap_ratios: List[float]
):
    """è™•ç†æ‰¹é‡åˆ†å¡Šçš„å¾Œå°ä»»å‹™"""
    try:
        # åˆå§‹åŒ–ä»»å‹™ç‹€æ…‹
        chunking_task_store[task_id] = {
            "status": "processing",
            "progress": 0.0,
            "results": []
        }
        
        # ç²å–æ–‡æª”
        doc = store.get_doc(doc_id)
        if not doc:
            chunking_task_store[task_id] = {
                "status": "failed",
                "error": "æ–‡æª”ä¸å­˜åœ¨"
            }
            return
        
        # ç”Ÿæˆæ‰€æœ‰é…ç½®çµ„åˆ
        total_combinations = len(strategies) * len(chunk_sizes) * len(overlap_ratios)
        completed_combinations = 0
        results = []
        
        for strategy in strategies:
            for chunk_size in chunk_sizes:
                for overlap_ratio in overlap_ratios:
                    try:
                        # æº–å‚™åˆ†å¡Šåƒæ•¸
                        chunk_kwargs = {
                            "chunk_size": chunk_size,
                            "max_chunk_size": chunk_size,
                            "overlap_ratio": overlap_ratio
                        }
                        
                        # æ ¹æ“šç­–ç•¥æ·»åŠ ç‰¹å®šåƒæ•¸
                        if strategy == "structured_hierarchical":
                            chunk_kwargs["chunk_by"] = "article"
                        elif strategy == "rcts_hierarchical":
                            chunk_kwargs["preserve_structure"] = True
                        elif strategy == "hierarchical":
                            chunk_kwargs["level_depth"] = 3
                            chunk_kwargs["min_chunk_size"] = 200
                        elif strategy == "semantic":
                            chunk_kwargs["similarity_threshold"] = 0.6
                            chunk_kwargs["context_window"] = 100
                        elif strategy == "sliding_window":
                            chunk_kwargs["window_size"] = chunk_size
                            chunk_kwargs["step_size"] = int(chunk_size * 0.5)
                            chunk_kwargs["boundary_aware"] = True
                            chunk_kwargs["preserve_sentences"] = True
                            chunk_kwargs["min_chunk_size_sw"] = 100
                            chunk_kwargs["max_chunk_size_sw"] = chunk_size * 2
                        
                        # è‹¥ç‚ºçµæ§‹åŒ–å±¤æ¬¡åˆ†å‰²ä½†æœªæä¾›å·²ä¿å­˜çš„ JSONï¼Œæ˜ç¢ºè·³éï¼Œé¿å…å›é€€åˆ°ç´”æ–‡å­—
                        if strategy == "structured_hierarchical":
                            if not doc.json_data or not isinstance(doc.json_data, dict) or not (
                                (doc.json_data.get("laws") or []) or (doc.json_data.get("chapters") or [])
                            ):
                                raise Exception("structured_hierarchical éœ€è¦åˆæ³•çš„ JSONï¼ˆåŒ…å« laws æˆ– chaptersï¼‰ã€‚")

                        # ç”Ÿæˆåˆ†å¡Šï¼ˆå¸¶spanä¿¡æ¯ï¼‰
                        from .chunking import chunk_text_with_span
                        effective_text = doc.text
                        if doc.json_data and strategy != "structured_hierarchical":
                            try:
                                effective_text = build_text_from_json(doc.json_data)
                            except Exception:
                                effective_text = doc.text
                        chunks_with_span = chunk_text_with_span(
                            effective_text,
                            strategy=strategy,
                            json_data=doc.json_data,
                            **chunk_kwargs
                        )
                        
                        # æå–chunksæ–‡æœ¬ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
                        chunks = [chunk_info['content'] for chunk_info in chunks_with_span]
                        
                        # è¨ˆç®—çµ±è¨ˆä¿¡æ¯
                        chunk_lengths = [len(chunk) for chunk in chunks] if chunks else []
                        avg_chunk_length = sum(chunk_lengths) / len(chunk_lengths) if chunk_lengths else 0
                        min_length = min(chunk_lengths) if chunk_lengths else 0
                        max_length = max(chunk_lengths) if chunk_lengths else 0
                        
                        # è¨ˆç®—é•·åº¦æ–¹å·®
                        if chunk_lengths:
                            variance = sum((length - avg_chunk_length) ** 2 for length in chunk_lengths) / len(chunk_lengths)
                        else:
                            variance = 0
                        
                        # å‰µå»ºçµæœ
                        result = {
                            "strategy": strategy,
                            "config": {
                                "chunk_size": chunk_size,
                                "overlap_ratio": overlap_ratio,
                                "strategy": strategy,
                                **chunk_kwargs
                            },
                            "chunks": chunks,
                            "all_chunks": chunks,
                            "chunks_with_span": chunks_with_span,  # æ–°å¢ï¼šå¸¶spanä¿¡æ¯çš„chunks
                            "chunk_count": len(chunks),
                            "metrics": {
                                "avg_length": avg_chunk_length,
                                "length_variance": variance,
                                "overlap_rate": overlap_ratio,
                                "min_length": min_length,
                                "max_length": max_length,
                            },
                            "sample_chunks": chunks[:3] if chunks else [],
                            "timestamp": datetime.now().isoformat(),
                        }
                        
                        results.append(result)
                        
                        # æ›´æ–°é€²åº¦
                        completed_combinations += 1
                        progress = completed_combinations / total_combinations
                        chunking_task_store[task_id]["progress"] = progress
                        
                    except Exception as e:
                        print(f"åˆ†å¡Šçµ„åˆ {strategy}-{chunk_size}-{overlap_ratio} å¤±æ•—: {e}")
                        continue
        
        # å®Œæˆä»»å‹™
        chunking_task_store[task_id] = {
            "status": "completed",
            "progress": 1.0,
            "results": results
        }
        
        # å°‡ç¬¬ä¸€å€‹çµæœåŒæ­¥åˆ°æ–‡æª”ä¸­ï¼Œä»¥ä¾¿å¾ŒçºŒçš„ embed æ“ä½œ
        if results:
            # é¸æ“‡ç¬¬ä¸€å€‹çµæœä½œç‚ºä¸»è¦åˆ†å¡Šçµæœ
            primary_result = results[0]
            doc = store.get_doc(doc_id)
            if doc:
                # æ›´æ–°æ–‡æª”çš„åˆ†å¡Šä¿¡æ¯
                doc.chunks = primary_result.get("chunks", [])
                doc.chunk_size = primary_result.get("config", {}).get("chunk_size", 500)
                doc.overlap = int(doc.chunk_size * primary_result.get("config", {}).get("overlap_ratio", 0.1))
                
                # å¦‚æœæœ‰çµæ§‹åŒ–chunksï¼Œä¹Ÿä¿å­˜
                if "chunks_with_span" in primary_result:
                    doc.structured_chunks = primary_result["chunks_with_span"]
                
                # ä¿å­˜æ–‡æª”
                store.add_doc(doc)
                print(f"å·²å°‡æ‰¹é‡åˆ†å¡ŠçµæœåŒæ­¥åˆ°æ–‡æª” {doc_id}ï¼Œåˆ†å¡Šæ•¸é‡: {len(doc.chunks)}")
        
    except Exception as e:
        chunking_task_store[task_id] = {
            "status": "failed",
            "error": str(e)
        }
        print(f"æ‰¹é‡åˆ†å¡Šå¤±æ•—: {e}")


async def process_strategy_evaluation(
    task_id: str,
    doc_id: str,
    chunking_results: List[Dict[str, Any]],
    qa_mapping_result: Dict[str, Any],
    test_queries: List[str],
    k_values: List[int]
):
    """è™•ç†ç­–ç•¥è©•ä¼°çš„å¾Œå°ä»»å‹™"""
    try:
        # åˆå§‹åŒ–ä»»å‹™ç‹€æ…‹
        eval_store.update_task_status(task_id, "running", progress=0.0)
        
        # ç²å–æ–‡æª”
        doc = store.get_doc(doc_id)
        if not doc:
            eval_store.update_task_status(task_id, "failed", error_message="æ–‡æª”ä¸å­˜åœ¨")
            return
        
        results = []
        total_configs = len(chunking_results)
        
        for i, chunking_result in enumerate(chunking_results):
            try:
                # ç²å–å°æ‡‰çš„æ˜ å°„çµæœ
                config_id = f"config_{i+1:03d}_{chunking_result['strategy']}_{chunking_result['config']['chunk_size']}_{chunking_result['config']['overlap_ratio']}"
                mapped_qa_set = qa_mapping_result.get("mapping_results", {}).get(config_id, {}).get("mapped_qa_set", [])
                
                # ä½¿ç”¨æ˜ å°„çš„QA Seté€²è¡Œè©•ä¼°
                result = evaluate_chunk_config_with_mapped_qa(
                    doc.text,
                    mapped_qa_set,
                    chunking_result["config"]["chunk_size"],
                    chunking_result["config"]["overlap_ratio"],
                    strategy=chunking_result["strategy"],
                    **{k: v for k, v in chunking_result["config"].items() if k not in ["chunk_size", "overlap_ratio", "strategy"]}
                )
                
                # æ·»åŠ åˆ†å¡Šçµæœä¿¡æ¯
                result.config.update({
                    "strategy": chunking_result["strategy"],
                    "chunk_count": chunking_result["chunk_count"],
                    "avg_chunk_length": chunking_result["metrics"]["avg_length"]
                })
                
                results.append(result)
                
                # æ›´æ–°é€²åº¦
                progress = (i + 1) / total_configs
                eval_store.update_task_status(task_id, "running", progress=progress)
                
            except Exception as e:
                print(f"è©•ä¼°åˆ†å¡Šçµæœ {i} æ™‚å‡ºéŒ¯: {e}")
                continue
        
        # å®Œæˆä»»å‹™
        eval_store.update_task_status(task_id, "completed", results=results)
        
    except Exception as e:
        eval_store.update_task_status(task_id, "failed", error_message=str(e))
        print(f"ç­–ç•¥è©•ä¼°å¤±æ•—: {e}")


async def process_multiple_pdf_conversion(task_id: str, file_contents: List[Dict], options):
    """è™•ç†å¤šå€‹PDFè½‰æ›çš„å¾Œå°ä»»å‹™"""
    try:
        # åˆå§‹åŒ–ä»»å‹™ç‹€æ…‹
        task_status_store[task_id] = {
            "status": "processing",
            "progress": 0.0
        }
        
        from .main import convert_pdf_structured, merge_law_documents
        
        # è½‰æ›æ¯å€‹PDFæ–‡ä»¶
        law_documents = []
        all_texts = []  # æ”¶é›†æ‰€æœ‰æ–‡æœ¬å…§å®¹
        total_files = len(file_contents)
        
        for i, file_info in enumerate(file_contents):
            # æ›´æ–°é€²åº¦
            progress = (i / total_files) * 0.8  # 80%ç”¨æ–¼è½‰æ›
            task_status_store[task_id]["progress"] = progress
            
            # ä½¿ç”¨é å…ˆè®€å–çš„æ–‡ä»¶å…§å®¹
            file_content = file_info['content']
            filename = file_info['filename']
            conversion_result = convert_pdf_structured(file_content, filename, options)
            
            # æª¢æŸ¥è½‰æ›æ˜¯å¦æˆåŠŸ
            if not conversion_result.get("success", False):
                print(f"PDFè½‰æ›å¤±æ•—: {filename}")
                continue
            
            # æª¢æŸ¥æ–‡æœ¬å…§å®¹
            extracted_text = conversion_result.get("text", "")
            if not extracted_text or not extracted_text.strip():
                print(f"PDFè½‰æ›æˆåŠŸä½†æ²’æœ‰æå–åˆ°æ–‡æœ¬å…§å®¹: {filename}")
                continue
                
            # æ”¶é›†æ–‡æœ¬å…§å®¹å’Œmetadata
            all_texts.append(extracted_text)
            law_doc = conversion_result["metadata"]
            law_documents.append(law_doc)
        
        # æ›´æ–°é€²åº¦åˆ°90%
        task_status_store[task_id]["progress"] = 0.9
        
        # æ•´åˆå¤šå€‹æ³•å¾‹æ–‡æª”
        merged_doc = merge_law_documents(law_documents)
        # æ­£è¦åŒ–åˆä½µå¾Œçš„ metadataï¼ˆè£œé½Šå¿…è¦éµï¼‰
        merged_doc = normalize_corpus_metadata(merged_doc)
        
        # åˆä½µæ‰€æœ‰æ–‡æœ¬å…§å®¹
        if all_texts:
            merged_text = "\n\n" + "="*80 + "\n\n".join(all_texts)
        else:
            # å¦‚æœæ²’æœ‰æ–‡æœ¬å…§å®¹ï¼Œå¾JSONçµæ§‹ç”Ÿæˆ
            merged_text = generate_text_from_merged_doc(merged_doc)
        
        print(f"å¤šæ–‡ä»¶åˆä½µå®Œæˆï¼Œç”Ÿæˆæ–‡æœ¬é•·åº¦: {len(merged_text)} å­—ç¬¦")
        
        # å‰µå»ºæ–‡æª”è¨˜éŒ„
        doc_id = str(uuid.uuid4())
        doc_record = DocRecord(
            id=doc_id,
            filename=f"merged_{len(file_contents)}_laws",
            text=merged_text,  # åˆä½µå¾Œçš„æ–‡æœ¬
            chunks=[],  # å°‡åœ¨å¾ŒçºŒæ­¥é©Ÿä¸­ç”Ÿæˆ
            chunk_size=0,
            overlap=0,
            json_data=merged_doc,
            structured_chunks=None,
            generated_questions=None
        )
        
        # å­˜å„²æ–‡æª”è¨˜éŒ„
        store.docs[doc_id] = doc_record
        
        # æ›´æ–°ä»»å‹™ç‹€æ…‹ç‚ºå®Œæˆ
        task_status_store[task_id] = {
            "status": "completed",
            "progress": 1.0,
            "result": {
                "doc_id": doc_id,
                "metadata": merged_doc
            }
        }
        
    except Exception as e:
        # æ›´æ–°ä»»å‹™ç‹€æ…‹ç‚ºå¤±æ•—
        task_status_store[task_id] = {
            "status": "failed",
            "progress": 0.0,
            "error": str(e)
        }
        print(f"å¤šæ–‡ä»¶è½‰æ›å¤±æ•—: {e}")


# æ‰¹é‡åˆ†å¡Šè·¯ç”±
@router.post("/chunk/multiple")
async def start_multiple_chunking(req: MultipleChunkingRequest, background_tasks: BackgroundTasks):
    """é–‹å§‹æ‰¹é‡åˆ†å¡Šä»»å‹™"""
    try:
        # é©—è­‰æ–‡æª”æ˜¯å¦å­˜åœ¨
        doc = store.get_doc(req.doc_id)
        if not doc:
            raise HTTPException(status_code=404, detail="æ–‡æª”ä¸å­˜åœ¨")
        
        # å‰µå»ºä»»å‹™ID
        task_id = str(uuid.uuid4())
        
        # åœ¨å¾Œå°è™•ç†æ‰¹é‡åˆ†å¡Š
        background_tasks.add_task(
            process_multiple_chunking,
            task_id,
            req.doc_id,
            req.strategies,
            req.chunk_sizes,
            req.overlap_ratios
        )
        
        return {
            "task_id": task_id,
            "status": "started",
            "total_combinations": len(req.strategies) * len(req.chunk_sizes) * len(req.overlap_ratios),
            "message": "æ‰¹é‡åˆ†å¡Šä»»å‹™å·²é–‹å§‹"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/chunk/status/{task_id}")
async def get_chunking_status(task_id: str):
    """ç²å–æ‰¹é‡åˆ†å¡Šä»»å‹™ç‹€æ…‹"""
    if task_id not in chunking_task_store:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")
    
    status_info = chunking_task_store[task_id]
    return {
        "task_id": task_id,
        "status": status_info["status"],
        "progress": status_info.get("progress", 0.0),
        "error": status_info.get("error")
    }


@router.get("/chunk/results/{task_id}")
async def get_chunking_results(task_id: str):
    """ç²å–æ‰¹é‡åˆ†å¡Šçµæœ"""
    if task_id not in chunking_task_store:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")
    
    status_info = chunking_task_store[task_id]
    if status_info["status"] != "completed":
        raise HTTPException(status_code=400, detail="ä»»å‹™æœªå®Œæˆ")
    
    return {
        "task_id": task_id,
        "status": status_info["status"],
        "results": status_info["results"]
    }


# ç­–ç•¥è©•ä¼°è·¯ç”±
@router.post("/evaluate/strategy")
async def start_strategy_evaluation(req: StrategyEvaluationRequest, background_tasks: BackgroundTasks):
    """é–‹å§‹ç­–ç•¥è©•ä¼°ä»»å‹™"""
    try:
        # é©—è­‰æ–‡æª”æ˜¯å¦å­˜åœ¨
        doc = store.get_doc(req.doc_id)
        if not doc:
            raise HTTPException(status_code=404, detail="æ–‡æª”ä¸å­˜åœ¨")
        
        # å‰µå»ºè©•ä¼°ä»»å‹™
        task_id = eval_store.create_task(
            doc_id=req.doc_id,
            configs=[],  # ä¸éœ€è¦é å…ˆç”Ÿæˆé…ç½®
            test_queries=req.test_queries,
            k_values=req.k_values,
            strategy="strategy_evaluation"
        )
        
        # åœ¨å¾Œå°è™•ç†ç­–ç•¥è©•ä¼°
        background_tasks.add_task(
            process_strategy_evaluation,
            task_id,
            req.doc_id,
            req.chunking_results,
            req.qa_mapping_result,
            req.test_queries,
            req.k_values
        )
        
        return {
            "task_id": task_id,
            "status": "started",
            "total_configs": len(req.chunking_results),
            "message": "ç­–ç•¥è©•ä¼°ä»»å‹™å·²é–‹å§‹"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
