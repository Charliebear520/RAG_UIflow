"""
Structured-HopRAG è§„åˆ™è¾¹æ„å»ºå™¨
å®ç°4ç§è§„åˆ™è¾¹ï¼šhierarchy, reference, similar_concept, theme
"""

import re
import numpy as np
from typing import Dict, List, Any, Set, Tuple, Optional
from collections import defaultdict
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfVectorizer

from .structured_hoprag_config import (
    StructuredHopRAGConfig,
    EdgeType,
    LegalLevel,
    DEFAULT_CONFIG
)
from .structured_hoprag_embedding import MultiLevelNode

class RuleEdgeBuilder:
    """è§„åˆ™è¾¹æ„å»ºå™¨"""
    
    def __init__(self, config: StructuredHopRAGConfig = DEFAULT_CONFIG):
        self.config = config
        self.edges = []
        
    def build_all_rule_edges(
        self,
        nodes: Dict[str, MultiLevelNode]
    ) -> List[Dict[str, Any]]:
        """æ„å»ºæ‰€æœ‰è§„åˆ™è¾¹"""
        print("ğŸ”— å¼€å§‹æ„å»ºè§„åˆ™è¾¹...")
        
        self.edges = []
        
        # 1. å±‚çº§è¾¹
        if self.config.hierarchy_edge_enabled:
            hierarchy_edges = self._build_hierarchy_edges(nodes)
            self.edges.extend(hierarchy_edges)
            print(f"  âœ… å±‚çº§è¾¹: {len(hierarchy_edges)} æ¡")
        
        # 2. å¼•ç”¨è¾¹
        if self.config.reference_edge_enabled:
            reference_edges = self._build_reference_edges(nodes)
            self.edges.extend(reference_edges)
            print(f"  âœ… å¼•ç”¨è¾¹: {len(reference_edges)} æ¡")
        
        # 3. ç›¸ä¼¼æ¦‚å¿µè¾¹
        if self.config.similar_edge_enabled:
            similar_edges = self._build_similar_concept_edges(nodes)
            self.edges.extend(similar_edges)
            print(f"  âœ… ç›¸ä¼¼æ¦‚å¿µè¾¹: {len(similar_edges)} æ¡")
        
        # 4. ä¸»é¢˜è¾¹
        if self.config.theme_edge_enabled:
            theme_edges = self._build_theme_edges(nodes)
            self.edges.extend(theme_edges)
            print(f"  âœ… ä¸»é¢˜è¾¹: {len(theme_edges)} æ¡")
        
        print(f"ğŸ¯ è§„åˆ™è¾¹æ„å»ºå®Œæˆï¼Œå…± {len(self.edges)} æ¡")
        return self.edges
    
    def _build_hierarchy_edges(
        self,
        nodes: Dict[str, MultiLevelNode]
    ) -> List[Dict[str, Any]]:
        """
        æ„å»ºå±‚çº§è¾¹ï¼ˆçˆ¶å­å…³ç³»ï¼‰
        
        ç±»å‹ï¼šdirected
        æƒé‡ï¼šcosine_sim(parent_embed, child_embed) æˆ–å›ºå®šå€¼1.0
        """
        edges = []
        
        for node in nodes.values():
            # è·³è¿‡æ²¡æœ‰å­èŠ‚ç‚¹çš„èŠ‚ç‚¹
            if not node.children_ids:
                continue
            
            parent_embed = node.final_embedding
            
            for child_id in node.children_ids:
                if child_id not in nodes:
                    continue
                
                child = nodes[child_id]
                child_embed = child.final_embedding
                
                # è®¡ç®—æƒé‡
                if self.config.hierarchy_weight_method == "cosine" and \
                   parent_embed is not None and child_embed is not None:
                    weight = self._cosine_similarity(parent_embed, child_embed)
                else:
                    weight = 1.0  # å›ºå®šæƒé‡
                
                edge = {
                    'from_node': node.node_id,
                    'to_node': child_id,
                    'edge_type': EdgeType.HIERARCHY.value,
                    'weight': weight,
                    'directed': True,
                    'metadata': {
                        'parent_level': node.level,
                        'child_level': child.level
                    }
                }
                edges.append(edge)
        
        return edges
    
    def _build_reference_edges(
        self,
        nodes: Dict[str, MultiLevelNode]
    ) -> List[Dict[str, Any]]:
        """
        æ„å»ºå¼•ç”¨è¾¹ï¼ˆå‡†ç”¨ã€ä¾ç¬¬Xæ¡ç­‰ï¼‰
        
        ç±»å‹ï¼šdirected
        æƒé‡ï¼šå›ºå®š0.95ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
        """
        edges = []
        
        # åªåœ¨basic_unitï¼ˆæ¡ï¼‰å±‚çº§æ£€æµ‹å¼•ç”¨
        article_nodes = [
            n for n in nodes.values() 
            if n.level == LegalLevel.BASIC_UNIT.value
        ]
        
        for node in article_nodes:
            # æ£€æµ‹å¼•ç”¨æ¨¡å¼
            references = self._detect_references(node.content)
            
            for ref_article_num in references:
                # æŸ¥æ‰¾è¢«å¼•ç”¨çš„æ¡æ–‡èŠ‚ç‚¹
                target_node = self._find_article_by_number(
                    ref_article_num, 
                    nodes,
                    node.metadata.get('law_name')  # åŒä¸€æ³•è§„å†…
                )
                
                if target_node:
                    edge = {
                        'from_node': node.node_id,
                        'to_node': target_node.node_id,
                        'edge_type': EdgeType.REFERENCE.value,
                        'weight': 0.95,
                        'directed': True,
                        'metadata': {
                            'reference_type': 'citation',
                            'cited_article': ref_article_num
                        }
                    }
                    edges.append(edge)
        
        return edges
    
    def _detect_references(self, content: str) -> List[str]:
        """æ£€æµ‹æ–‡æœ¬ä¸­çš„å¼•ç”¨"""
        references = []
        
        for pattern in self.config.reference_patterns:
            matches = re.finditer(pattern, content)
            for match in matches:
                article_num = match.group(1)
                references.append(article_num)
        
        return list(set(references))  # å»é‡
    
    def _find_article_by_number(
        self,
        article_num: str,
        nodes: Dict[str, MultiLevelNode],
        law_name: Optional[str] = None
    ) -> Optional[MultiLevelNode]:
        """æ ¹æ®æ¡æ–‡ç¼–å·æŸ¥æ‰¾èŠ‚ç‚¹"""
        for node in nodes.values():
            if node.level != LegalLevel.BASIC_UNIT.value:
                continue
            
            # æ£€æŸ¥æ¡æ–‡ç¼–å·
            node_article_num = node.metadata.get('article_number', '')
            if article_num in node_article_num or node_article_num in article_num:
                # å¦‚æœæŒ‡å®šäº†æ³•è§„åç§°ï¼Œéœ€è¦åŒ¹é…
                if law_name:
                    node_law = node.metadata.get('law_name', '')
                    if law_name in node_law or node_law in law_name:
                        return node
                else:
                    return node
        
        return None
    
    def _build_similar_concept_edges(
        self,
        nodes: Dict[str, MultiLevelNode]
    ) -> List[Dict[str, Any]]:
        """
        æ„å»ºç›¸ä¼¼æ¦‚å¿µè¾¹
        
        æ–¹æ³•ï¼š
        1. TF-IDFæå–æ³•å¾‹å…³é”®è¯
        2. è¯å…¸åŒ¹é… + embeddingç›¸ä¼¼åº¦ > 0.75
        
        ç±»å‹ï¼šundirected
        æƒé‡ï¼šcosine_sim
        """
        edges = []
        
        # åªåœ¨æŒ‡å®šå±‚çº§æ„å»ºç›¸ä¼¼è¾¹ï¼ˆé»˜è®¤ä»…basic_unitï¼‰
        target_nodes = [
            n for n in nodes.values()
            if n.level in self.config.similar_edge_levels
        ]
        
        if not target_nodes:
            return edges
        
        # æå–æ³•å¾‹æœ¯è¯­è¯å…¸
        legal_terms = self._extract_legal_terms(target_nodes)
        print(f"  ğŸ“š æå–æ³•å¾‹æœ¯è¯­: {len(legal_terms)} ä¸ª")
        
        # æ„å»ºèŠ‚ç‚¹çš„å…³é”®è¯é›†åˆ
        node_keywords = {}
        for node in target_nodes:
            keywords = self._extract_keywords(node.content, legal_terms)
            node_keywords[node.node_id] = keywords
        
        # ä¸¤ä¸¤æ¯”è¾ƒèŠ‚ç‚¹
        for i, node_a in enumerate(target_nodes):
            for node_b in target_nodes[i+1:]:
                # 1. æ£€æŸ¥å…³é”®è¯é‡å 
                keywords_a = node_keywords.get(node_a.node_id, set())
                keywords_b = node_keywords.get(node_b.node_id, set())
                
                if not keywords_a or not keywords_b:
                    continue
                
                # Jaccardç›¸ä¼¼åº¦
                jaccard_sim = len(keywords_a & keywords_b) / len(keywords_a | keywords_b)
                
                # éœ€è¦æœ‰ä¸€å®šçš„å…³é”®è¯é‡å 
                if jaccard_sim < 0.1:
                    continue
                
                # 2. è®¡ç®—embeddingç›¸ä¼¼åº¦
                if node_a.final_embedding is not None and node_b.final_embedding is not None:
                    cosine_sim = self._cosine_similarity(
                        node_a.final_embedding,
                        node_b.final_embedding
                    )
                    
                    # ç›¸ä¼¼åº¦é˜ˆå€¼
                    if cosine_sim >= self.config.similar_edge_threshold:
                        edge = {
                            'from_node': node_a.node_id,
                            'to_node': node_b.node_id,
                            'edge_type': EdgeType.SIMILAR_CONCEPT.value,
                            'weight': cosine_sim,
                            'directed': False,
                            'metadata': {
                                'common_keywords': list(keywords_a & keywords_b),
                                'jaccard_similarity': jaccard_sim
                            }
                        }
                        edges.append(edge)
        
        return edges
    
    def _extract_legal_terms(
        self,
        nodes: List[MultiLevelNode],
        top_n: int = 100
    ) -> Set[str]:
        """ä½¿ç”¨TF-IDFæå–æ³•å¾‹æœ¯è¯­"""
        # æ”¶é›†æ‰€æœ‰æ–‡æœ¬
        documents = [node.content for node in nodes]
        
        try:
            # TF-IDFå‘é‡åŒ–
            vectorizer = TfidfVectorizer(
                max_features=top_n,
                min_df=2,  # è‡³å°‘å‡ºç°åœ¨2ä¸ªæ–‡æ¡£ä¸­
                max_df=0.5,  # æœ€å¤šå‡ºç°åœ¨50%çš„æ–‡æ¡£ä¸­
                ngram_range=(1, 3),  # 1-3ä¸ªè¯çš„çŸ­è¯­
                token_pattern=r'[\u4e00-\u9fff]{2,}'  # ä¸­æ–‡è¯æ±‡ï¼Œè‡³å°‘2å­—
            )
            
            tfidf_matrix = vectorizer.fit_transform(documents)
            feature_names = vectorizer.get_feature_names_out()
            
            # è·å–é«˜TF-IDFåˆ†æ•°çš„æœ¯è¯­
            avg_tfidf = np.mean(tfidf_matrix.toarray(), axis=0)
            top_indices = avg_tfidf.argsort()[-top_n:][::-1]
            
            legal_terms = {feature_names[i] for i in top_indices}
            
            # æ·»åŠ å¸¸è§æ³•å¾‹æœ¯è¯­
            common_legal_terms = {
                'ä¾µæƒ', 'èµ”å¿', 'ç½šé‡‘', 'æ‹˜å½¹', 'æœ‰æœŸå¾’åˆ‘', 'æ²¡æ”¶',
                'è‘—ä½œæƒ', 'å•†æ ‡æƒ', 'ä¸“åˆ©æƒ', 'åˆç†ä½¿ç”¨', 'å‡†ç”¨',
                'æ°‘äº‹è´£ä»»', 'åˆ‘äº‹è´£ä»»', 'è¡Œæ”¿è´£ä»»', 'æŸå®³èµ”å¿',
                'çŸ¥è¯†äº§æƒ', 'æƒåˆ©äºº', 'ä¹‰åŠ¡äºº', 'ä¾µæƒäºº'
            }
            legal_terms.update(common_legal_terms)
            
            return legal_terms
            
        except Exception as e:
            print(f"  âš ï¸ TF-IDFæå–å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤æœ¯è¯­")
            return {
                'ä¾µæƒ', 'èµ”å¿', 'ç½šé‡‘', 'æ‹˜å½¹', 'è‘—ä½œæƒ', 'å•†æ ‡æƒ',
                'åˆç†ä½¿ç”¨', 'æ°‘äº‹è´£ä»»', 'åˆ‘äº‹è´£ä»»'
            }
    
    def _extract_keywords(
        self,
        content: str,
        legal_terms: Set[str]
    ) -> Set[str]:
        """ä»å†…å®¹ä¸­æå–å…³é”®è¯ï¼ˆåŒ¹é…æ³•å¾‹æœ¯è¯­ï¼‰"""
        keywords = set()
        
        for term in legal_terms:
            if term in content:
                keywords.add(term)
        
        return keywords
    
    def _build_theme_edges(
        self,
        nodes: Dict[str, MultiLevelNode]
    ) -> List[Dict[str, Any]]:
        """
        æ„å»ºä¸»é¢˜è¾¹ï¼ˆåŸºäºèšç±»ï¼‰
        
        æ–¹æ³•ï¼šå¯¹é«˜å±‚èŠ‚ç‚¹ï¼ˆchapter/sectionï¼‰è¿›è¡Œembeddingèšç±»
        ç±»å‹ï¼šundirected
        æƒé‡ï¼šèšç±»å†…ç›¸ä¼¼åº¦
        """
        edges = []
        
        # åªåœ¨æŒ‡å®šå±‚çº§æ„å»ºä¸»é¢˜è¾¹
        target_nodes = [
            n for n in nodes.values()
            if n.level in self.config.theme_levels and n.final_embedding is not None
        ]
        
        if len(target_nodes) < 2:
            return edges
        
        # å‡†å¤‡embeddingçŸ©é˜µ
        embeddings = np.array([n.final_embedding for n in target_nodes])
        node_ids = [n.node_id for n in target_nodes]
        
        # K-meansèšç±»
        try:
            n_clusters = min(self.config.theme_num_clusters, len(target_nodes))
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            cluster_labels = kmeans.fit_predict(embeddings)
            
            # æŒ‰èšç±»åˆ†ç»„
            clusters = defaultdict(list)
            for i, label in enumerate(cluster_labels):
                clusters[label].append(i)
            
            # åœ¨æ¯ä¸ªèšç±»å†…éƒ¨å»ºè¾¹
            for cluster_id, indices in clusters.items():
                if len(indices) < 2:
                    continue
                
                # èšç±»å†…ä¸¤ä¸¤è¿æ¥
                for i in range(len(indices)):
                    for j in range(i+1, len(indices)):
                        idx_a = indices[i]
                        idx_b = indices[j]
                        
                        node_a_id = node_ids[idx_a]
                        node_b_id = node_ids[idx_b]
                        
                        # è®¡ç®—ç›¸ä¼¼åº¦ä½œä¸ºæƒé‡
                        similarity = self._cosine_similarity(
                            embeddings[idx_a],
                            embeddings[idx_b]
                        )
                        
                        edge = {
                            'from_node': node_a_id,
                            'to_node': node_b_id,
                            'edge_type': EdgeType.THEME.value,
                            'weight': similarity,
                            'directed': False,
                            'metadata': {
                                'cluster_id': int(cluster_id),
                                'cluster_size': len(indices)
                            }
                        }
                        edges.append(edge)
            
            print(f"  ğŸ“Š ä¸»é¢˜èšç±»: {n_clusters} ä¸ªç°‡")
            
        except Exception as e:
            print(f"  âš ï¸ ä¸»é¢˜èšç±»å¤±è´¥: {e}")
        
        return edges
    
    def _cosine_similarity(self, vec_a: np.ndarray, vec_b: np.ndarray) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        dot_product = np.dot(vec_a, vec_b)
        norm_a = np.linalg.norm(vec_a)
        norm_b = np.linalg.norm(vec_b)
        
        if norm_a == 0 or norm_b == 0:
            return 0.0
        
        return float(dot_product / (norm_a * norm_b))
    
    def get_edge_statistics(self) -> Dict[str, Any]:
        """è·å–è¾¹ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'total_edges': len(self.edges),
            'by_type': {},
            'directed_edges': sum(1 for e in self.edges if e.get('directed', False)),
            'undirected_edges': sum(1 for e in self.edges if not e.get('directed', False)),
        }
        
        # æŒ‰ç±»å‹ç»Ÿè®¡
        for edge in self.edges:
            edge_type = edge['edge_type']
            if edge_type not in stats['by_type']:
                stats['by_type'][edge_type] = {
                    'count': 0,
                    'avg_weight': 0.0,
                    'weights': []
                }
            stats['by_type'][edge_type]['count'] += 1
            stats['by_type'][edge_type]['weights'].append(edge['weight'])
        
        # è®¡ç®—å¹³å‡æƒé‡
        for edge_type in stats['by_type']:
            weights = stats['by_type'][edge_type]['weights']
            stats['by_type'][edge_type]['avg_weight'] = np.mean(weights) if weights else 0.0
            del stats['by_type'][edge_type]['weights']  # ç§»é™¤åŸå§‹æƒé‡åˆ—è¡¨
        
        return stats
