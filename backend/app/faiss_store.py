"""
FAISSå‘é‡å­˜å„²æ¨¡çµ„
"""

import os
import pickle
import numpy as np
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
import faiss

try:
    import faiss
    FAISS_AVAILABLE = True
except ImportError:
    faiss = None
    FAISS_AVAILABLE = False


@dataclass
class FAISSIndexInfo:
    """FAISSç´¢å¼•ä¿¡æ¯"""
    index_type: str
    dimension: int
    total_vectors: int
    is_trained: bool
    metadata: Dict[str, Any]


class FAISSVectorStore:
    """FAISSå‘é‡å­˜å„²é¡"""
    
    def __init__(self, dimension: int = 768):
        self.dimension = dimension
        self.index = None
        self.index_info: Optional[FAISSIndexInfo] = None
        self.chunk_ids: List[str] = []
        self.chunk_doc_ids: List[str] = []
        self.chunks_flat: List[str] = []
        self.enhanced_metadata: Dict[str, Dict] = {}
        
        # å¤šå±¤æ¬¡embeddingå­˜å„²
        self.multi_level_indices: Dict[str, Any] = {}
        self.multi_level_chunk_ids: Dict[str, List[str]] = {}
        self.multi_level_chunk_doc_ids: Dict[str, List[str]] = {}
        self.multi_level_chunks_flat: Dict[str, List[str]] = {}
        self.multi_level_enhanced_metadata: Dict[str, Dict[str, Dict]] = {}
        self.multi_level_index_info: Dict[str, FAISSIndexInfo] = {}
        
        # æŒä¹…åŒ–è¨­ç½®
        self.data_dir = "data"
        self.ensure_data_dir()
    
    def ensure_data_dir(self):
        """ç¢ºä¿æ•¸æ“šç›®éŒ„å­˜åœ¨"""
        if not os.path.exists(self.data_dir):
            os.makedirs(self.data_dir)
            print(f"âœ… å‰µå»ºFAISSæ•¸æ“šç›®éŒ„: {self.data_dir}")
    
    def create_index(self, dimension: int, index_type: str = "flat") -> None:
        """å‰µå»ºFAISSç´¢å¼•"""
        if not FAISS_AVAILABLE:
            raise RuntimeError("FAISS not available. Please install faiss-cpu or faiss-gpu.")
        
        self.dimension = dimension
        
        if index_type == "flat":
            # ä½¿ç”¨FlatL2ç´¢å¼•ï¼ˆç²¾ç¢ºæœç´¢ï¼‰
            self.index = faiss.IndexFlatIP(dimension)  # Inner Product (cosine similarity)
        elif index_type == "ivf":
            # ä½¿ç”¨IVFç´¢å¼•ï¼ˆè¿‘ä¼¼æœç´¢ï¼Œé©åˆå¤§è¦æ¨¡æ•¸æ“šï¼‰
            quantizer = faiss.IndexFlatIP(dimension)
            self.index = faiss.IndexIVFFlat(quantizer, dimension, 100)
        else:
            raise ValueError(f"Unsupported index type: {index_type}")
        
        self.index_info = FAISSIndexInfo(
            index_type=index_type,
            dimension=dimension,
            total_vectors=0,
            is_trained=index_type != "ivf",
            metadata={"created_at": None}
        )
        
        print(f"âœ… å‰µå»ºFAISSç´¢å¼•: {index_type}, ç¶­åº¦: {dimension}")
    
    def add_vectors(self, vectors: List[List[float]], chunk_ids: List[str], 
                   chunk_doc_ids: List[str], chunks_flat: List[str]) -> None:
        """æ·»åŠ å‘é‡åˆ°ç´¢å¼•"""
        if self.index is None:
            raise ValueError("Index not created. Call create_index() first.")
        
        if not vectors:
            return
        
        # è½‰æ›ç‚ºnumpyæ•¸çµ„
        vectors_array = np.array(vectors, dtype=np.float32)
        
        # æ­£è¦åŒ–å‘é‡ï¼ˆç”¨æ–¼cosine similarityï¼‰
        faiss.normalize_L2(vectors_array)
        
        # å¦‚æœä½¿ç”¨IVFç´¢å¼•ä¸”æœªè¨“ç·´ï¼Œéœ€è¦å…ˆè¨“ç·´
        if hasattr(self.index, 'is_trained') and not self.index.is_trained:
            print("ğŸ”§ è¨“ç·´IVFç´¢å¼•...")
            self.index.train(vectors_array)
            self.index_info.is_trained = True
        
        # æ·»åŠ å‘é‡åˆ°ç´¢å¼•
        self.index.add(vectors_array)
        
        # æ›´æ–°å…ƒæ•¸æ“š
        self.chunk_ids.extend(chunk_ids)
        self.chunk_doc_ids.extend(chunk_doc_ids)
        self.chunks_flat.extend(chunks_flat)
        self.index_info.total_vectors = len(self.chunk_ids)
        
        print(f"âœ… æ·»åŠ  {len(vectors)} å€‹å‘é‡åˆ°FAISSç´¢å¼•ï¼Œç¸½è¨ˆ: {self.index_info.total_vectors}")
    
    def add_multi_level_vectors(self, level_name: str, vectors: List[List[float]], 
                               chunk_ids: List[str], chunk_doc_ids: List[str], 
                               chunks_flat: List[str]) -> None:
        """æ·»åŠ å¤šå±¤æ¬¡å‘é‡åˆ°ç´¢å¼•"""
        if not vectors:
            return
        
        # ç‚ºè©²å±¤æ¬¡å‰µå»ºç´¢å¼•
        dimension = len(vectors[0])
        level_index = faiss.IndexFlatIP(dimension)
        
        # è½‰æ›ç‚ºnumpyæ•¸çµ„ä¸¦æ­£è¦åŒ–
        vectors_array = np.array(vectors, dtype=np.float32)
        faiss.normalize_L2(vectors_array)
        
        # æ·»åŠ å‘é‡
        level_index.add(vectors_array)
        
        # å­˜å„²ç´¢å¼•å’Œå…ƒæ•¸æ“š
        self.multi_level_indices[level_name] = level_index
        self.multi_level_chunk_ids[level_name] = chunk_ids
        self.multi_level_chunk_doc_ids[level_name] = chunk_doc_ids
        self.multi_level_chunks_flat[level_name] = chunks_flat
        
        # å‰µå»ºç´¢å¼•ä¿¡æ¯
        self.multi_level_index_info[level_name] = FAISSIndexInfo(
            index_type="flat",
            dimension=dimension,
            total_vectors=len(chunk_ids),
            is_trained=True,
            metadata={"level": level_name}
        )
        
        print(f"âœ… æ·»åŠ  {len(vectors)} å€‹å‘é‡åˆ°å±¤æ¬¡ '{level_name}' FAISSç´¢å¼•")
    
    def search(self, query_vector: List[float], k: int = 10) -> Tuple[List[int], List[float]]:
        """æœç´¢æœ€ç›¸ä¼¼çš„å‘é‡"""
        if self.index is None:
            raise ValueError("Index not created. Call create_index() first.")
        
        if not query_vector:
            return [], []
        
        # è½‰æ›æŸ¥è©¢å‘é‡ç‚ºnumpyæ•¸çµ„
        query_array = np.array([query_vector], dtype=np.float32)
        faiss.normalize_L2(query_array)
        
        # åŸ·è¡Œæœç´¢ - ä½¿ç”¨index.ntotalè€Œä¸æ˜¯index_info.total_vectorsï¼ˆæ›´å¯é ï¼‰
        total_vectors = self.index.ntotal if hasattr(self.index, 'ntotal') else (
            self.index_info.total_vectors if self.index_info else 0
        )
        scores, indices = self.index.search(query_array, min(k, total_vectors))
        
        # è½‰æ›çµæœ
        result_indices = [int(idx) for idx in indices[0] if idx >= 0]
        result_scores = [float(score) for score in scores[0][:len(result_indices)]]
        
        return result_indices, result_scores
    
    def search_multi_level(self, level_name: str, query_vector: List[float], k: int = 10) -> Tuple[List[int], List[float]]:
        """æœç´¢æŒ‡å®šå±¤æ¬¡çš„æœ€ç›¸ä¼¼å‘é‡"""
        if level_name not in self.multi_level_indices:
            return [], []
        
        index = self.multi_level_indices[level_name]
        index_info = self.multi_level_index_info[level_name]
        
        if not query_vector:
            return [], []
        
        # è½‰æ›æŸ¥è©¢å‘é‡
        query_array = np.array([query_vector], dtype=np.float32)
        faiss.normalize_L2(query_array)
        
        # åŸ·è¡Œæœç´¢
        scores, indices = index.search(query_array, min(k, index_info.total_vectors))
        
        # è½‰æ›çµæœ
        result_indices = [int(idx) for idx in indices[0] if idx >= 0]
        result_scores = [float(score) for score in scores[0][:len(result_indices)]]
        
        return result_indices, result_scores
    
    def get_chunk_by_index(self, index: int) -> Optional[Dict[str, Any]]:
        """æ ¹æ“šç´¢å¼•ç²å–chunkä¿¡æ¯"""
        if index < 0 or index >= len(self.chunk_ids):
            return None
        
        return {
            "chunk_id": self.chunk_ids[index],
            "doc_id": self.chunk_doc_ids[index],
            "content": self.chunks_flat[index],
            "enhanced_metadata": self.enhanced_metadata.get(self.chunk_ids[index], {})
        }
    
    def get_multi_level_chunk_by_index(self, level_name: str, index: int) -> Optional[Dict[str, Any]]:
        """æ ¹æ“šç´¢å¼•ç²å–å¤šå±¤æ¬¡chunkä¿¡æ¯"""
        if level_name not in self.multi_level_chunk_ids:
            return None
        
        chunk_ids = self.multi_level_chunk_ids[level_name]
        if index < 0 or index >= len(chunk_ids):
            return None
        
        return {
            "chunk_id": chunk_ids[index],
            "doc_id": self.multi_level_chunk_doc_ids[level_name][index],
            "content": self.multi_level_chunks_flat[level_name][index],
            "enhanced_metadata": self.multi_level_enhanced_metadata.get(level_name, {}).get(chunk_ids[index], {})
        }
    
    def set_enhanced_metadata(self, chunk_id: str, metadata: Dict[str, Any]) -> None:
        """è¨­ç½®å¢å¼·metadata"""
        self.enhanced_metadata[chunk_id] = metadata
    
    def set_multi_level_enhanced_metadata(self, level_name: str, chunk_id: str, metadata: Dict[str, Any]) -> None:
        """è¨­ç½®å¤šå±¤æ¬¡å¢å¼·metadata"""
        if level_name not in self.multi_level_enhanced_metadata:
            self.multi_level_enhanced_metadata[level_name] = {}
        self.multi_level_enhanced_metadata[level_name][chunk_id] = metadata
    
    def get_available_levels(self) -> List[str]:
        """ç²å–å¯ç”¨çš„å±¤æ¬¡"""
        return list(self.multi_level_indices.keys())
    
    def has_vectors(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦æœ‰å‘é‡"""
        return self.index is not None and self.index_info is not None and self.index_info.total_vectors > 0
    
    def has_multi_level_vectors(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦æœ‰å¤šå±¤æ¬¡å‘é‡"""
        return len(self.multi_level_indices) > 0
    
    def save_data(self) -> None:
        """ä¿å­˜FAISSç´¢å¼•å’Œå…ƒæ•¸æ“š"""
        try:
            # ä¿å­˜æ¨™æº–ç´¢å¼•
            if self.index is not None:
                faiss.write_index(self.index, os.path.join(self.data_dir, "faiss_index.bin"))
            
            # ä¿å­˜å¤šå±¤æ¬¡ç´¢å¼•
            for level_name, index in self.multi_level_indices.items():
                faiss.write_index(index, os.path.join(self.data_dir, f"faiss_index_{level_name}.bin"))
            
            # ä¿å­˜å…ƒæ•¸æ“š
            metadata = {
                "index_info": self.index_info.__dict__ if self.index_info else None,
                "chunk_ids": self.chunk_ids,
                "chunk_doc_ids": self.chunk_doc_ids,
                "chunks_flat": self.chunks_flat,
                "enhanced_metadata": self.enhanced_metadata,
                "multi_level_index_info": {k: v.__dict__ for k, v in self.multi_level_index_info.items()},
                "multi_level_chunk_ids": self.multi_level_chunk_ids,
                "multi_level_chunk_doc_ids": self.multi_level_chunk_doc_ids,
                "multi_level_chunks_flat": self.multi_level_chunks_flat,
                "multi_level_enhanced_metadata": self.multi_level_enhanced_metadata
            }
            
            with open(os.path.join(self.data_dir, "faiss_metadata.pkl"), "wb") as f:
                pickle.dump(metadata, f)
            
            print(f"âœ… FAISSæ•¸æ“šå·²ä¿å­˜åˆ° {self.data_dir}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜FAISSæ•¸æ“šå¤±æ•—: {e}")
    
    def load_data(self) -> None:
        """è¼‰å…¥FAISSç´¢å¼•å’Œå…ƒæ•¸æ“š"""
        try:
            # è¼‰å…¥å…ƒæ•¸æ“š
            metadata_file = os.path.join(self.data_dir, "faiss_metadata.pkl")
            if not os.path.exists(metadata_file):
                print(f"ğŸ“ FAISSå…ƒæ•¸æ“šæ–‡ä»¶ä¸å­˜åœ¨: {metadata_file}")
                return
            
            with open(metadata_file, "rb") as f:
                metadata = pickle.load(f)
            
            # æ¢å¾©æ¨™æº–ç´¢å¼•
            index_file = os.path.join(self.data_dir, "faiss_index.bin")
            if os.path.exists(index_file):
                self.index = faiss.read_index(index_file)
                self.index_info = FAISSIndexInfo(**metadata["index_info"]) if metadata["index_info"] else None
            
            # æ¢å¾©å¤šå±¤æ¬¡ç´¢å¼•
            for level_name in metadata.get("multi_level_index_info", {}).keys():
                level_index_file = os.path.join(self.data_dir, f"faiss_index_{level_name}.bin")
                if os.path.exists(level_index_file):
                    self.multi_level_indices[level_name] = faiss.read_index(level_index_file)
            
            # æ¢å¾©å…ƒæ•¸æ“š
            self.chunk_ids = metadata.get("chunk_ids", [])
            self.chunk_doc_ids = metadata.get("chunk_doc_ids", [])
            self.chunks_flat = metadata.get("chunks_flat", [])
            self.enhanced_metadata = metadata.get("enhanced_metadata", {})
            
            # æ¢å¾©å¤šå±¤æ¬¡å…ƒæ•¸æ“š
            self.multi_level_index_info = {
                k: FAISSIndexInfo(**v) for k, v in metadata.get("multi_level_index_info", {}).items()
            }
            self.multi_level_chunk_ids = metadata.get("multi_level_chunk_ids", {})
            self.multi_level_chunk_doc_ids = metadata.get("multi_level_chunk_doc_ids", {})
            self.multi_level_chunks_flat = metadata.get("multi_level_chunks_flat", {})
            self.multi_level_enhanced_metadata = metadata.get("multi_level_enhanced_metadata", {})
            
            print(f"âœ… FAISSæ•¸æ“šå·²å¾ {self.data_dir} è¼‰å…¥")
            print(f"   ğŸ“„ æ¨™æº–å‘é‡: {self.index_info.total_vectors if self.index_info else 0} å€‹")
            print(f"   ğŸ—ï¸ å¤šå±¤æ¬¡å‘é‡: {len(self.multi_level_indices)} å€‹å±¤æ¬¡")
            
        except Exception as e:
            print(f"âŒ è¼‰å…¥FAISSæ•¸æ“šå¤±æ•—: {e}")
    
    def reset_vectors(self) -> None:
        """é‡ç½®æ‰€æœ‰å‘é‡"""
        self.index = None
        self.index_info = None
        self.chunk_ids = []
        self.chunk_doc_ids = []
        self.chunks_flat = []
        self.enhanced_metadata = {}
        
        self.multi_level_indices = {}
        self.multi_level_chunk_ids = {}
        self.multi_level_chunk_doc_ids = {}
        self.multi_level_chunks_flat = {}
        self.multi_level_enhanced_metadata = {}
        self.multi_level_index_info = {}
        
        print("ğŸ—‘ï¸ FAISSå‘é‡æ•¸æ“šå·²é‡ç½®")
    
    def get_stats(self) -> Dict[str, Any]:
        """ç²å–çµ±è¨ˆä¿¡æ¯"""
        stats = {
            "faiss_available": FAISS_AVAILABLE,
            "standard_index": {
                "has_index": self.index is not None,
                "total_vectors": self.index_info.total_vectors if self.index_info else 0,
                "dimension": self.index_info.dimension if self.index_info else 0,
                "index_type": self.index_info.index_type if self.index_info else None
            },
            "multi_level_indices": {
                level: {
                    "total_vectors": info.total_vectors,
                    "dimension": info.dimension,
                    "index_type": info.index_type
                }
                for level, info in self.multi_level_index_info.items()
            }
        }
        return stats
