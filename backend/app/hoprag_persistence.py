"""
HopRAGå›¾è°±æŒä¹…åŒ–æ¨¡å—
è‡ªåŠ¨ä¿å­˜å’ŒåŠ è½½HopRAGå›¾è°±ï¼Œé¿å…æ¯æ¬¡é‡å¯éƒ½è¦é‡æ–°æ„å»º
"""

import os
import json
import pickle
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

class HopRAGPersistence:
    """HopRAGå›¾è°±æŒä¹…åŒ–ç®¡ç†å™¨"""
    
    def __init__(self, storage_dir: str = "hoprag_storage"):
        """
        åˆå§‹åŒ–æŒä¹…åŒ–ç®¡ç†å™¨
        
        Args:
            storage_dir: å­˜å‚¨ç›®å½•è·¯å¾„
        """
        self.storage_dir = Path(storage_dir)
        self.storage_dir.mkdir(exist_ok=True)
        
        # æ–‡ä»¶è·¯å¾„
        self.graph_file = self.storage_dir / "hoprag_graph.pkl"
        self.metadata_file = self.storage_dir / "metadata.json"
        
    def save_graph(self, hoprag_system, force: bool = False) -> bool:
        """
        ä¿å­˜HopRAGå›¾è°±åˆ°æ–‡ä»¶
        
        Args:
            hoprag_system: HopRAGç³»ç»Ÿå®ä¾‹
            force: æ˜¯å¦å¼ºåˆ¶ä¿å­˜ï¼ˆå³ä½¿å›¾è°±æœªæ„å»ºï¼‰
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        if not hoprag_system.is_graph_built and not force:
            print("âš ï¸ HopRAGå›¾è°±æœªæ„å»ºï¼Œè·³è¿‡ä¿å­˜")
            return False
            
        try:
            print("ğŸ’¾ å¼€å§‹ä¿å­˜HopRAGå›¾è°±...")
            start_time = datetime.now()
            
            # å¯¼å‡ºå›¾æ•°æ®
            graph_data = hoprag_system.export_graph_data()
            
            # ä¿å­˜åˆ°pickleæ–‡ä»¶ï¼ˆæ›´å¿«ï¼Œæ”¯æŒå¤æ‚å¯¹è±¡ï¼‰
            with open(self.graph_file, 'wb') as f:
                pickle.dump(graph_data, f, protocol=pickle.HIGHEST_PROTOCOL)
            
            # ä¿å­˜å…ƒæ•°æ®ï¼ˆJSONæ ¼å¼ï¼Œæ–¹ä¾¿æŸ¥çœ‹ï¼‰
            metadata = {
                "save_time": start_time.isoformat(),
                "statistics": hoprag_system.get_graph_statistics(),
                "file_size_mb": os.path.getsize(self.graph_file) / (1024 * 1024)
            }
            
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            elapsed = (datetime.now() - start_time).total_seconds()
            
            print(f"âœ… HopRAGå›¾è°±ä¿å­˜æˆåŠŸï¼")
            print(f"   æ–‡ä»¶å¤§å°: {metadata['file_size_mb']:.2f} MB")
            print(f"   ä¿å­˜æ—¶é—´: {elapsed:.2f}ç§’")
            print(f"   ä½ç½®: {self.graph_file}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜HopRAGå›¾è°±å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def load_graph(self, hoprag_system) -> bool:
        """
        ä»æ–‡ä»¶åŠ è½½HopRAGå›¾è°±
        
        Args:
            hoprag_system: HopRAGç³»ç»Ÿå®ä¾‹
            
        Returns:
            æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        if not self.graph_file.exists():
            print("â„¹ï¸ æœªæ‰¾åˆ°å·²ä¿å­˜çš„HopRAGå›¾è°±")
            return False
            
        try:
            print("ğŸ“‚ å‘ç°å·²ä¿å­˜çš„HopRAGå›¾è°±ï¼Œå¼€å§‹åŠ è½½...")
            start_time = datetime.now()
            
            # è¯»å–å…ƒæ•°æ®
            if self.metadata_file.exists():
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                    save_time = metadata.get('save_time', 'Unknown')
                    print(f"   ä¿å­˜æ—¶é—´: {save_time}")
                    print(f"   æ–‡ä»¶å¤§å°: {metadata.get('file_size_mb', 0):.2f} MB")
            
            # ä»pickleæ–‡ä»¶åŠ è½½
            with open(self.graph_file, 'rb') as f:
                graph_data = pickle.load(f)
            
            # å¯¼å…¥åˆ°HopRAGç³»ç»Ÿ
            hoprag_system.import_graph_data(graph_data)
            
            elapsed = (datetime.now() - start_time).total_seconds()
            
            print(f"âœ… HopRAGå›¾è°±åŠ è½½æˆåŠŸï¼")
            print(f"   åŠ è½½æ—¶é—´: {elapsed:.2f}ç§’")
            print(f"   ç»Ÿè®¡ä¿¡æ¯: {hoprag_system.get_graph_statistics()}")
            
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½HopRAGå›¾è°±å¤±è´¥: {e}")
            print(f"   å¯èƒ½éœ€è¦é‡æ–°æ„å»ºå›¾è°±")
            import traceback
            traceback.print_exc()
            return False
    
    def has_saved_graph(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰å·²ä¿å­˜çš„å›¾è°±"""
        return self.graph_file.exists()
    
    def get_metadata(self) -> Optional[Dict[str, Any]]:
        """è·å–å·²ä¿å­˜å›¾è°±çš„å…ƒæ•°æ®"""
        if not self.metadata_file.exists():
            return None
            
        try:
            with open(self.metadata_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ è¯»å–å…ƒæ•°æ®å¤±è´¥: {e}")
            return None
    
    def delete_saved_graph(self) -> bool:
        """åˆ é™¤å·²ä¿å­˜çš„å›¾è°±"""
        try:
            if self.graph_file.exists():
                os.remove(self.graph_file)
                print(f"âœ… å·²åˆ é™¤å›¾è°±æ–‡ä»¶: {self.graph_file}")
                
            if self.metadata_file.exists():
                os.remove(self.metadata_file)
                print(f"âœ… å·²åˆ é™¤å…ƒæ•°æ®æ–‡ä»¶: {self.metadata_file}")
                
            return True
            
        except Exception as e:
            print(f"âŒ åˆ é™¤å¤±è´¥: {e}")
            return False
    
    def get_storage_info(self) -> Dict[str, Any]:
        """è·å–å­˜å‚¨ä¿¡æ¯"""
        info = {
            "storage_dir": str(self.storage_dir),
            "has_saved_graph": self.has_saved_graph(),
            "graph_file": str(self.graph_file),
            "metadata_file": str(self.metadata_file)
        }
        
        if self.has_saved_graph():
            info["file_size_mb"] = os.path.getsize(self.graph_file) / (1024 * 1024)
            metadata = self.get_metadata()
            if metadata:
                info["save_time"] = metadata.get("save_time")
                info["statistics"] = metadata.get("statistics")
        
        return info
