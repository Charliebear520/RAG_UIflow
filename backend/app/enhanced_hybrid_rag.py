"""
å¢å¼·ç‰ˆHybridRAGæ¨¡çµ„
æ·±åº¦èåˆå‘é‡æª¢ç´¢ã€BM25é—œéµå­—æª¢ç´¢å’Œmetadataå¢å¼·
"""

import numpy as np
from typing import List, Dict, Any, Tuple, Optional
from dataclasses import dataclass
import re

try:
    import jieba  # type: ignore
    import jieba.analyse  # type: ignore
    jieba.initialize()
except ImportError:
    jieba = None  # type: ignore

from .faiss_store import FAISSVectorStore
from .bm25_index import BM25KeywordIndex
from .metadata_enhancer import MetadataEnhancer


@dataclass
class EnhancedHybridConfig:
    """å¢å¼·ç‰ˆHybridRAGé…ç½®"""
    # å‘é‡æª¢ç´¢æ¬Šé‡
    vector_weight: float = 0.6
    
    # BM25é—œéµå­—æª¢ç´¢æ¬Šé‡
    bm25_weight: float = 0.25
    
    # MetadataåŠ åˆ†æ¬Šé‡
    metadata_weight: float = 0.15
    
    # å…·é«”çš„metadataåŠ åˆ†æ¬Šé‡
    w_law_match: float = 0.15
    w_article_match: float = 0.15
    w_concept_match: float = 0.1
    w_keyword_hit: float = 0.05
    w_domain_match: float = 0.05
    w_title_match: float = 0.1
    w_category_match: float = 0.05
    
    # åŠ åˆ†ä¸Šé™
    max_bonus: float = 0.4
    
    # æ¨™é¡ŒåŒ¹é…é…ç½®
    title_boost_factor: float = 1.5
    category_boost_factor: float = 1.3
    
    # Metadataå‘ä¸‹ç¹¼æ‰¿é…ç½®
    enable_inheritance_strategy: bool = True
    metadata_match_threshold: float = 0.3
    inheritance_bonus: float = 0.1
    inheritance_boost_factor: float = 1.2


class EnhancedHybridRAG:
    """å¢å¼·ç‰ˆHybridRAG"""
    
    def __init__(self, faiss_store: FAISSVectorStore, bm25_index: BM25KeywordIndex, 
                 metadata_enhancer: MetadataEnhancer):
        self.faiss_store = faiss_store
        self.bm25_index = bm25_index
        self.metadata_enhancer = metadata_enhancer
        
        # æ³•å¾‹åŒç¾©è©å­—å…¸
        self.legal_synonyms = {
            'å…¬é–‹å‚³è¼¸': ['å…¬é–‹å‚³è¼¸', 'æ•¸ä½å‚³è¼¸', 'ç¶²è·¯å‚³è¼¸', 'ç·šä¸Šå‚³è¼¸', 'ä¸Šç·šæä¾›', 'public transmission'],
            'å…¬é–‹æ’­é€': ['å…¬é–‹æ’­é€', 'å»£æ’­', 'æ’­é€', 'broadcast'],
            'é‡è£½': ['é‡è£½', 'è¤‡è£½', 'æ‹·è²', 'è¤‡æœ¬è£½ä½œ', 'reproduction'],
            'æ•£å¸ƒ': ['æ•£å¸ƒ', 'ç™¼è¡Œ', 'æµé€š', 'distribution'],
            'æ”¹ä½œ': ['æ”¹ä½œ', 'æ”¹ç·¨', 'ç¿»æ¡ˆ', 'è¡ç”Ÿå‰µä½œ', 'derivative'],
            'å¼•ç”¨': ['å¼•ç”¨', 'ç¯€éŒ„', 'æ‘˜éŒ„', 'å¼•ç”¨ä»–äººè‘—ä½œ'],
            'åˆç†ä½¿ç”¨': ['åˆç†ä½¿ç”¨', 'å…¬å¹³ä½¿ç”¨', 'fair use'],
            'å•†æ¨™æ¬Š': ['å•†æ¨™æ¬Š', 'å•†æ¨™å°ˆç”¨æ¬Š', 'å•†æ¨™ä½¿ç”¨æ¬Š'],
            'è‘—ä½œæ¬Š': ['è‘—ä½œæ¬Š', 'ç‰ˆæ¬Š', 'copyright'],
            'å°ˆåˆ©æ¬Š': ['å°ˆåˆ©æ¬Š', 'å°ˆåˆ©', 'patent'],
            'ä¾µå®³': ['ä¾µå®³', 'ä¾µçŠ¯', 'é•å', 'æå®³', 'é•æ³•', 'ä¸æ³•'],
            'è™•ç½°': ['è™•ç½°', 'åˆ¶è£', 'æ‡²ç½°', 'penalty']
        }
    
    def retrieve(self, query: str, k: int = 10, config: Optional[EnhancedHybridConfig] = None) -> List[Dict[str, Any]]:
        """åŸ·è¡Œå¢å¼·ç‰ˆHybridRAGæª¢ç´¢ - æ”¯æŒmetadataå‘ä¸‹ç¹¼æ‰¿"""
        if not config:
            config = EnhancedHybridConfig()
        
        # 1. Metadataé—œéµå­—åŒ¹é…ï¼ˆå¯¦ç¾å‘ä¸‹ç¹¼æ‰¿ç­–ç•¥ï¼‰
        metadata_matched_articles = []
        if config.enable_inheritance_strategy:
            metadata_matched_articles = self._metadata_keyword_match(query)
            print(f"ğŸ” Metadataé—œéµå­—åŒ¹é…åˆ° {len(metadata_matched_articles)} å€‹æ¢å±¤ç´š")
        
        # 2. å‘é‡æª¢ç´¢
        vector_results = self._vector_retrieve(query, k * 3)  # ç²å–æ›´å¤šå€™é¸
        
        # 3. BM25é—œéµå­—æª¢ç´¢
        bm25_results = self._bm25_retrieve(query, k * 3)
        
        # 4. åˆä½µå€™é¸çµæœ
        candidate_nodes = self._merge_candidates(vector_results, bm25_results, k * 2)
        
        # 5. æ‡‰ç”¨metadataå‘ä¸‹ç¹¼æ‰¿ç­–ç•¥
        if config.enable_inheritance_strategy and metadata_matched_articles:
            candidate_nodes = self._apply_inheritance_strategy(candidate_nodes, metadata_matched_articles, query, config)
        
        # 6. è¨ˆç®—ç¶œåˆåˆ†æ•¸
        final_results = self._calculate_hybrid_scores(query, candidate_nodes, config)
        
        # 7. æ’åºä¸¦è¿”å›å‰kå€‹çµæœ
        final_results.sort(key=lambda x: x['hybrid_score'], reverse=True)
        
        return final_results[:k]
    
    def retrieve_multi_level(self, query: str, level_name: str, k: int = 10, 
                           config: Optional[EnhancedHybridConfig] = None) -> List[Dict[str, Any]]:
        """åŸ·è¡Œå¤šå±¤æ¬¡å¢å¼·ç‰ˆHybridRAGæª¢ç´¢"""
        if not config:
            config = EnhancedHybridConfig()
        
        # 1. å¤šå±¤æ¬¡å‘é‡æª¢ç´¢
        vector_results = self._multi_level_vector_retrieve(query, level_name, k * 3)
        
        # 2. å¤šå±¤æ¬¡BM25æª¢ç´¢
        bm25_results = self._multi_level_bm25_retrieve(query, level_name, k * 3)
        
        # 3. åˆä½µå€™é¸çµæœ
        candidate_nodes = self._merge_candidates(vector_results, bm25_results, k * 2)
        
        # 4. è¨ˆç®—ç¶œåˆåˆ†æ•¸
        final_results = self._calculate_hybrid_scores(query, candidate_nodes, config)
        
        # 5. æ’åºä¸¦è¿”å›å‰kå€‹çµæœ
        final_results.sort(key=lambda x: x['hybrid_score'], reverse=True)
        
        return final_results[:k]
    
    def _vector_retrieve(self, query: str, k: int) -> List[Dict[str, Any]]:
        """å‘é‡æª¢ç´¢"""
        if not self.faiss_store.has_vectors():
            return []
        
        # ç”ŸæˆæŸ¥è©¢å‘é‡ï¼ˆé€™è£¡éœ€è¦èª¿ç”¨embeddingå‡½æ•¸ï¼‰
        query_vector = self._get_query_vector(query)
        if not query_vector:
            return []
        
        # FAISSæœç´¢
        indices, scores = self.faiss_store.search(query_vector, k)
        
        results = []
        for idx, score in zip(indices, scores):
            chunk_info = self.faiss_store.get_chunk_by_index(idx)
            if chunk_info:
                results.append({
                    'chunk_id': chunk_info['chunk_id'],
                    'doc_id': chunk_info['doc_id'],
                    'content': chunk_info['content'],
                    'enhanced_metadata': chunk_info['enhanced_metadata'],
                    'vector_score': score,
                    'bm25_score': 0.0,
                    'chunk_index': idx
                })
        
        return results
    
    def _bm25_retrieve(self, query: str, k: int) -> List[Dict[str, Any]]:
        """BM25é—œéµå­—æª¢ç´¢"""
        if not self.bm25_index.has_index():
            return []
        
        # BM25æœç´¢
        indices, scores = self.bm25_index.search(query, k)
        
        results = []
        for idx, score in zip(indices, scores):
            chunk_info = self.bm25_index.get_chunk_by_index(idx)
            if chunk_info:
                results.append({
                    'chunk_id': chunk_info['chunk_id'],
                    'doc_id': chunk_info['doc_id'],
                    'content': chunk_info['content'],
                    'enhanced_metadata': {},  # BM25ç´¢å¼•ä¸åŒ…å«enhanced_metadata
                    'vector_score': 0.0,
                    'bm25_score': score,
                    'chunk_index': idx
                })
        
        return results
    
    def _multi_level_vector_retrieve(self, query: str, level_name: str, k: int) -> List[Dict[str, Any]]:
        """å¤šå±¤æ¬¡å‘é‡æª¢ç´¢"""
        if level_name not in self.faiss_store.get_available_levels():
            return []
        
        # ç”ŸæˆæŸ¥è©¢å‘é‡
        query_vector = self._get_query_vector(query)
        if not query_vector:
            return []
        
        # å¤šå±¤æ¬¡FAISSæœç´¢
        indices, scores = self.faiss_store.search_multi_level(level_name, query_vector, k)
        
        results = []
        for idx, score in zip(indices, scores):
            chunk_info = self.faiss_store.get_multi_level_chunk_by_index(level_name, idx)
            if chunk_info:
                results.append({
                    'chunk_id': chunk_info['chunk_id'],
                    'doc_id': chunk_info['doc_id'],
                    'content': chunk_info['content'],
                    'enhanced_metadata': chunk_info['enhanced_metadata'],
                    'vector_score': score,
                    'bm25_score': 0.0,
                    'chunk_index': idx,
                    'level': level_name
                })
        
        return results
    
    def _multi_level_bm25_retrieve(self, query: str, level_name: str, k: int) -> List[Dict[str, Any]]:
        """å¤šå±¤æ¬¡BM25æª¢ç´¢"""
        if level_name not in self.bm25_index.get_available_levels():
            return []
        
        # å¤šå±¤æ¬¡BM25æœç´¢
        indices, scores = self.bm25_index.search_multi_level(level_name, query, k)
        
        results = []
        for idx, score in zip(indices, scores):
            chunk_info = self.bm25_index.get_multi_level_chunk_by_index(level_name, idx)
            if chunk_info:
                results.append({
                    'chunk_id': chunk_info['chunk_id'],
                    'doc_id': chunk_info['doc_id'],
                    'content': chunk_info['content'],
                    'enhanced_metadata': {},
                    'vector_score': 0.0,
                    'bm25_score': score,
                    'chunk_index': idx,
                    'level': level_name
                })
        
        return results
    
    def _merge_candidates(self, vector_results: List[Dict[str, Any]], 
                         bm25_results: List[Dict[str, Any]], k: int) -> List[Dict[str, Any]]:
        """åˆä½µå€™é¸çµæœ"""
        # ä½¿ç”¨chunk_idä½œç‚ºå”¯ä¸€æ¨™è­˜ç¬¦
        merged = {}
        
        # æ·»åŠ å‘é‡æª¢ç´¢çµæœ
        for result in vector_results:
            chunk_id = result['chunk_id']
            merged[chunk_id] = result.copy()
        
        # åˆä½µBM25æª¢ç´¢çµæœ
        for result in bm25_results:
            chunk_id = result['chunk_id']
            if chunk_id in merged:
                # åˆä½µåˆ†æ•¸
                merged[chunk_id]['bm25_score'] = result['bm25_score']
                if not merged[chunk_id]['enhanced_metadata']:
                    merged[chunk_id]['enhanced_metadata'] = result['enhanced_metadata']
            else:
                merged[chunk_id] = result.copy()
        
        # è½‰æ›ç‚ºåˆ—è¡¨ä¸¦æ’åº
        candidate_list = list(merged.values())
        
        # æŒ‰ç¶œåˆåˆ†æ•¸æ’åºï¼ˆå‘é‡åˆ†æ•¸ + BM25åˆ†æ•¸ï¼‰
        candidate_list.sort(key=lambda x: x['vector_score'] + x['bm25_score'], reverse=True)
        
        return candidate_list[:k]
    
    def _calculate_hybrid_scores(self, query: str, candidates: List[Dict[str, Any]], 
                                config: EnhancedHybridConfig) -> List[Dict[str, Any]]:
        """è¨ˆç®—HybridRAGç¶œåˆåˆ†æ•¸"""
        query_features = self._extract_query_features(query)
        
        for candidate in candidates:
            # 1. æ¨™æº–åŒ–å‘é‡å’ŒBM25åˆ†æ•¸
            vector_score = self._normalize_score(candidate['vector_score'], 'vector')
            bm25_score = self._normalize_score(candidate['bm25_score'], 'bm25')
            
            # 2. è¨ˆç®—metadataåŠ åˆ†
            metadata_bonus = self._calculate_metadata_bonus(
                candidate['enhanced_metadata'], query_features, config
            )
            
            # 3. è¨ˆç®—æ¨™é¡Œå°ˆé–€è™•ç†åŠ åˆ†
            title_bonus = self._calculate_title_bonus(
                candidate['enhanced_metadata'], query, config
            )
            
            # 4. è¨ˆç®—ç¶œåˆåˆ†æ•¸
            hybrid_score = (
                config.vector_weight * vector_score +
                config.bm25_weight * bm25_score +
                config.metadata_weight * metadata_bonus +
                title_bonus
            )
            
            # 5. æ·»åŠ è©³ç´°åˆ†æ•¸åˆ†è§£
            candidate['hybrid_score'] = hybrid_score
            candidate['score_breakdown'] = {
                'vector_score': vector_score,
                'bm25_score': bm25_score,
                'metadata_bonus': metadata_bonus,
                'title_bonus': title_bonus,
                'final_score': hybrid_score
            }
        
        return candidates
    
    def _extract_query_features(self, query: str) -> Dict[str, Any]:
        """æå–æŸ¥è©¢ç‰¹å¾µ"""
        query_lower = query.lower()
        
        # æå–æ³•å
        law = ''
        if 'è‘—ä½œæ¬Šæ³•' in query:
            law = 'è‘—ä½œæ¬Šæ³•'
        elif 'å•†æ¨™æ³•' in query:
            law = 'å•†æ¨™æ³•'
        elif 'å°ˆåˆ©æ³•' in query:
            law = 'å°ˆåˆ©æ³•'
        
        # æå–æ¢è™Ÿ
        article_number, article_suffix = self._extract_article_number(query)
        
        # æå–æ³•å¾‹æ¦‚å¿µ
        concepts = []
        for canonical, variants in self.legal_synonyms.items():
            if any(v in query for v in variants):
                concepts.append(canonical)
        
        # æå–æŸ¥è©¢æ„åœ–
        intent_tags = []
        if any(word in query for word in ["ä»€éº¼æ˜¯", "å®šç¾©", "æ¬Šåˆ©", "ä»€éº¼æ¬Š"]):
            intent_tags.append("æ¬Šåˆ©æŸ¥è©¢")
        if any(word in query for word in ["å¿…é ˆ", "æ‡‰", "ä¸å¾—", "ç¦æ­¢", "ç¾©å‹™"]):
            intent_tags.append("ç¾©å‹™æŸ¥è©¢")
        if any(word in query for word in ["ä¾‹å¤–", "é™¤å¤–", "ä½†", "æƒŸ", "ä¸é©ç”¨"]):
            intent_tags.append("ä¾‹å¤–æŸ¥è©¢")
        if any(word in query for word in ["è™•ç½°", "é•å", "å¾Œæœ", "è²¬ä»»", "è³ å„Ÿ"]):
            intent_tags.append("å¾ŒæœæŸ¥è©¢")
        
        return {
            'law': law,
            'article_number': article_number,
            'article_suffix': article_suffix,
            'concepts': concepts,
            'intent_tags': intent_tags,
            'query_text': query
        }
    
    def _extract_article_number(self, text: str) -> Tuple[Optional[int], Optional[int]]:
        """æå–æ¢è™Ÿ"""
        # ç¬¬Xæ¢ä¹‹Y
        match = re.search(r"ç¬¬(\d+)æ¢ä¹‹(\d+)", text)
        if match:
            return int(match.group(1)), int(match.group(2))
        
        # ç¬¬Xæ¢
        match = re.search(r"ç¬¬(\d+)æ¢", text)
        if match:
            return int(match.group(1)), None
        
        return None, None
    
    def _calculate_metadata_bonus(self, metadata: Dict[str, Any], 
                                 query_features: Dict[str, Any], 
                                 config: EnhancedHybridConfig) -> float:
        """è¨ˆç®—metadataåŠ åˆ†"""
        bonus = 0.0
        
        # 1. æ³•ååŒ¹é…åŠ åˆ†
        if query_features['law'] and metadata.get('category') == query_features['law']:
            bonus += config.w_law_match
        
        # 2. æ¢è™ŸåŒ¹é…åŠ åˆ†
        if query_features['article_number'] and metadata.get('article_number') == query_features['article_number']:
            article_bonus = config.w_article_match
            if query_features['article_suffix'] and metadata.get('article_suffix') != query_features['article_suffix']:
                article_bonus *= 0.5
            bonus += article_bonus
        
        # 3. æ³•å¾‹æ¦‚å¿µåŒ¹é…åŠ åˆ†
        legal_concepts = metadata.get('legal_concepts', [])
        for concept in legal_concepts:
            concept_name = concept.get('concept_name', '')
            synonyms = concept.get('synonyms', [])
            importance = concept.get('importance_score', 0.5)
            
            if concept_name in query_features['query_text']:
                bonus += config.w_concept_match * importance
            elif any(syn in query_features['query_text'] for syn in synonyms):
                bonus += config.w_concept_match * importance * 0.7
        
        # 4. èªç¾©é—œéµè©åŒ¹é…åŠ åˆ†
        semantic_keywords = metadata.get('semantic_keywords', {})
        keyword_weights = semantic_keywords.get('keyword_weights', {})
        for keyword, weight in keyword_weights.items():
            if keyword in query_features['query_text']:
                bonus += config.w_keyword_hit * weight
        
        # 5. æ³•å¾‹é ˜åŸŸåŒ¹é…åŠ åˆ†
        legal_domain = metadata.get('legal_domain', {})
        domain_name = legal_domain.get('legal_domain', '')
        if domain_name in query_features['query_text']:
            bonus += config.w_domain_match
        
        # 6. æŸ¥è©¢æ„åœ–åŒ¹é…åŠ åˆ†
        intent_tags = metadata.get('query_intent_tags', [])
        if any(intent in intent_tags for intent in query_features['intent_tags']):
            bonus += config.w_keyword_hit * 0.5
        
        return min(bonus, config.max_bonus)
    
    def _calculate_title_bonus(self, metadata: Dict[str, Any], query: str, 
                              config: EnhancedHybridConfig) -> float:
        """è¨ˆç®—æ¨™é¡Œå°ˆé–€è™•ç†åŠ åˆ†"""
        bonus = 0.0
        
        # 1. æ¢æ–‡æ¨™é¡ŒåŒ¹é…
        article_label = metadata.get('article_label', '')
        if article_label and article_label in query:
            bonus += config.w_title_match * config.title_boost_factor
        
        # 2. ç« ç¯€æ¨™é¡ŒåŒ¹é…
        chapter = metadata.get('chapter', '')
        if chapter and any(word in query for word in chapter.split()):
            bonus += config.w_title_match * 0.5
        
        # 3. åˆ†é¡åŒ¹é…
        category = metadata.get('category', '')
        if category and category in query:
            bonus += config.w_category_match * config.category_boost_factor
        
        # 4. æ³•å¾‹åç¨±åŒ¹é…ï¼ˆæ¨™é¡Œå±¤é¢ï¼‰
        law_name = metadata.get('law_name', '')
        if law_name and law_name in query:
            bonus += config.w_category_match * 0.7
        
        return min(bonus, config.max_bonus)
    
    def _normalize_score(self, score: float, score_type: str) -> float:
        """æ¨™æº–åŒ–åˆ†æ•¸"""
        if score_type == 'vector':
            # å‘é‡ç›¸ä¼¼åº¦åˆ†æ•¸é€šå¸¸åœ¨0-1ä¹‹é–“
            return max(0.0, min(1.0, score))
        elif score_type == 'bm25':
            # BM25åˆ†æ•¸éœ€è¦æ¨™æº–åŒ–ï¼Œé€šå¸¸ä½¿ç”¨sigmoidå‡½æ•¸
            import math
            return 1.0 / (1.0 + math.exp(-score))
        else:
            return max(0.0, min(1.0, score))
    
    def _get_query_vector(self, query: str) -> Optional[List[float]]:
        """ç²å–æŸ¥è©¢å‘é‡"""
        # é€™è£¡éœ€è¦èª¿ç”¨embeddingå‡½æ•¸
        # å¯¦éš›å¯¦ç¾æ™‚éœ€è¦èª¿ç”¨embed_geminiæˆ–embed_bge_m3
        # æš«æ™‚è¿”å›Noneï¼Œéœ€è¦åœ¨main.pyä¸­å¯¦ç¾å…·é«”çš„embeddingèª¿ç”¨
        return None
    
    def _metadata_keyword_match(self, query: str) -> List[str]:
        """é€šémetadataé—œéµå­—åŒ¹é…æ‰¾åˆ°ç›¸é—œçš„æ¢å±¤ç´š"""
        matched_articles = []
        
        # ç²å–æ‰€æœ‰æ¢å±¤ç´šçš„metadata
        article_metadata_map = self.metadata_enhancer.get_article_metadata_map()
        
        # æå–æŸ¥è©¢é—œéµè©
        query_keywords = self._extract_query_keywords(query)
        
        for article_id, metadata in article_metadata_map.items():
            match_score = self._calculate_metadata_match_score(query_keywords, metadata)
            
            # å¦‚æœåŒ¹é…åˆ†æ•¸è¶…éé–¾å€¼ï¼Œå‰‡èªç‚ºåŒ¹é…
            if match_score > 0.3:  # ä½¿ç”¨é…ç½®ä¸­çš„é–¾å€¼
                matched_articles.append(article_id)
                print(f"ğŸ“‹ æ¢å±¤ç´š {article_id} åŒ¹é…åˆ†æ•¸: {match_score:.3f}")
        
        return matched_articles
    
    def _extract_query_keywords(self, query: str) -> List[str]:
        """æå–æŸ¥è©¢ä¸­çš„é—œéµè©"""
        keywords = []
        
        # ä½¿ç”¨jiebaåˆ†è©
        if jieba:
            words = jieba.analyse.extract_tags(query, topK=10, withWeight=False)
            keywords.extend(words)
        
        # æ·»åŠ æ³•å¾‹åŒç¾©è©åŒ¹é…
        query_lower = query.lower()
        for canonical, variants in self.legal_synonyms.items():
            if any(variant in query_lower for variant in variants):
                keywords.append(canonical)
        
        return keywords
    
    def _calculate_metadata_match_score(self, query_keywords: List[str], metadata: Dict[str, Any]) -> float:
        """è¨ˆç®—æŸ¥è©¢é—œéµè©èˆ‡metadataçš„åŒ¹é…åˆ†æ•¸"""
        total_score = 0.0
        matched_fields = 0
        
        # 1. æª¢æŸ¥æ³•å¾‹æ¦‚å¿µåŒ¹é…
        legal_concepts = metadata.get("legal_concepts", [])
        for concept in legal_concepts:
            concept_name = concept.get("concept_name", "")
            concept_synonyms = concept.get("synonyms", [])
            importance = concept.get("importance_score", 0.5)
            
            if any(kw in concept_name for kw in query_keywords):
                total_score += importance * 0.3
                matched_fields += 1
            elif any(kw in syn for kw in query_keywords for syn in concept_synonyms):
                total_score += importance * 0.2
                matched_fields += 1
        
        # 2. æª¢æŸ¥èªç¾©é—œéµè©åŒ¹é…
        semantic_keywords = metadata.get("semantic_keywords", {})
        keyword_weights = semantic_keywords.get("keyword_weights", {})
        
        for keyword, weight in keyword_weights.items():
            if any(kw in keyword for kw in query_keywords):
                total_score += weight * 0.2
                matched_fields += 1
        
        # 3. æª¢æŸ¥æ³•å¾‹é ˜åŸŸåŒ¹é…
        legal_domain = metadata.get("legal_domain", {})
        domain_name = legal_domain.get("legal_domain", "")
        
        if any(kw in domain_name for kw in query_keywords):
            total_score += 0.2
            matched_fields += 1
        
        # 4. æª¢æŸ¥æŸ¥è©¢æ„åœ–åŒ¹é…
        query_intent_tags = metadata.get("query_intent_tags", [])
        for intent_tag in query_intent_tags:
            if any(kw in intent_tag for kw in query_keywords):
                total_score += 0.1
                matched_fields += 1
        
        # æ­£è¦åŒ–åˆ†æ•¸
        if matched_fields > 0:
            return min(total_score, 1.0)
        
        return 0.0
    
    def _apply_inheritance_strategy(self, candidate_nodes: List[Dict[str, Any]], 
                                   matched_articles: List[str], query: str, config: EnhancedHybridConfig) -> List[Dict[str, Any]]:
        """æ‡‰ç”¨metadataå‘ä¸‹ç¹¼æ‰¿ç­–ç•¥"""
        # ç²å–ç¹¼æ‰¿é—œä¿‚æ˜ å°„
        inheritance_hierarchy = self.metadata_enhancer.get_inheritance_hierarchy()
        
        # æ‰¾åˆ°åŒ¹é…æ¢å±¤ç´šçš„æ‰€æœ‰å­chunks
        inherited_candidates = []
        
        for article_id in matched_articles:
            # æ‰¾åˆ°è©²æ¢å±¤ç´šçš„æ‰€æœ‰å­chunks
            child_chunks = []
            for child_chunk_id, parent_article_id in inheritance_hierarchy.items():
                if parent_article_id == article_id:
                    child_chunks.append(child_chunk_id)
            
            print(f"ğŸ“‹ æ¢å±¤ç´š {article_id} æœ‰ {len(child_chunks)} å€‹å­chunks")
            
            # ç‚ºæ¯å€‹å­chunkå‰µå»ºå€™é¸ç¯€é»
            for child_chunk_id in child_chunks:
                # å¾FAISSæˆ–BM25ç²å–chunkä¿¡æ¯
                chunk_info = self._get_chunk_info_by_id(child_chunk_id)
                if chunk_info:
                    # æ·»åŠ ç¹¼æ‰¿æ¨™è¨˜å’Œé¡å¤–åŠ åˆ†
                    chunk_info["inherited_from"] = article_id
                    chunk_info["inheritance_bonus"] = config.inheritance_bonus  # ä½¿ç”¨é…ç½®ä¸­çš„ç¹¼æ‰¿åŠ åˆ†
                    chunk_info["inheritance_boost_factor"] = config.inheritance_boost_factor
                    chunk_info["metadata_match_reason"] = f"ç¹¼æ‰¿è‡ªæ¢å±¤ç´š {article_id}"
                    
                    inherited_candidates.append(chunk_info)
        
        # åˆä½µåŸæœ‰å€™é¸å’Œç¹¼æ‰¿å€™é¸
        all_candidates = candidate_nodes + inherited_candidates
        
        print(f"ğŸ”„ æ‡‰ç”¨ç¹¼æ‰¿ç­–ç•¥ï¼šåŸæœ‰å€™é¸ {len(candidate_nodes)} + ç¹¼æ‰¿å€™é¸ {len(inherited_candidates)} = ç¸½è¨ˆ {len(all_candidates)}")
        
        return all_candidates
    
    def _get_chunk_info_by_id(self, chunk_id: str) -> Optional[Dict[str, Any]]:
        """æ ¹æ“šchunk_idç²å–chunkä¿¡æ¯"""
        # å˜—è©¦å¾FAISSç²å–
        if self.faiss_store.has_vectors():
            # é€™è£¡éœ€è¦å¯¦ç¾æ ¹æ“šchunk_idæŸ¥æ‰¾çš„é‚è¼¯
            # æš«æ™‚è¿”å›Noneï¼Œå¯¦éš›å¯¦ç¾æ™‚éœ€è¦ç¶­è­·chunk_idåˆ°indexçš„æ˜ å°„
            pass
        
        # å˜—è©¦å¾BM25ç²å–
        if self.bm25_index.has_index():
            # åŒæ¨£éœ€è¦å¯¦ç¾chunk_idæŸ¥æ‰¾é‚è¼¯
            pass
        
        return None
    
    def get_retrieval_stats(self) -> Dict[str, Any]:
        """ç²å–æª¢ç´¢çµ±è¨ˆä¿¡æ¯"""
        stats = {
            "faiss_stats": self.faiss_store.get_stats(),
            "bm25_stats": self.bm25_index.get_stats(),
            "metadata_stats": self.metadata_enhancer.get_enhancement_stats()
        }
        
        # æ·»åŠ ç¹¼æ‰¿ç›¸é—œçµ±è¨ˆ
        article_metadata_map = self.metadata_enhancer.get_article_metadata_map()
        inheritance_hierarchy = self.metadata_enhancer.get_inheritance_hierarchy()
        
        stats["inheritance_stats"] = {
            "total_articles": len(article_metadata_map),
            "total_inheritance_relations": len(inheritance_hierarchy),
            "avg_children_per_article": len(inheritance_hierarchy) / max(len(article_metadata_map), 1)
        }
        
        return stats
