"""
å‹•æ…‹æ¦‚å¿µå­¸ç¿’ç³»çµ± - è‡ªå‹•å­¸ç¿’æ–°çš„æ³•å¾‹æ¦‚å¿µå’Œé—œä¿‚
"""

import json
import re
from typing import Dict, List, Any, Set, Tuple
from dataclasses import dataclass, asdict
from collections import defaultdict, Counter
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import jieba


@dataclass
class LearningPattern:
    """å­¸ç¿’æ¨¡å¼"""
    pattern_id: str
    pattern_type: str  # æ¦‚å¿µæå–ã€é—œä¿‚è­˜åˆ¥ã€æ¨ç†è¦å‰‡ç­‰
    pattern_regex: str
    confidence_threshold: float
    success_count: int = 0
    failure_count: int = 0
    last_updated: str = ""


@dataclass
class LearnedConcept:
    """å­¸ç¿’åˆ°çš„æ¦‚å¿µ"""
    concept_id: str
    concept_name: str
    concept_type: str
    legal_domain: str
    source_queries: List[str]  # ä¾†æºæŸ¥è©¢
    related_articles: List[str]
    confidence: float
    learning_method: str  # è‡ªå‹•å­¸ç¿’ã€äººå·¥é©—è­‰ç­‰
    created_at: str
    updated_at: str


@dataclass
class LearnedRelation:
    """å­¸ç¿’åˆ°çš„é—œä¿‚"""
    relation_id: str
    source_concept: str
    target_concept: str
    relation_type: str
    confidence: float
    evidence_queries: List[str]
    learning_method: str
    created_at: str


class DynamicConceptLearningSystem:
    """å‹•æ…‹æ¦‚å¿µå­¸ç¿’ç³»çµ±"""
    
    def __init__(self):
        self.learning_patterns = self._initialize_learning_patterns()
        self.learned_concepts = {}
        self.learned_relations = []
        self.query_history = []
        self.feedback_history = []
        self.concept_similarity_matrix = None
        
    def _initialize_learning_patterns(self) -> List[LearningPattern]:
        """åˆå§‹åŒ–å­¸ç¿’æ¨¡å¼"""
        return [
            # æ¦‚å¿µæå–æ¨¡å¼
            LearningPattern(
                pattern_id="concept_extraction_1",
                pattern_type="æ¦‚å¿µæå–",
                pattern_regex=r"([^ï¼Œã€‚ï¼›ï¼šï¼ï¼Ÿ]+)(?:å±¬æ–¼|æ˜¯|ç‚º)([^ï¼Œã€‚ï¼›ï¼šï¼ï¼Ÿ]*)(?:çš„ä¸€ç¨®|é¡å‹|æ¦‚å¿µ)",
                confidence_threshold=0.7
            ),
            LearningPattern(
                pattern_id="concept_extraction_2",
                pattern_type="æ¦‚å¿µæå–",
                pattern_regex=r"([^ï¼Œã€‚ï¼›ï¼šï¼ï¼Ÿ]+)(?:åŒ…æ‹¬|å«|æ¶µè“‹)([^ï¼Œã€‚ï¼›ï¼šï¼ï¼Ÿ]*)",
                confidence_threshold=0.6
            ),
            
            # é—œä¿‚è­˜åˆ¥æ¨¡å¼
            LearningPattern(
                pattern_id="relation_identification_1",
                pattern_type="é—œä¿‚è­˜åˆ¥",
                pattern_regex=r"([^ï¼Œã€‚ï¼›ï¼šï¼ï¼Ÿ]+)(?:éœ€è¦|å¿…é ˆ|æ‡‰)([^ï¼Œã€‚ï¼›ï¼šï¼ï¼Ÿ]*)",
                confidence_threshold=0.8
            ),
            LearningPattern(
                pattern_id="relation_identification_2",
                pattern_type="é—œä¿‚è­˜åˆ¥",
                pattern_regex=r"([^ï¼Œã€‚ï¼›ï¼šï¼ï¼Ÿ]+)(?:é©ç”¨æ–¼|é©ç”¨)([^ï¼Œã€‚ï¼›ï¼šï¼ï¼Ÿ]*)",
                confidence_threshold=0.7
            ),
            
            # æ¨ç†è¦å‰‡æ¨¡å¼
            LearningPattern(
                pattern_id="reasoning_rule_1",
                pattern_type="æ¨ç†è¦å‰‡",
                pattern_regex=r"([^ï¼Œã€‚ï¼›ï¼šï¼ï¼Ÿ]+)(?:ç­‰åŒæ–¼|ç›¸ç•¶æ–¼|ç­‰åŒ)([^ï¼Œã€‚ï¼›ï¼šï¼ï¼Ÿ]*)",
                confidence_threshold=0.9
            )
        ]
    
    def learn_from_query_feedback(self, query: str, retrieved_results: List[Dict], 
                                user_feedback: Dict[str, Any]) -> Dict[str, Any]:
        """å¾æŸ¥è©¢åé¥‹ä¸­å­¸ç¿’"""
        learning_result = {
            "new_concepts": [],
            "new_relations": [],
            "updated_patterns": [],
            "learning_insights": []
        }
        
        print(f"ğŸ§  é–‹å§‹å¾æŸ¥è©¢åé¥‹ä¸­å­¸ç¿’: '{query}'")
        
        # è¨˜éŒ„æŸ¥è©¢æ­·å²
        self.query_history.append({
            "query": query,
            "results": retrieved_results,
            "feedback": user_feedback,
            "timestamp": self._get_current_timestamp()
        })
        
        # åˆ†æç”¨æˆ¶åé¥‹
        if user_feedback.get("relevant_results"):
            self._learn_from_relevant_results(query, user_feedback["relevant_results"], learning_result)
        
        if user_feedback.get("missing_concepts"):
            self._learn_missing_concepts(query, user_feedback["missing_concepts"], learning_result)
        
        if user_feedback.get("concept_mappings"):
            self._learn_concept_mappings(query, user_feedback["concept_mappings"], learning_result)
        
        # æ›´æ–°å­¸ç¿’æ¨¡å¼
        self._update_learning_patterns(query, retrieved_results, user_feedback, learning_result)
        
        # ç”Ÿæˆå­¸ç¿’æ´å¯Ÿ
        self._generate_learning_insights(learning_result)
        
        print(f"âœ… å­¸ç¿’å®Œæˆ: {len(learning_result['new_concepts'])}å€‹æ–°æ¦‚å¿µ, {len(learning_result['new_relations'])}å€‹æ–°é—œä¿‚")
        
        return learning_result
    
    def _learn_from_relevant_results(self, query: str, relevant_results: List[Dict], 
                                   learning_result: Dict[str, Any]):
        """å¾ç›¸é—œçµæœä¸­å­¸ç¿’"""
        for result in relevant_results:
            content = result.get('content', '')
            
            # æå–æ–°çš„æ³•å¾‹æ¦‚å¿µ
            new_concepts = self._extract_concepts_from_content(content, query)
            learning_result["new_concepts"].extend(new_concepts)
            
            # æå–æ¦‚å¿µé—œä¿‚
            new_relations = self._extract_relations_from_content(content, query)
            learning_result["new_relations"].extend(new_relations)
    
    def _learn_missing_concepts(self, query: str, missing_concepts: List[str], 
                              learning_result: Dict[str, Any]):
        """å­¸ç¿’ç¼ºå¤±çš„æ¦‚å¿µ"""
        for concept_name in missing_concepts:
            # åˆ†ææ¦‚å¿µèˆ‡æŸ¥è©¢çš„é—œä¿‚
            concept_info = self._analyze_missing_concept(query, concept_name)
            
            if concept_info:
                learned_concept = LearnedConcept(
                    concept_id=f"learned_{concept_name}_{len(self.learned_concepts)}",
                    concept_name=concept_name,
                    concept_type=concept_info.get("type", "æœªçŸ¥"),
                    legal_domain=concept_info.get("domain", "å…¶ä»–"),
                    source_queries=[query],
                    related_articles=concept_info.get("articles", []),
                    confidence=concept_info.get("confidence", 0.5),
                    learning_method="ç¼ºå¤±æ¦‚å¿µå­¸ç¿’",
                    created_at=self._get_current_timestamp(),
                    updated_at=self._get_current_timestamp()
                )
                
                self.learned_concepts[learned_concept.concept_id] = learned_concept
                learning_result["new_concepts"].append(asdict(learned_concept))
    
    def _learn_concept_mappings(self, query: str, concept_mappings: List[Dict], 
                              learning_result: Dict[str, Any]):
        """å­¸ç¿’æ¦‚å¿µæ˜ å°„"""
        for mapping in concept_mappings:
            source_term = mapping.get("source")
            target_concept = mapping.get("target")
            confidence = mapping.get("confidence", 0.8)
            
            if source_term and target_concept:
                # å‰µå»ºæ–°çš„æ¨ç†è¦å‰‡
                new_relation = LearnedRelation(
                    relation_id=f"mapping_{source_term}_{target_concept}_{len(self.learned_relations)}",
                    source_concept=source_term,
                    target_concept=target_concept,
                    relation_type="æ¦‚å¿µæ˜ å°„",
                    confidence=confidence,
                    evidence_queries=[query],
                    learning_method="ç”¨æˆ¶åé¥‹å­¸ç¿’",
                    created_at=self._get_current_timestamp()
                )
                
                self.learned_relations.append(new_relation)
                learning_result["new_relations"].append(asdict(new_relation))
    
    def _extract_concepts_from_content(self, content: str, query: str) -> List[Dict[str, Any]]:
        """å¾å…§å®¹ä¸­æå–æ¦‚å¿µ"""
        concepts = []
        
        # ä½¿ç”¨å­¸ç¿’æ¨¡å¼æå–æ¦‚å¿µ
        for pattern in self.learning_patterns:
            if pattern.pattern_type == "æ¦‚å¿µæå–":
                matches = re.finditer(pattern.pattern_regex, content)
                
                for match in matches:
                    concept_name = match.group(1).strip()
                    concept_description = match.group(2).strip() if len(match.groups()) > 1 else ""
                    
                    if concept_name and len(concept_name) > 1:
                        concept = {
                            "concept_name": concept_name,
                            "concept_description": concept_description,
                            "source_content": content[:200],
                            "source_query": query,
                            "learning_pattern": pattern.pattern_id,
                            "confidence": pattern.confidence_threshold
                        }
                        concepts.append(concept)
        
        return concepts
    
    def _extract_relations_from_content(self, content: str, query: str) -> List[Dict[str, Any]]:
        """å¾å…§å®¹ä¸­æå–é—œä¿‚"""
        relations = []
        
        for pattern in self.learning_patterns:
            if pattern.pattern_type == "é—œä¿‚è­˜åˆ¥":
                matches = re.finditer(pattern.pattern_regex, content)
                
                for match in matches:
                    if len(match.groups()) >= 2:
                        source = match.group(1).strip()
                        target = match.group(2).strip()
                        
                        if source and target:
                            relation = {
                                "source_concept": source,
                                "target_concept": target,
                                "relation_type": "å­¸ç¿’é—œä¿‚",
                                "source_content": content[:200],
                                "source_query": query,
                                "learning_pattern": pattern.pattern_id,
                                "confidence": pattern.confidence_threshold
                            }
                            relations.append(relation)
        
        return relations
    
    def _analyze_missing_concept(self, query: str, concept_name: str) -> Dict[str, Any]:
        """åˆ†æç¼ºå¤±çš„æ¦‚å¿µ"""
        analysis = {
            "type": "æœªçŸ¥",
            "domain": "å…¶ä»–",
            "articles": [],
            "confidence": 0.5
        }
        
        # åŸºæ–¼æŸ¥è©¢ä¸Šä¸‹æ–‡æ¨æ–·æ¦‚å¿µé¡å‹
        query_lower = query.lower()
        concept_lower = concept_name.lower()
        
        # åˆ¤æ–·æ³•å¾‹é ˜åŸŸ
        if any(keyword in query_lower for keyword in ["è‘—ä½œæ¬Š", "ç‰ˆæ¬Š", "é‡è£½", "æ”¹ä½œ"]):
            analysis["domain"] = "è‘—ä½œæ¬Š"
        elif any(keyword in query_lower for keyword in ["å•†æ¨™", "è¨»å†Š", "ä½¿ç”¨"]):
            analysis["domain"] = "å•†æ¨™æ¬Š"
        elif any(keyword in query_lower for keyword in ["å°ˆåˆ©", "ç™¼æ˜", "æŠ€è¡“"]):
            analysis["domain"] = "å°ˆåˆ©æ¬Š"
        
        # åˆ¤æ–·æ¦‚å¿µé¡å‹
        if any(keyword in concept_lower for keyword in ["æ¬Š", "æ¬Šåˆ©"]):
            analysis["type"] = "æ¬Šåˆ©"
        elif any(keyword in concept_lower for keyword in ["ç¾©å‹™", "è²¬ä»»", "æ‡‰", "å¿…é ˆ"]):
            analysis["type"] = "ç¾©å‹™"
        elif any(keyword in concept_lower for keyword in ["ä¾‹å¤–", "ä½†", "é™¤å¤–"]):
            analysis["type"] = "ä¾‹å¤–"
        
        # æå–å¯èƒ½çš„æ¢æ–‡
        article_matches = re.findall(r'ç¬¬(\d+(?:-\d+)?)æ¢', query)
        analysis["articles"] = [f"ç¬¬{art}æ¢" for art in article_matches]
        
        return analysis
    
    def _update_learning_patterns(self, query: str, results: List[Dict], 
                                feedback: Dict[str, Any], learning_result: Dict[str, Any]):
        """æ›´æ–°å­¸ç¿’æ¨¡å¼"""
        updated_patterns = []
        
        # åˆ†ææˆåŠŸçš„æ¨¡å¼
        if feedback.get("successful_patterns"):
            for pattern_id in feedback["successful_patterns"]:
                pattern = next((p for p in self.learning_patterns if p.pattern_id == pattern_id), None)
                if pattern:
                    pattern.success_count += 1
                    pattern.last_updated = self._get_current_timestamp()
                    updated_patterns.append({
                        "pattern_id": pattern_id,
                        "action": "success",
                        "new_confidence": min(1.0, pattern.confidence_threshold + 0.05)
                    })
        
        # åˆ†æå¤±æ•—çš„æ¨¡å¼
        if feedback.get("failed_patterns"):
            for pattern_id in feedback["failed_patterns"]:
                pattern = next((p for p in self.learning_patterns if p.pattern_id == pattern_id), None)
                if pattern:
                    pattern.failure_count += 1
                    pattern.last_updated = self._get_current_timestamp()
                    updated_patterns.append({
                        "pattern_id": pattern_id,
                        "action": "failure",
                        "new_confidence": max(0.1, pattern.confidence_threshold - 0.05)
                    })
        
        learning_result["updated_patterns"] = updated_patterns
    
    def _generate_learning_insights(self, learning_result: Dict[str, Any]):
        """ç”Ÿæˆå­¸ç¿’æ´å¯Ÿ"""
        insights = []
        
        # åˆ†ææ–°æ¦‚å¿µçš„ç‰¹å¾µ
        if learning_result["new_concepts"]:
            concepts_by_domain = defaultdict(int)
            concepts_by_type = defaultdict(int)
            
            for concept in learning_result["new_concepts"]:
                domain = concept.get("legal_domain", "å…¶ä»–")
                concept_type = concept.get("concept_type", "æœªçŸ¥")
                concepts_by_domain[domain] += 1
                concepts_by_type[concept_type] += 1
            
            insights.append({
                "type": "æ¦‚å¿µåˆ†å¸ƒ",
                "message": f"æ–°å­¸ç¿’åˆ°{len(learning_result['new_concepts'])}å€‹æ¦‚å¿µ",
                "details": {
                    "domain_distribution": dict(concepts_by_domain),
                    "type_distribution": dict(concepts_by_type)
                }
            })
        
        # åˆ†æå­¸ç¿’æ¨¡å¼çš„æ•ˆæœ
        if learning_result["updated_patterns"]:
            successful_updates = len([p for p in learning_result["updated_patterns"] if p["action"] == "success"])
            failed_updates = len([p for p in learning_result["updated_patterns"] if p["action"] == "failure"])
            
            insights.append({
                "type": "æ¨¡å¼æ•ˆæœ",
                "message": f"æ›´æ–°äº†{len(learning_result['updated_patterns'])}å€‹å­¸ç¿’æ¨¡å¼",
                "details": {
                    "successful_updates": successful_updates,
                    "failed_updates": failed_updates,
                    "success_rate": successful_updates / (successful_updates + failed_updates) if (successful_updates + failed_updates) > 0 else 0
                }
            })
        
        learning_result["learning_insights"] = insights
    
    def generate_enhanced_query_expansion(self, query: str) -> Dict[str, Any]:
        """ç”Ÿæˆå¢å¼·çš„æŸ¥è©¢æ“´å±•"""
        expansion = {
            "original_query": query,
            "expanded_query": query,
            "learned_concepts": [],
            "learned_relations": [],
            "confidence_boost": 0.0
        }
        
        # æŸ¥æ‰¾å­¸ç¿’åˆ°çš„æ¦‚å¿µ
        query_lower = query.lower()
        for concept_id, concept in self.learned_concepts.items():
            if concept.concept_name.lower() in query_lower:
                expansion["learned_concepts"].append(asdict(concept))
                expansion["expanded_query"] += f" {concept.concept_name}"
                expansion["confidence_boost"] += concept.confidence * 0.1
        
        # æŸ¥æ‰¾å­¸ç¿’åˆ°çš„é—œä¿‚
        for relation in self.learned_relations:
            if relation.source_concept.lower() in query_lower:
                expansion["learned_relations"].append(asdict(relation))
                expansion["expanded_query"] += f" {relation.target_concept}"
                expansion["confidence_boost"] += relation.confidence * 0.05
        
        return expansion
    
    def get_learning_statistics(self) -> Dict[str, Any]:
        """ç²å–å­¸ç¿’çµ±è¨ˆ"""
        return {
            "total_learned_concepts": len(self.learned_concepts),
            "total_learned_relations": len(self.learned_relations),
            "total_queries_processed": len(self.query_history),
            "learning_patterns": {
                "total_patterns": len(self.learning_patterns),
                "successful_patterns": len([p for p in self.learning_patterns if p.success_count > p.failure_count]),
                "pattern_success_rate": self._calculate_pattern_success_rate()
            },
            "concept_distribution": self._get_concept_distribution(),
            "recent_learning_activity": self._get_recent_learning_activity()
        }
    
    def _calculate_pattern_success_rate(self) -> float:
        """è¨ˆç®—æ¨¡å¼æˆåŠŸç‡"""
        if not self.learning_patterns:
            return 0.0
        
        total_success = sum(p.success_count for p in self.learning_patterns)
        total_attempts = sum(p.success_count + p.failure_count for p in self.learning_patterns)
        
        return total_success / total_attempts if total_attempts > 0 else 0.0
    
    def _get_concept_distribution(self) -> Dict[str, int]:
        """ç²å–æ¦‚å¿µåˆ†å¸ƒ"""
        domain_counts = defaultdict(int)
        type_counts = defaultdict(int)
        
        for concept in self.learned_concepts.values():
            domain_counts[concept.legal_domain] += 1
            type_counts[concept.concept_type] += 1
        
        return {
            "by_domain": dict(domain_counts),
            "by_type": dict(type_counts)
        }
    
    def _get_recent_learning_activity(self) -> List[Dict[str, Any]]:
        """ç²å–æœ€è¿‘çš„å­¸ç¿’æ´»å‹•"""
        recent_queries = self.query_history[-10:] if self.query_history else []
        
        activity = []
        for query_info in recent_queries:
            activity.append({
                "query": query_info["query"],
                "timestamp": query_info["timestamp"],
                "has_feedback": bool(query_info.get("feedback")),
                "result_count": len(query_info.get("results", []))
            })
        
        return activity
    
    def _get_current_timestamp(self) -> str:
        """ç²å–ç•¶å‰æ™‚é–“æˆ³"""
        import datetime
        return datetime.datetime.now().isoformat()


# å…¨å±€å­¸ç¿’ç³»çµ±å¯¦ä¾‹
dynamic_learning_system = DynamicConceptLearningSystem()
