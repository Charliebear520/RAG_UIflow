"""
Structured-HopRAG å¤šå±‚æ¬¡åµŒå…¥æ¨¡å—
å®ç°åŸºäºaboutness scoreçš„åŠ æƒèšåˆ
"""

import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass

from .structured_hoprag_config import (
    StructuredHopRAGConfig, 
    LegalLevel,
    AboutnessWeights,
    DEFAULT_CONFIG
)

@dataclass
class MultiLevelNode:
    """å¤šå±‚æ¬¡èŠ‚ç‚¹æ•°æ®ç»“æ„"""
    node_id: str
    level: str  # LegalLevelæšä¸¾å€¼
    content: str
    
    # åµŒå…¥å‘é‡
    direct_embedding: Optional[np.ndarray] = None  # ç›´æ¥åµŒå…¥ï¼ˆå¶èŠ‚ç‚¹ï¼‰
    aggregated_embedding: Optional[np.ndarray] = None  # èšåˆåµŒå…¥ï¼ˆçˆ¶èŠ‚ç‚¹ï¼‰
    final_embedding: Optional[np.ndarray] = None  # æœ€ç»ˆä½¿ç”¨çš„åµŒå…¥
    
    # å±‚çº§å…³ç³»
    parent_id: Optional[str] = None
    children_ids: List[str] = None
    
    # Aboutnessç›¸å…³
    aboutness_score: float = 0.0  # ç›¸å¯¹äºçˆ¶èŠ‚ç‚¹çš„aboutness
    aboutness_weights: Dict[str, float] = None  # å­èŠ‚ç‚¹çš„aboutnessæƒé‡
    
    # å…ƒæ•°æ®
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.children_ids is None:
            self.children_ids = []
        if self.aboutness_weights is None:
            self.aboutness_weights = {}
        if self.metadata is None:
            self.metadata = {}

class MultiLevelEmbedding:
    """å¤šå±‚æ¬¡åµŒå…¥ç”Ÿæˆå™¨"""
    
    def __init__(self, embedding_model, config: StructuredHopRAGConfig = DEFAULT_CONFIG):
        self.embedding_model = embedding_model
        self.config = config
        self.aboutness_weights = config.aboutness_weights
        
    def compute_multi_level_embeddings(
        self, 
        nodes: Dict[str, MultiLevelNode]
    ) -> Dict[str, MultiLevelNode]:
        """
        è®¡ç®—æ‰€æœ‰èŠ‚ç‚¹çš„å¤šå±‚æ¬¡åµŒå…¥
        
        ç­–ç•¥ï¼š
        1. å¶èŠ‚ç‚¹ï¼šç›´æ¥åµŒå…¥
        2. çˆ¶èŠ‚ç‚¹ï¼šåŠ æƒèšåˆå­èŠ‚ç‚¹åµŒå…¥
        """
        print("ğŸ”® å¼€å§‹è®¡ç®—å¤šå±‚æ¬¡åµŒå…¥...")
        
        # Step 1: è¯†åˆ«å¶èŠ‚ç‚¹å’Œçˆ¶èŠ‚ç‚¹
        leaf_nodes, parent_nodes = self._classify_nodes(nodes)
        
        # Step 2: ä¸ºå¶èŠ‚ç‚¹ç”Ÿæˆç›´æ¥åµŒå…¥
        self._compute_direct_embeddings(leaf_nodes)
        
        # Step 3: è‡ªåº•å‘ä¸Šèšåˆçˆ¶èŠ‚ç‚¹åµŒå…¥
        self._compute_aggregated_embeddings(parent_nodes, nodes)
        
        # Step 4: è®¾ç½®final_embedding
        for node in nodes.values():
            if node.aggregated_embedding is not None:
                node.final_embedding = node.aggregated_embedding
            else:
                node.final_embedding = node.direct_embedding
        
        print(f"âœ… å¤šå±‚æ¬¡åµŒå…¥è®¡ç®—å®Œæˆï¼Œå…± {len(nodes)} ä¸ªèŠ‚ç‚¹")
        return nodes
    
    def _classify_nodes(
        self, 
        nodes: Dict[str, MultiLevelNode]
    ) -> Tuple[List[MultiLevelNode], List[MultiLevelNode]]:
        """åˆ†ç±»å¶èŠ‚ç‚¹å’Œçˆ¶èŠ‚ç‚¹"""
        leaf_nodes = []
        parent_nodes = []
        
        for node in nodes.values():
            if not node.children_ids or len(node.children_ids) == 0:
                leaf_nodes.append(node)
            else:
                parent_nodes.append(node)
        
        # æŒ‰å±‚çº§æ’åºçˆ¶èŠ‚ç‚¹ï¼ˆä»ä½åˆ°é«˜ï¼Œä»¥ä¾¿è‡ªåº•å‘ä¸Šèšåˆï¼‰
        hierarchy = LegalLevel.get_hierarchy()
        parent_nodes.sort(
            key=lambda n: hierarchy.index(n.level) if n.level in hierarchy else 99,
            reverse=True  # ä»ä½å±‚åˆ°é«˜å±‚
        )
        
        print(f"  å¶èŠ‚ç‚¹: {len(leaf_nodes)}, çˆ¶èŠ‚ç‚¹: {len(parent_nodes)}")
        return leaf_nodes, parent_nodes
    
    def _compute_direct_embeddings(self, leaf_nodes: List[MultiLevelNode]):
        """ä¸ºå¶èŠ‚ç‚¹è®¡ç®—ç›´æ¥åµŒå…¥"""
        print("  ğŸ“ è®¡ç®—å¶èŠ‚ç‚¹ç›´æ¥åµŒå…¥...")
        
        # æ‰¹é‡ç¼–ç 
        contents = [node.content for node in leaf_nodes]
        
        if hasattr(self.embedding_model, 'encode'):
            embeddings = self.embedding_model.encode(contents)
        else:
            # å¼‚æ­¥æ–¹æ³•éœ€è¦åœ¨å¤–éƒ¨å¤„ç†
            embeddings = self.embedding_model.encode(contents)
        
        # åˆ†é…åµŒå…¥å‘é‡
        for i, node in enumerate(leaf_nodes):
            node.direct_embedding = embeddings[i]
            # å¶èŠ‚ç‚¹çš„aboutnessé»˜è®¤ä¸ºæœ€å¤§å€¼
            node.aboutness_score = self.aboutness_weights.get_weight(node.level)
        
        print(f"  âœ… {len(leaf_nodes)} ä¸ªå¶èŠ‚ç‚¹åµŒå…¥å®Œæˆ")
    
    def _compute_aggregated_embeddings(
        self, 
        parent_nodes: List[MultiLevelNode],
        all_nodes: Dict[str, MultiLevelNode]
    ):
        """è‡ªåº•å‘ä¸Šèšåˆçˆ¶èŠ‚ç‚¹åµŒå…¥"""
        print("  ğŸ”„ è®¡ç®—çˆ¶èŠ‚ç‚¹èšåˆåµŒå…¥...")
        
        for parent in parent_nodes:
            # è·å–æ‰€æœ‰å­èŠ‚ç‚¹
            children = [
                all_nodes[child_id] 
                for child_id in parent.children_ids 
                if child_id in all_nodes
            ]
            
            if not children:
                # æ²¡æœ‰å­èŠ‚ç‚¹ï¼Œä½¿ç”¨ç›´æ¥åµŒå…¥
                if parent.content:
                    parent.direct_embedding = self.embedding_model.encode([parent.content])[0]
                    parent.aggregated_embedding = parent.direct_embedding
                continue
            
            # è®¡ç®—aboutnessæƒé‡
            aboutness_weights = self._calculate_aboutness_weights(
                parent, children, all_nodes
            )
            
            # åŠ æƒèšåˆ
            aggregated = self._weighted_aggregation(
                children, aboutness_weights, all_nodes
            )
            
            parent.aggregated_embedding = aggregated
            parent.aboutness_weights = aboutness_weights
        
        print(f"  âœ… {len(parent_nodes)} ä¸ªçˆ¶èŠ‚ç‚¹èšåˆå®Œæˆ")
    
    def _calculate_aboutness_weights(
        self,
        parent: MultiLevelNode,
        children: List[MultiLevelNode],
        all_nodes: Dict[str, MultiLevelNode]
    ) -> Dict[str, float]:
        """
        è®¡ç®—å­èŠ‚ç‚¹çš„aboutnessæƒé‡
        
        å…¬å¼ï¼šw_i = aboutness_score(child_i) / Î£ aboutness_score(all_children)
        
        aboutness_scoreé€šè¿‡cosineç›¸ä¼¼åº¦éšå¼è®¡ç®—ï¼š
        - å¦‚æœparentæœ‰ç›´æ¥åµŒå…¥ï¼Œä½¿ç”¨cosine(child_embed, parent_embed)
        - å¦åˆ™ä½¿ç”¨å±‚çº§é»˜è®¤æƒé‡
        """
        weights = {}
        
        # å¦‚æœçˆ¶èŠ‚ç‚¹æœ‰ç›´æ¥åµŒå…¥ï¼ˆä¾‹å¦‚æœ‰è‡ªå·±çš„æ–‡æœ¬å†…å®¹ï¼‰
        if parent.content:
            # ç”Ÿæˆçˆ¶èŠ‚ç‚¹çš„ä¸´æ—¶åµŒå…¥ï¼ˆç”¨äºè®¡ç®—ç›¸ä¼¼åº¦ï¼‰
            parent_temp_embed = self.embedding_model.encode([parent.content])[0]
            
            # è®¡ç®—æ¯ä¸ªå­èŠ‚ç‚¹ä¸çˆ¶èŠ‚ç‚¹çš„ç›¸ä¼¼åº¦ä½œä¸ºaboutness
            similarities = {}
            for child in children:
                child_embed = self._get_node_embedding(child, all_nodes)
                if child_embed is not None:
                    sim = self._cosine_similarity(child_embed, parent_temp_embed)
                    similarities[child.node_id] = max(sim, 0.0)  # è´Ÿå€¼è®¾ä¸º0
                else:
                    # ä½¿ç”¨é»˜è®¤æƒé‡
                    similarities[child.node_id] = self.aboutness_weights.get_weight(child.level)
            
            # å½’ä¸€åŒ–
            total = sum(similarities.values())
            if total > 0:
                weights = {k: v/total for k, v in similarities.items()}
            else:
                # å‡ç­‰æƒé‡
                weights = {child.node_id: 1.0/len(children) for child in children}
        
        else:
            # ä½¿ç”¨å±‚çº§é»˜è®¤æƒé‡
            raw_weights = {
                child.node_id: self.aboutness_weights.get_weight(child.level)
                for child in children
            }
            total = sum(raw_weights.values())
            weights = {k: v/total for k, v in raw_weights.items()} if total > 0 else {}
        
        return weights
    
    def _weighted_aggregation(
        self,
        children: List[MultiLevelNode],
        weights: Dict[str, float],
        all_nodes: Dict[str, MultiLevelNode]
    ) -> np.ndarray:
        """
        åŠ æƒèšåˆå­èŠ‚ç‚¹åµŒå…¥
        
        å…¬å¼ï¼še_parent = Î£(w_i Ã— e_child_i)
        """
        aggregated = None
        
        for child in children:
            child_embed = self._get_node_embedding(child, all_nodes)
            weight = weights.get(child.node_id, 0.0)
            
            if child_embed is not None and weight > 0:
                weighted_embed = child_embed * weight
                
                if aggregated is None:
                    aggregated = weighted_embed
                else:
                    aggregated += weighted_embed
        
        # å½’ä¸€åŒ–ï¼ˆå¯é€‰ï¼‰
        if aggregated is not None:
            norm = np.linalg.norm(aggregated)
            if norm > 0:
                aggregated = aggregated / norm
        
        return aggregated
    
    def _get_node_embedding(
        self, 
        node: MultiLevelNode,
        all_nodes: Dict[str, MultiLevelNode]
    ) -> Optional[np.ndarray]:
        """è·å–èŠ‚ç‚¹çš„åµŒå…¥å‘é‡ï¼ˆä¼˜å…ˆä½¿ç”¨å·²æœ‰çš„ï¼‰"""
        if node.final_embedding is not None:
            return node.final_embedding
        elif node.aggregated_embedding is not None:
            return node.aggregated_embedding
        elif node.direct_embedding is not None:
            return node.direct_embedding
        else:
            return None
    
    def _cosine_similarity(self, vec_a: np.ndarray, vec_b: np.ndarray) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        dot_product = np.dot(vec_a, vec_b)
        norm_a = np.linalg.norm(vec_a)
        norm_b = np.linalg.norm(vec_b)
        
        if norm_a == 0 or norm_b == 0:
            return 0.0
        
        return float(dot_product / (norm_a * norm_b))
    
    def get_embedding_statistics(self, nodes: Dict[str, MultiLevelNode]) -> Dict[str, Any]:
        """è·å–åµŒå…¥ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "total_nodes": len(nodes),
            "direct_embeddings": sum(1 for n in nodes.values() if n.direct_embedding is not None),
            "aggregated_embeddings": sum(1 for n in nodes.values() if n.aggregated_embedding is not None),
            "final_embeddings": sum(1 for n in nodes.values() if n.final_embedding is not None),
        }
        
        # æŒ‰å±‚çº§ç»Ÿè®¡
        level_stats = {}
        for level in LegalLevel.get_hierarchy():
            level_nodes = [n for n in nodes.values() if n.level == level]
            level_stats[level] = {
                "count": len(level_nodes),
                "avg_aboutness": np.mean([n.aboutness_score for n in level_nodes]) if level_nodes else 0.0
            }
        
        stats["level_statistics"] = level_stats
        return stats
