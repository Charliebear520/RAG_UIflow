"""
è‡ªé©æ‡‰æ³•å¾‹RAGç³»çµ±
æ ¹æ“šæŸ¥è©¢ç‰¹å¾µå‹•æ…‹é¸æ“‡æœ€å„ªçš„æª¢ç´¢ç­–ç•¥çµ„åˆ
"""

import re
import numpy as np
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import json


class QueryType(Enum):
    """æŸ¥è©¢é¡å‹æšèˆ‰"""
    CONCEPTUAL = "conceptual"      # æ¦‚å¿µæ€§æŸ¥è©¢
    NORMATIVE = "normative"        # è¦ç¯„æ€§æŸ¥è©¢
    PROCEDURAL = "procedural"      # ç¨‹åºæ€§æŸ¥è©¢
    EXPLICIT_ARTICLE = "explicit_article"  # æ˜ç¢ºæ³•æ¢æŸ¥è©¢
    COMPARATIVE = "comparative"    # æ¯”è¼ƒæ€§æŸ¥è©¢
    CASE_BASED = "case_based"      # æ¡ˆä¾‹æ€§æŸ¥è©¢


@dataclass
class QueryAnalysis:
    """æŸ¥è©¢åˆ†æçµæœ"""
    query_type: QueryType
    confidence: float
    key_concepts: List[str]
    legal_articles: List[str]
    complexity_score: float
    semantic_features: Dict[str, Any]
    recommended_strategies: List[str]


@dataclass
class RetrievalStrategy:
    """æª¢ç´¢ç­–ç•¥é…ç½®"""
    name: str
    weight: float
    parameters: Dict[str, Any]
    applicable_query_types: List[QueryType]
    performance_history: List[float]


class QueryAnalyzer:
    """æŸ¥è©¢åˆ†æå™¨"""
    
    def __init__(self):
        # æŸ¥è©¢é¡å‹è­˜åˆ¥æ¨¡å¼
        self.query_patterns = {
            QueryType.CONCEPTUAL: [
                r'ä»€éº¼æ˜¯.*?',
                r'.*?çš„å®šç¾©',
                r'.*?æ˜¯æŒ‡.*?',
                r'.*?æ¦‚å¿µ.*?',
                r'ä½•è¬‚.*?'
            ],
            QueryType.NORMATIVE: [
                r'ç¬¬\s*\d+\s*æ¢',
                r'.*?è¦å®š.*?',
                r'.*?ç¦æ­¢.*?',
                r'.*?æ‡‰.*?',
                r'.*?ä¸å¾—.*?'
            ],
            QueryType.PROCEDURAL: [
                r'å¦‚ä½•.*?',
                r'.*?ç¨‹åº.*?',
                r'.*?ç”³è«‹.*?',
                r'.*?è¾¦ç†.*?',
                r'.*?æµç¨‹.*?'
            ],
            QueryType.EXPLICIT_ARTICLE: [
                r'ç¬¬\s*\d+\s*æ¢.*?',
                r'article\s*\d+',
                r'æ¢æ–‡\s*\d+'
            ],
            QueryType.COMPARATIVE: [
                r'.*?èˆ‡.*?çš„å·®åˆ¥',
                r'.*?æ¯”è¼ƒ.*?',
                r'.*?å€åˆ¥.*?',
                r'.*?å·®ç•°.*?'
            ],
            QueryType.CASE_BASED: [
                r'.*?æ¡ˆä¾‹.*?',
                r'.*?æƒ…å½¢.*?',
                r'.*?æƒ…æ³.*?',
                r'.*?ä¾‹å­.*?'
            ]
        }
        
        # æ³•å¾‹é—œéµè©
        self.legal_keywords = {
            'copyright': ['è‘—ä½œæ¬Š', 'ç‰ˆæ¬Š', 'é‡è£½', 'æ”¹ä½œ', 'æ•£å¸ƒ', 'åˆç†ä½¿ç”¨'],
            'trademark': ['å•†æ¨™', 'è¨»å†Š', 'ä»¿å†’', 'æ··æ·†', 'å°ˆç”¨æ¬Š'],
            'patent': ['å°ˆåˆ©', 'ç™¼æ˜', 'æ–°ç©æ€§', 'é€²æ­¥æ€§', 'ç”¢æ¥­åˆ©ç”¨æ€§'],
            'civil': ['æ°‘æ³•', 'å¥‘ç´„', 'æå®³è³ å„Ÿ', 'ä¾µæ¬Š'],
            'criminal': ['åˆ‘æ³•', 'çŠ¯ç½ª', 'åˆ‘ç½°', 'ç½°é‡‘']
        }
        
        # è¤‡é›œåº¦æŒ‡æ¨™
        self.complexity_indicators = {
            'high': ['æ¯”è¼ƒ', 'åˆ†æ', 'è©•ä¼°', 'ç¶œåˆ', 'è¤‡é›œ', 'å¤šé‡'],
            'medium': ['é—œä¿‚', 'å½±éŸ¿', 'é©ç”¨', 'ç¯„åœ'],
            'low': ['å®šç¾©', 'ä»€éº¼', 'å¦‚ä½•', 'æ˜¯å¦']
        }
    
    def analyze_query(self, query: str) -> QueryAnalysis:
        """åˆ†ææŸ¥è©¢"""
        print(f"ğŸ” é–‹å§‹åˆ†ææŸ¥è©¢: '{query}'")
        
        # 1. è­˜åˆ¥æŸ¥è©¢é¡å‹
        query_type, confidence = self._identify_query_type(query)
        print(f"ğŸ” è­˜åˆ¥æŸ¥è©¢é¡å‹: {query_type.value} (ç½®ä¿¡åº¦: {confidence:.3f})")
        
        # 2. æå–é—œéµæ¦‚å¿µ
        key_concepts = self._extract_key_concepts(query)
        print(f"ğŸ” æå–é—œéµæ¦‚å¿µ: {key_concepts}")
        
        # 3. æå–æ³•å¾‹æ¢æ–‡
        legal_articles = self._extract_legal_articles(query)
        print(f"ğŸ” æå–æ³•å¾‹æ¢æ–‡: {legal_articles}")
        
        # 4. è¨ˆç®—è¤‡é›œåº¦
        complexity_score = self._calculate_complexity(query)
        print(f"ğŸ” è¨ˆç®—è¤‡é›œåº¦: {complexity_score:.3f}")
        
        # 5. æå–èªç¾©ç‰¹å¾µ
        semantic_features = self._extract_semantic_features(query)
        print(f"ğŸ” æå–èªç¾©ç‰¹å¾µ: {len(semantic_features)} å€‹ç‰¹å¾µ")
        
        # 6. æ¨è–¦ç­–ç•¥
        recommended_strategies = self._recommend_strategies(
            query_type, complexity_score, key_concepts, legal_articles
        )
        print(f"ğŸ” æ¨è–¦ç­–ç•¥: {recommended_strategies}")
        
        return QueryAnalysis(
            query_type=query_type,
            confidence=confidence,
            key_concepts=key_concepts,
            legal_articles=legal_articles,
            complexity_score=complexity_score,
            semantic_features=semantic_features,
            recommended_strategies=recommended_strategies
        )
    
    def _identify_query_type(self, query: str) -> Tuple[QueryType, float]:
        """è­˜åˆ¥æŸ¥è©¢é¡å‹"""
        type_scores = {}
        
        for query_type, patterns in self.query_patterns.items():
            score = 0.0
            for pattern in patterns:
                matches = re.findall(pattern, query, re.IGNORECASE)
                score += len(matches) * 0.5
            
            # ç‰¹æ®Šè™•ç†æ˜ç¢ºæ³•æ¢æŸ¥è©¢
            if query_type == QueryType.EXPLICIT_ARTICLE:
                article_matches = re.findall(r'ç¬¬\s*\d+\s*æ¢', query)
                score += len(article_matches) * 1.0
            
            type_scores[query_type] = score
        
        # æ‰¾åˆ°æœ€é«˜åˆ†æ•¸çš„é¡å‹
        if type_scores:
            best_type = max(type_scores.items(), key=lambda x: x[1])
            max_score = best_type[1]
            confidence = min(1.0, max_score / 2.0)  # æ­¸ä¸€åŒ–åˆ°0-1
            return best_type[0], confidence
        
        return QueryType.CONCEPTUAL, 0.5  # é»˜èªé¡å‹
    
    def _extract_key_concepts(self, query: str) -> List[str]:
        """æå–é—œéµæ¦‚å¿µ"""
        concepts = []
        
        # å¾æ³•å¾‹é—œéµè©ä¸­æå–
        for domain, keywords in self.legal_keywords.items():
            for keyword in keywords:
                if keyword in query:
                    concepts.append(keyword)
        
        # å¾æŸ¥è©¢ä¸­æå–æ³•å¾‹ç›¸é—œè©å½™
        legal_terms = re.findall(r'[è‘—ä½œå•†å°ˆæ°‘åˆ‘][æ¬Šæ³•]|[æ¬Šæ³•]|[é‡è£½æ”¹ä½œæ•£å¸ƒæˆæ¬Šåˆç†ä½¿ç”¨]', query)
        concepts.extend(legal_terms)
        
        return list(set(concepts))
    
    def _extract_legal_articles(self, query: str) -> List[str]:
        """æå–æ³•å¾‹æ¢æ–‡"""
        articles = []
        
        # æå–ç¬¬Xæ¢æ ¼å¼
        article_matches = re.findall(r'ç¬¬\s*(\d+)\s*æ¢', query)
        articles.extend([f"ç¬¬{article}æ¢" for article in article_matches])
        
        # æå–article Xæ ¼å¼
        article_en_matches = re.findall(r'article\s*(\d+)', query, re.IGNORECASE)
        articles.extend([f"Article {article}" for article in article_en_matches])
        
        return articles
    
    def _calculate_complexity(self, query: str) -> float:
        """è¨ˆç®—æŸ¥è©¢è¤‡é›œåº¦"""
        complexity_score = 0.0
        
        # åŸºæ–¼è¤‡é›œåº¦æŒ‡æ¨™
        for level, indicators in self.complexity_indicators.items():
            for indicator in indicators:
                if indicator in query:
                    if level == 'high':
                        complexity_score += 0.8
                    elif level == 'medium':
                        complexity_score += 0.5
                    else:
                        complexity_score += 0.2
        
        # åŸºæ–¼æŸ¥è©¢é•·åº¦
        length_factor = min(1.0, len(query) / 100)
        complexity_score += length_factor * 0.3
        
        # åŸºæ–¼é—œéµæ¦‚å¿µæ•¸é‡
        concept_count = len(self._extract_key_concepts(query))
        concept_factor = min(1.0, concept_count / 5)
        complexity_score += concept_factor * 0.2
        
        return min(1.0, complexity_score)
    
    def _extract_semantic_features(self, query: str) -> Dict[str, Any]:
        """æå–èªç¾©ç‰¹å¾µ"""
        features = {
            'length': len(query),
            'word_count': len(query.split()),
            'has_question_mark': '?' in query or 'ï¼Ÿ' in query,
            'has_comparison': any(word in query for word in ['æ¯”è¼ƒ', 'èˆ‡', 'å·®åˆ¥', 'å€åˆ¥']),
            'has_condition': any(word in query for word in ['å¦‚æœ', 'ç•¶', 'æƒ…å½¢', 'æƒ…æ³']),
            'has_negation': any(word in query for word in ['ä¸', 'é', 'ç„¡', 'ç¦æ­¢']),
            'domain_keywords': [],
            'sentence_structure': self._analyze_sentence_structure(query)
        }
        
        # è­˜åˆ¥é ˜åŸŸé—œéµè©
        for domain, keywords in self.legal_keywords.items():
            domain_matches = [kw for kw in keywords if kw in query]
            if domain_matches:
                features['domain_keywords'].append({
                    'domain': domain,
                    'keywords': domain_matches
                })
        
        return features
    
    def _analyze_sentence_structure(self, query: str) -> str:
        """åˆ†æå¥å­çµæ§‹"""
        if 'ï¼Ÿ' in query or '?' in query:
            return 'question'
        elif 'ï¼Œ' in query or ',' in query:
            return 'compound'
        elif any(word in query for word in ['å’Œ', 'èˆ‡', 'åŠ']):
            return 'conjunction'
        else:
            return 'simple'
    
    def _recommend_strategies(self, query_type: QueryType, complexity_score: float,
                            key_concepts: List[str], legal_articles: List[str]) -> List[str]:
        """æ¨è–¦æª¢ç´¢ç­–ç•¥"""
        strategies = []
        
        # åŸºæ–¼æŸ¥è©¢é¡å‹æ¨è–¦ç­–ç•¥
        if query_type == QueryType.CONCEPTUAL:
            strategies.extend(['concept_graph', 'semantic_search', 'multi_modal'])
        elif query_type == QueryType.NORMATIVE:
            strategies.extend(['hybrid_rag', 'structured_search', 'legal_semantic'])
        elif query_type == QueryType.PROCEDURAL:
            strategies.extend(['hierarchical', 'sequential_search'])
        elif query_type == QueryType.EXPLICIT_ARTICLE:
            strategies.extend(['exact_match', 'structured_search'])
        elif query_type == QueryType.COMPARATIVE:
            strategies.extend(['multi_modal', 'concept_graph', 'comparative_analysis'])
        elif query_type == QueryType.CASE_BASED:
            strategies.extend(['semantic_search', 'case_matching'])
        
        # åŸºæ–¼è¤‡é›œåº¦èª¿æ•´ç­–ç•¥
        if complexity_score > 0.7:
            strategies.extend(['multi_strategy', 'adaptive_fusion'])
        
        # åŸºæ–¼é—œéµæ¦‚å¿µèª¿æ•´
        if len(key_concepts) > 3:
            strategies.append('concept_expansion')
        
        # åŸºæ–¼æ³•å¾‹æ¢æ–‡èª¿æ•´
        if legal_articles:
            strategies.extend(['article_focused', 'legal_structure'])
        
        return list(set(strategies))


class StrategySelector:
    """ç­–ç•¥é¸æ“‡å™¨"""
    
    def __init__(self):
        self.strategies = {
            'vector_search': RetrievalStrategy(
                name='vector_search',
                weight=1.0,
                parameters={'k': 5, 'similarity_threshold': 0.7},
                applicable_query_types=[QueryType.CONCEPTUAL, QueryType.CASE_BASED],
                performance_history=[]
            ),
            'hybrid_rag': RetrievalStrategy(
                name='hybrid_rag',
                weight=1.2,
                parameters={'alpha': 0.7, 'legal_boost': 0.3},
                applicable_query_types=[QueryType.NORMATIVE, QueryType.EXPLICIT_ARTICLE],
                performance_history=[]
            ),
            'concept_graph': RetrievalStrategy(
                name='concept_graph',
                weight=1.5,
                parameters={'reasoning_weight': 0.8},
                applicable_query_types=[QueryType.CONCEPTUAL, QueryType.COMPARATIVE],
                performance_history=[]
            ),
            'multi_modal': RetrievalStrategy(
                name='multi_modal',
                weight=1.3,
                parameters={'text_weight': 0.6, 'structure_weight': 0.4},
                applicable_query_types=[QueryType.COMPARATIVE, QueryType.PROCEDURAL],
                performance_history=[]
            ),
            'hierarchical': RetrievalStrategy(
                name='hierarchical',
                weight=1.1,
                parameters={'level_weights': [1.0, 0.8, 0.6]},
                applicable_query_types=[QueryType.PROCEDURAL, QueryType.NORMATIVE],
                performance_history=[]
            ),
            'semantic_search': RetrievalStrategy(
                name='semantic_search',
                weight=1.0,
                parameters={'semantic_threshold': 0.6},
                applicable_query_types=[QueryType.CONCEPTUAL, QueryType.CASE_BASED],
                performance_history=[]
            )
        }
    
    def select_strategies(self, query_analysis: QueryAnalysis, 
                         available_strategies: Dict[str, Any]) -> Dict[str, Any]:
        """é¸æ“‡æª¢ç´¢ç­–ç•¥"""
        print(f"ğŸ¯ é–‹å§‹ç­–ç•¥é¸æ“‡ï¼Œæ¨è–¦ç­–ç•¥: {query_analysis.recommended_strategies}")
        
        selected_strategies = {}
        
        # 1. åŸºæ–¼æ¨è–¦ç­–ç•¥é¸æ“‡
        for strategy_name in query_analysis.recommended_strategies:
            if strategy_name in available_strategies:
                strategy = self.strategies.get(strategy_name)
                if strategy and self._is_strategy_applicable(strategy, query_analysis):
                    selected_strategies[strategy_name] = {
                        'strategy': available_strategies[strategy_name],
                        'weight': strategy.weight,
                        'parameters': strategy.parameters.copy()
                    }
        
        # 2. ç¢ºä¿è‡³å°‘æœ‰ä¸€å€‹ç­–ç•¥
        if not selected_strategies:
            # é»˜èªé¸æ“‡ç­–ç•¥
            default_strategy = 'hybrid_rag' if 'hybrid_rag' in available_strategies else 'vector_search'
            selected_strategies[default_strategy] = {
                'strategy': available_strategies[default_strategy],
                'weight': 1.0,
                'parameters': {}
            }
        
        # 3. æ ¹æ“šæŸ¥è©¢è¤‡é›œåº¦èª¿æ•´ç­–ç•¥æ•¸é‡
        if query_analysis.complexity_score > 0.7 and len(selected_strategies) == 1:
            # ç‚ºè¤‡é›œæŸ¥è©¢æ·»åŠ é¡å¤–ç­–ç•¥
            additional_strategy = self._select_additional_strategy(query_analysis, available_strategies)
            if additional_strategy:
                selected_strategies.update(additional_strategy)
        
        print(f"ğŸ¯ æœ€çµ‚é¸æ“‡ç­–ç•¥: {list(selected_strategies.keys())}")
        
        return selected_strategies
    
    def _is_strategy_applicable(self, strategy: RetrievalStrategy, 
                               query_analysis: QueryAnalysis) -> bool:
        """åˆ¤æ–·ç­–ç•¥æ˜¯å¦é©ç”¨"""
        return query_analysis.query_type in strategy.applicable_query_types
    
    def _select_additional_strategy(self, query_analysis: QueryAnalysis,
                                   available_strategies: Dict[str, Any]) -> Dict[str, Any]:
        """ç‚ºè¤‡é›œæŸ¥è©¢é¸æ“‡é¡å¤–ç­–ç•¥"""
        additional = {}
        
        # åŸºæ–¼æŸ¥è©¢é¡å‹é¸æ“‡äº’è£œç­–ç•¥
        if query_analysis.query_type == QueryType.CONCEPTUAL:
            if 'semantic_search' in available_strategies:
                additional['semantic_search'] = {
                    'strategy': available_strategies['semantic_search'],
                    'weight': 0.8,
                    'parameters': {}
                }
        elif query_analysis.query_type == QueryType.NORMATIVE:
            if 'hierarchical' in available_strategies:
                additional['hierarchical'] = {
                    'strategy': available_strategies['hierarchical'],
                    'weight': 0.9,
                    'parameters': {}
                }
        
        return additional


class AdaptiveLegalRAG:
    """è‡ªé©æ‡‰æ³•å¾‹RAGç³»çµ±"""
    
    def __init__(self):
        self.query_analyzer = QueryAnalyzer()
        self.strategy_selector = StrategySelector()
        
        # æª¢ç´¢ç­–ç•¥å¯¦ä¾‹
        self.retrieval_strategies = {}
        
        # æ€§èƒ½ç›£æ§
        self.performance_monitor = PerformanceMonitor()
    
    def register_strategy(self, name: str, strategy_instance: Any) -> None:
        """è¨»å†Šæª¢ç´¢ç­–ç•¥"""
        self.retrieval_strategies[name] = strategy_instance
        print(f"âœ… è¨»å†Šç­–ç•¥: {name}")
    
    def retrieve(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """è‡ªé©æ‡‰æª¢ç´¢"""
        print(f"ğŸš€ é–‹å§‹è‡ªé©æ‡‰æª¢ç´¢ï¼ŒæŸ¥è©¢: '{query}'")
        
        # 1. æŸ¥è©¢åˆ†æ
        query_analysis = self.query_analyzer.analyze_query(query)
        
        # 2. ç­–ç•¥é¸æ“‡
        selected_strategies = self.strategy_selector.select_strategies(
            query_analysis, self.retrieval_strategies
        )
        
        # 3. å¤šç­–ç•¥æª¢ç´¢
        strategy_results = {}
        for strategy_name, strategy_config in selected_strategies.items():
            try:
                strategy_instance = strategy_config['strategy']
                parameters = strategy_config['parameters']
                parameters['k'] = k
                
                print(f"ğŸ” åŸ·è¡Œç­–ç•¥: {strategy_name}")
                results = strategy_instance.retrieve(query, **parameters)
                strategy_results[strategy_name] = {
                    'results': results,
                    'weight': strategy_config['weight']
                }
            except Exception as e:
                print(f"âŒ ç­–ç•¥ {strategy_name} åŸ·è¡Œå¤±æ•—: {e}")
                continue
        
        # 4. çµæœèåˆ
        if strategy_results:
            fused_results = self._fuse_results(strategy_results, query_analysis)
            
            # 5. æ€§èƒ½ç›£æ§
            self.performance_monitor.record_retrieval(query, query_analysis, fused_results)
            
            return fused_results
        else:
            print("âŒ æ²’æœ‰å¯ç”¨çš„æª¢ç´¢ç­–ç•¥")
            return []
    
    def _fuse_results(self, strategy_results: Dict[str, Dict[str, Any]], 
                     query_analysis: QueryAnalysis) -> List[Dict[str, Any]]:
        """èåˆå¤šç­–ç•¥çµæœ"""
        print(f"ğŸ”€ é–‹å§‹çµæœèåˆï¼Œç­–ç•¥æ•¸é‡: {len(strategy_results)}")
        
        # æ”¶é›†æ‰€æœ‰çµæœ
        all_results = []
        result_scores = {}
        
        for strategy_name, strategy_data in strategy_results.items():
            results = strategy_data['results']
            weight = strategy_data['weight']
            
            for result in results:
                # è¨ˆç®—åŠ æ¬Šåˆ†æ•¸
                base_score = result.get('score', 0.0)
                weighted_score = base_score * weight
                
                # æ ¹æ“šæŸ¥è©¢é¡å‹èª¿æ•´åˆ†æ•¸
                adjusted_score = self._adjust_score_by_query_type(
                    weighted_score, result, query_analysis
                )
                
                result_id = self._generate_result_id(result)
                if result_id not in result_scores:
                    result_scores[result_id] = {
                        'result': result,
                        'scores': [],
                        'strategies': []
                    }
                
                result_scores[result_id]['scores'].append(adjusted_score)
                result_scores[result_id]['strategies'].append(strategy_name)
        
        # èåˆåˆ†æ•¸
        fused_results = []
        for result_id, data in result_scores.items():
            result = data['result']
            scores = data['scores']
            strategies = data['strategies']
            
            # è¨ˆç®—èåˆåˆ†æ•¸ï¼ˆåŠ æ¬Šå¹³å‡ï¼‰
            if scores:
                fused_score = sum(scores) / len(scores)
                
                # æ·»åŠ èåˆå…ƒæ•¸æ“š
                result['fused_score'] = fused_score
                result['contributing_strategies'] = strategies
                result['strategy_count'] = len(strategies)
                result['metadata']['adaptive_fusion'] = True
                
                fused_results.append(result)
        
        # æŒ‰èåˆåˆ†æ•¸æ’åº
        fused_results.sort(key=lambda x: x['fused_score'], reverse=True)
        
        print(f"ğŸ”€ èåˆå®Œæˆï¼Œçµæœæ•¸é‡: {len(fused_results)}")
        
        return fused_results
    
    def _adjust_score_by_query_type(self, score: float, result: Dict[str, Any], 
                                   query_analysis: QueryAnalysis) -> float:
        """æ ¹æ“šæŸ¥è©¢é¡å‹èª¿æ•´åˆ†æ•¸"""
        adjusted_score = score
        
        # åŸºæ–¼æŸ¥è©¢é¡å‹èª¿æ•´
        if query_analysis.query_type == QueryType.CONCEPTUAL:
            # æ¦‚å¿µæ€§æŸ¥è©¢ï¼šé‡è¦–æ¦‚å¿µåŒ¹é…
            if result.get('metadata', {}).get('concept_based', False):
                adjusted_score *= 1.2
        
        elif query_analysis.query_type == QueryType.NORMATIVE:
            # è¦ç¯„æ€§æŸ¥è©¢ï¼šé‡è¦–æ³•æ¢åŒ¹é…
            if any(article in result.get('content', '') for article in query_analysis.legal_articles):
                adjusted_score *= 1.3
        
        elif query_analysis.query_type == QueryType.EXPLICIT_ARTICLE:
            # æ˜ç¢ºæ³•æ¢æŸ¥è©¢ï¼šé‡è¦–ç²¾ç¢ºåŒ¹é…
            if any(article in result.get('content', '') for article in query_analysis.legal_articles):
                adjusted_score *= 1.5
        
        # åŸºæ–¼è¤‡é›œåº¦èª¿æ•´
        if query_analysis.complexity_score > 0.7:
            # è¤‡é›œæŸ¥è©¢ï¼šé‡è¦–å¤šç­–ç•¥æ”¯æŒ
            if result.get('strategy_count', 1) > 1:
                adjusted_score *= 1.1
        
        return adjusted_score
    
    def _generate_result_id(self, result: Dict[str, Any]) -> str:
        """ç”ŸæˆçµæœID"""
        content = result.get('content', '')
        metadata = result.get('metadata', {})
        
        # åŸºæ–¼å…§å®¹å’Œå…ƒæ•¸æ“šç”ŸæˆID
        id_parts = [
            content[:50],  # å…§å®¹å‰50å­—ç¬¦
            metadata.get('strategy', 'unknown'),
            str(metadata.get('chunk_index', 0))
        ]
        
        return '_'.join(id_parts)


class PerformanceMonitor:
    """æ€§èƒ½ç›£æ§å™¨"""
    
    def __init__(self):
        self.retrieval_history = []
        self.strategy_performance = {}
    
    def record_retrieval(self, query: str, query_analysis: QueryAnalysis, 
                        results: List[Dict[str, Any]]) -> None:
        """è¨˜éŒ„æª¢ç´¢æ€§èƒ½"""
        record = {
            'query': query,
            'query_type': query_analysis.query_type.value,
            'complexity': query_analysis.complexity_score,
            'result_count': len(results),
            'timestamp': self._get_timestamp()
        }
        
        self.retrieval_history.append(record)
        
        # æ›´æ–°ç­–ç•¥æ€§èƒ½
        for result in results:
            strategies = result.get('contributing_strategies', [])
            for strategy in strategies:
                if strategy not in self.strategy_performance:
                    self.strategy_performance[strategy] = []
                
                self.strategy_performance[strategy].append(result.get('fused_score', 0.0))
    
    def get_strategy_performance(self) -> Dict[str, float]:
        """ç²å–ç­–ç•¥æ€§èƒ½çµ±è¨ˆ"""
        performance = {}
        
        for strategy, scores in self.strategy_performance.items():
            if scores:
                performance[strategy] = {
                    'avg_score': sum(scores) / len(scores),
                    'usage_count': len(scores),
                    'max_score': max(scores),
                    'min_score': min(scores)
                }
        
        return performance
    
    def _get_timestamp(self) -> str:
        """ç²å–æ™‚é–“æˆ³"""
        import datetime
        return datetime.datetime.now().isoformat()
