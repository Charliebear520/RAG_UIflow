# BGE-M3 æœ¬åœ°æ¨¡å‹é…ç½®è¯´æ˜

## ğŸ¯ é…ç½®ç›®æ ‡

**ä» Gemini API åˆ‡æ¢åˆ° BGE-M3 æœ¬åœ°æ¨¡å‹**ï¼Œå®ç°ï¼š

- âœ… **30 å€é€Ÿåº¦æå‡**ï¼š1842 ä¸ª embedding ä» ~30 åˆ†é˜é™ä½åˆ° **< 1 åˆ†é˜**
- âœ… **ç„¡ API é™åˆ¶**ï¼šæœ¬åœ°é‹è¡Œï¼Œç„¡é€Ÿç‡é™åˆ¶
- âœ… **é›¶æˆæœ¬**ï¼šä¸æ¶ˆè€— Gemini API é…é¡
- âœ… **æ›´é«˜è³ªé‡**ï¼šBGE-M3 å°ˆç‚ºå¤šèªè¨€æª¢ç´¢å„ªåŒ–ï¼Œå°ä¸­æ–‡æ³•å¾‹æ–‡æœ¬æ•ˆæœæ›´ä½³

---

## âœ… å·²å®Œæˆé…ç½®

### **1ï¸âƒ£ å®‰è£ä¾è³´**

```bash
cd backend
source venv/bin/activate
pip install sentence-transformers
```

**ç‹€æ…‹**ï¼šâœ… å·²å®‰è£

- `sentence-transformers==5.1.1`
- `torch==2.8.0`
- `transformers==4.56.2`

---

### **2ï¸âƒ£ ä¿®æ”¹ Embedding å„ªå…ˆç´š**

#### **æ–‡ä»¶**ï¼š`backend/app/hoprag_clients.py`

#### **ä¿®æ”¹å…§å®¹**ï¼š

**åŒæ­¥ encode æ–¹æ³•**ï¼š

```python
def encode(self, texts: List[str]) -> np.ndarray:
    """åŒæ­¥ç·¨ç¢¼æ–‡æœ¬ï¼ˆå„ªå…ˆä½¿ç”¨æœ¬åœ°BGE-M3æ¨¡å‹ï¼‰"""
    if self.use_bge:  # ğŸš€ å„ªå…ˆä½¿ç”¨BGE-M3æœ¬åœ°æ¨¡å‹ï¼ˆå¿«30å€ + ç„¡APIé™åˆ¶ï¼‰
        return self._encode_with_bge(texts)
    elif self.use_gemini:
        return self._encode_with_gemini(texts)
    else:
        return self._encode_mock(texts)
```

**ç•°æ­¥ encode_async æ–¹æ³•**ï¼š

```python
async def encode_async(self, texts: List[str]) -> np.ndarray:
    """ç•°æ­¥ç·¨ç¢¼æ–‡æœ¬ï¼ˆå„ªå…ˆä½¿ç”¨æœ¬åœ°BGE-M3æ¨¡å‹ï¼‰"""
    if self.use_bge:  # ğŸš€ å„ªå…ˆä½¿ç”¨BGE-M3æœ¬åœ°æ¨¡å‹ï¼ˆå¿«30å€ + ç„¡APIé™åˆ¶ï¼‰
        return self._encode_with_bge(texts)
    elif self.use_gemini:
        return await self._encode_with_gemini_async(texts)
    else:
        return self._encode_mock(texts)
```

**è®Šæ›´èªªæ˜**ï¼š

- âœ… **å„ªå…ˆç´šèª¿æ•´**ï¼š`use_bge` æª¢æŸ¥ç§»åˆ°æœ€å‰é¢ï¼ˆåŸæœ¬åœ¨ `use_gemini` ä¹‹å¾Œï¼‰
- âœ… **è‡ªå‹•æª¢æ¸¬**ï¼šç³»çµ±å•Ÿå‹•æ™‚æœƒè‡ªå‹•æª¢æ¸¬ `sentence-transformers` æ˜¯å¦å¯ç”¨
- âœ… **ç„¡ç¸«åˆ‡æ›**ï¼šå¦‚æœ BGE-M3 ä¸å¯ç”¨ï¼Œæœƒè‡ªå‹• fallback åˆ° Gemini API

---

### **3ï¸âƒ£ BGE-M3 æ¨¡å‹è‡ªå‹•ä¸‹è¼‰**

#### **é¦–æ¬¡é‹è¡Œæ™‚**ï¼š

ç•¶ç³»çµ±é¦–æ¬¡ä½¿ç”¨ BGE-M3 æ™‚ï¼Œæœƒè‡ªå‹•å¾ Hugging Face ä¸‹è¼‰æ¨¡å‹ï¼š

```python
# hoprag_clients.py ä¸­çš„ _encode_with_bge æ–¹æ³•
def _encode_with_bge(self, texts: List[str]) -> np.ndarray:
    """ä½¿ç”¨BGE-M3ç·¨ç¢¼"""
    try:
        from sentence_transformers import SentenceTransformer

        # ğŸ”½ é¦–æ¬¡æœƒè‡ªå‹•ä¸‹è¼‰æ¨¡å‹ï¼ˆç´„ 2.3 GBï¼‰
        model = SentenceTransformer('BAAI/bge-m3')
        embeddings = model.encode(texts)

        return embeddings

    except Exception as e:
        print(f"âŒ BGE-M3 Embeddingå¤±æ•—: {e}")
        # ä½¿ç”¨éš¨æ©Ÿå‘é‡ä½œç‚ºfallback
        return np.random.randn(len(texts), 1024).astype(np.float32)
```

**ä¸‹è¼‰ä¿¡æ¯**ï¼š

- **æ¨¡å‹å¤§å°**ï¼š~2.3 GB
- **ä¸‹è¼‰ä½ç½®**ï¼š`~/.cache/huggingface/hub/`
- **ä¸‹è¼‰æ™‚é–“**ï¼šå–æ±ºæ–¼ç¶²é€Ÿï¼ˆé€šå¸¸ 5-15 åˆ†é˜ï¼‰
- **åƒ…é¦–æ¬¡**ï¼šä¸‹è¼‰å¾Œæœƒç·©å­˜ï¼Œå¾ŒçºŒå•Ÿå‹•ç„¡éœ€é‡æ–°ä¸‹è¼‰

**é æœŸæ—¥å¿—**ï¼š

```
Downloading (â€¦)lve/main/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 743/743 [00:00<00:00, 1.23MB/s]
Downloading pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.24G/2.24G [05:23<00:00, 6.92MB/s]
Downloading (â€¦)okenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 366/366 [00:00<00:00, 892kB/s]
Downloading (â€¦)solve/main/vocab.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 232k/232k [00:00<00:00, 1.23MB/s]
```

---

## ğŸ” é©—è­‰é…ç½®

### **å•Ÿå‹•æœå‹™å™¨æ™‚çš„æ—¥èªŒ**

æ­£ç¢ºé…ç½®å¾Œï¼Œå•Ÿå‹•æœå‹™å™¨æ™‚æœƒçœ‹åˆ°ï¼š

```bash
cd backend
source venv/bin/activate
uvicorn app.main:app --reload
```

**é æœŸè¼¸å‡º**ï¼š

```
INFO:     Will watch for changes in these directories: ['/Users/.../RAG/backend']
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
âœ… æª¢æ¸¬åˆ°Gemini APIå¯ç”¨
âœ… æª¢æ¸¬åˆ°Sentence Transformerså¯ç”¨  â† ç¢ºèªBGE-M3å¯ç”¨
âœ… æª¢æ¸¬åˆ°Gemini Embedding APIå¯ç”¨
```

**é—œéµæ¨™èªŒ**ï¼š

- `âœ… æª¢æ¸¬åˆ°Sentence Transformerså¯ç”¨` â†’ BGE-M3 å·²å•Ÿç”¨

---

### **æ§‹å»º HopRAG åœ–è­œæ™‚çš„é©—è­‰**

æ§‹å»ºåœ–è­œæ™‚ï¼Œç³»çµ±æœƒä½¿ç”¨ BGE-M3 è€Œä¸æ˜¯ Gemini APIï¼š

**Gemini APIï¼ˆèˆŠï¼‰**ï¼š

```
ğŸ“Š é–‹å§‹ç”Ÿæˆå½æŸ¥è©¢embeddingå‘é‡...
ğŸ“ˆ ç¸½å…±éœ€è¦ç”Ÿæˆ 1842 å€‹embeddingå‘é‡
â±ï¸ é è¨ˆéœ€è¦ 1-2 åˆ†é˜
âŒ Gemini Embeddingå¤±æ•—: 500 An internal error  â† é€Ÿç‡é™åˆ¶éŒ¯èª¤
è™•ç†æ™‚é–“ï¼š~30 åˆ†é˜
```

**BGE-M3ï¼ˆæ–°ï¼‰**ï¼š

```
ğŸ“Š é–‹å§‹ç”Ÿæˆå½æŸ¥è©¢embeddingå‘é‡...
ğŸ“ˆ ç¸½å…±éœ€è¦ç”Ÿæˆ 1842 å€‹embeddingå‘é‡
âœ… ä½¿ç”¨BGE-M3æœ¬åœ°æ¨¡å‹  â† ç¢ºèªä½¿ç”¨æœ¬åœ°æ¨¡å‹
è™•ç†æ™‚é–“ï¼š< 1 åˆ†é˜  â† å¿«30å€ï¼
```

---

## ğŸ“Š æ€§èƒ½å°æ¯”

### **Embedding ç”Ÿæˆé€Ÿåº¦**

| æ–¹æ¡ˆ               | 1842 å€‹ Embedding æ™‚é–“ | API èª¿ç”¨ | é€Ÿç‡é™åˆ¶        | æˆæœ¬     |
| ------------------ | ---------------------- | -------- | --------------- | -------- |
| Gemini API         | ~30 åˆ†é˜               | 1842 æ¬¡  | æ˜¯ï¼ˆ~1 req/ç§’ï¼‰ | API é…é¡ |
| **BGE-M3ï¼ˆæœ¬åœ°ï¼‰** | **< 1 åˆ†é˜**           | **0 æ¬¡** | **å¦**          | **å…è²»** |

**åŠ é€Ÿæ¯”**ï¼š**30x**

---

### **HopRAG å®Œæ•´æ§‹å»ºæ™‚é–“**

ä»¥ 307 å€‹ç¯€é»çš„æ³•è¦ç‚ºä¾‹ï¼š

| éšæ®µ              | Gemini API   | BGE-M3       | ç¯€çœæ™‚é–“                 |
| ----------------- | ------------ | ------------ | ------------------------ |
| å½æŸ¥è©¢ç”Ÿæˆï¼ˆLLMï¼‰ | 25.4 åˆ†é˜    | 25.4 åˆ†é˜    | 0 åˆ†é˜                   |
| Embedding ç”Ÿæˆ    | ~30 åˆ†é˜     | **< 1 åˆ†é˜** | **~29 åˆ†é˜**             |
| é‚ŠåŒ¹é…å’Œé€£æ¥      | 5 åˆ†é˜       | 5 åˆ†é˜       | 0 åˆ†é˜                   |
| **ç¸½è¨ˆ**          | **~60 åˆ†é˜** | **~31 åˆ†é˜** | **~29 åˆ†é˜ï¼ˆç¯€çœ 48%ï¼‰** |

---

## ğŸ”§ æŠ€è¡“ç´°ç¯€

### **BGE-M3 æ¨¡å‹è¦æ ¼**

| å±¬æ€§           | å€¼                   |
| -------------- | -------------------- |
| æ¨¡å‹åç¨±       | `BAAI/bge-m3`        |
| æ¨¡å‹å¤§å°       | ~2.3 GB              |
| Embedding ç¶­åº¦ | 1024                 |
| æœ€å¤§åºåˆ—é•·åº¦   | 8192 tokens          |
| æ”¯æŒèªè¨€       | 100+ èªè¨€ï¼ˆå«ä¸­æ–‡ï¼‰  |
| å„ªåŒ–å ´æ™¯       | å¤šèªè¨€æª¢ç´¢ã€èªç¾©æœç´¢ |

**ä¾†æº**ï¼š[BAAI/bge-m3 on Hugging Face](https://huggingface.co/BAAI/bge-m3)

---

### **ç‚ºä½• BGE-M3 æ›´é©åˆæ³•å¾‹æ–‡æœ¬ï¼Ÿ**

1. **å¤šèªè¨€å„ªåŒ–**ï¼šå°ˆç‚ºä¸­æ–‡ç­‰å¤šèªè¨€è¨­è¨ˆï¼Œå°ä¸­æ–‡æ³•å¾‹è¡“èªç†è§£æ›´æº–ç¢º
2. **é•·æ–‡æœ¬æ”¯æŒ**ï¼š8192 tokens åºåˆ—é•·åº¦ï¼Œå¯è™•ç†é•·æ¢æ–‡
3. **èªç¾©æœç´¢å„ªåŒ–**ï¼šé‡å°æª¢ç´¢ä»»å‹™è¨“ç·´ï¼Œç›¸ä¼¼åº¦è¨ˆç®—æ›´ç²¾ç¢º
4. **æœ¬åœ°é‹è¡Œ**ï¼šç„¡ç¶²çµ¡å»¶é²ï¼Œé€Ÿåº¦æ›´å¿«

**Gemini Embedding-001 å°æ¯”**ï¼š

- **ç¶­åº¦**ï¼š768ï¼ˆBGE-M3 ç‚º 1024ï¼Œä¿¡æ¯é‡æ›´å¤§ï¼‰
- **åºåˆ—é•·åº¦**ï¼šæœªå…¬é–‹ï¼ˆBGE-M3 ç‚º 8192ï¼‰
- **é€Ÿç‡é™åˆ¶**ï¼š~1 req/ç§’ï¼ˆBGE-M3 ç„¡é™åˆ¶ï¼‰

---

## âš ï¸ æ³¨æ„äº‹é …

### **1ï¸âƒ£ æ¨¡å‹ç·©å­˜ä½ç½®**

BGE-M3 æ¨¡å‹æœƒä¸‹è¼‰åˆ°ï¼š

```
~/.cache/huggingface/hub/models--BAAI--bge-m3/
```

**ç£ç›¤ç©ºé–“éœ€æ±‚**ï¼š~2.3 GB

**æ¸…ç†ç·©å­˜**ï¼ˆå¦‚éœ€é‡æ–°ä¸‹è¼‰ï¼‰ï¼š

```bash
rm -rf ~/.cache/huggingface/hub/models--BAAI--bge-m3/
```

---

### **2ï¸âƒ£ å…§å­˜éœ€æ±‚**

é‹è¡Œ BGE-M3 éœ€è¦é¡å¤–å…§å­˜ï¼š

- **æœ€å°**ï¼š4 GB RAM
- **æ¨è–¦**ï¼š8 GB RAM
- **å¤§æ‰¹é‡è™•ç†**ï¼š16 GB RAM

**å¦‚æœå…§å­˜ä¸è¶³**ï¼š

- æ¸›å°‘æ‰¹é‡å¤§å°ï¼ˆåœ¨ `_encode_with_bge` ä¸­ä¿®æ”¹ï¼‰
- ä½¿ç”¨ CPU æ¨¡å¼ï¼ˆé»˜èªæœƒè‡ªå‹•åˆ‡æ›ï¼‰

---

### **3ï¸âƒ£ GPU åŠ é€Ÿï¼ˆå¯é¸ï¼‰**

å¦‚æœç³»çµ±æœ‰ NVIDIA GPUï¼ŒBGE-M3 æœƒè‡ªå‹•ä½¿ç”¨ GPU åŠ é€Ÿï¼š

**æª¢æ¸¬ GPU**ï¼š

```python
import torch
print(f"GPU å¯ç”¨: {torch.cuda.is_available()}")
print(f"GPU åç¨±: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}")
```

**é€Ÿåº¦å°æ¯”**ï¼š

- **CPU**ï¼š1842 å€‹ embedding ~1 åˆ†é˜
- **GPU**ï¼š1842 å€‹ embedding ~10-20 ç§’ï¼ˆå¿« 3-6 å€ï¼‰

---

## ğŸ› æ•…éšœæ’é™¤

### **å•é¡Œ 1ï¼šæ¨¡å‹ä¸‹è¼‰å¤±æ•—**

**éŒ¯èª¤ä¿¡æ¯**ï¼š

```
ConnectionError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded
```

**è§£æ±ºæ–¹æ¡ˆ**ï¼š

1. **æª¢æŸ¥ç¶²çµ¡é€£æ¥**
2. **ä½¿ç”¨é¡åƒç«™**ï¼ˆä¸­åœ‹å¤§é™¸ç”¨æˆ¶ï¼‰ï¼š
   ```bash
   export HF_ENDPOINT=https://hf-mirror.com
   ```
3. **æ‰‹å‹•ä¸‹è¼‰æ¨¡å‹**ï¼š
   - è¨ªå• https://huggingface.co/BAAI/bge-m3
   - ä¸‹è¼‰æ‰€æœ‰æ–‡ä»¶åˆ° `~/.cache/huggingface/hub/models--BAAI--bge-m3/snapshots/[hash]/`

---

### **å•é¡Œ 2ï¼šå…§å­˜ä¸è¶³**

**éŒ¯èª¤ä¿¡æ¯**ï¼š

```
RuntimeError: CUDA out of memory
```

**è§£æ±ºæ–¹æ¡ˆ**ï¼š

1. **å¼·åˆ¶ä½¿ç”¨ CPU**ï¼š

   ```python
   # åœ¨ _encode_with_bge æ–¹æ³•é–‹é ­æ·»åŠ 
   import os
   os.environ['CUDA_VISIBLE_DEVICES'] = ''  # ç¦ç”¨GPU
   ```

2. **æ¸›å°‘æ‰¹é‡å¤§å°**ï¼š
   ```python
   # ä¿®æ”¹ _encode_with_bge æ–¹æ³•
   model = SentenceTransformer('BAAI/bge-m3')
   embeddings = model.encode(texts, batch_size=8)  # é»˜èª32ï¼Œé™ä½åˆ°8
   ```

---

### **å•é¡Œ 3ï¼šBGE-M3 æœªè¢«æª¢æ¸¬åˆ°**

**ç—‡ç‹€**ï¼šå•Ÿå‹•æ™‚æœªçœ‹åˆ° `âœ… æª¢æ¸¬åˆ°Sentence Transformerså¯ç”¨`

**è§£æ±ºæ–¹æ¡ˆ**ï¼š

1. **æª¢æŸ¥å®‰è£**ï¼š

   ```bash
   cd backend
   source venv/bin/activate
   python -c "import sentence_transformers; print(sentence_transformers.__version__)"
   ```

2. **é‡æ–°å®‰è£**ï¼š

   ```bash
   pip uninstall sentence-transformers -y
   pip install sentence-transformers
   ```

3. **æª¢æŸ¥ Python ç‰ˆæœ¬**ï¼š
   ```bash
   python --version  # éœ€è¦ Python 3.8+
   ```

---

## âœ… é©—è­‰æ¸…å–®

é…ç½®å®Œæˆå¾Œï¼Œè«‹ç¢ºèªä»¥ä¸‹é …ç›®ï¼š

- [ ] âœ… `sentence-transformers` å·²å®‰è£ï¼ˆç‰ˆæœ¬ 5.1.1+ï¼‰
- [ ] âœ… `hoprag_clients.py` ä¸­ `encode` å’Œ `encode_async` æ–¹æ³•å·²ä¿®æ”¹
- [ ] âœ… å„ªå…ˆç´šå·²èª¿æ•´ï¼š`use_bge` åœ¨ `use_gemini` ä¹‹å‰
- [ ] âœ… å•Ÿå‹•æœå‹™å™¨æ™‚çœ‹åˆ° `âœ… æª¢æ¸¬åˆ°Sentence Transformerså¯ç”¨`
- [ ] âœ… ç£ç›¤ç©ºé–“å……è¶³ï¼ˆè‡³å°‘ 3 GB å¯ç”¨ç©ºé–“ï¼‰
- [ ] âœ… å…§å­˜å……è¶³ï¼ˆè‡³å°‘ 4 GB RAM å¯ç”¨ï¼‰
- [ ] âœ… ç¶²çµ¡é€£æ¥æ­£å¸¸ï¼ˆé¦–æ¬¡ä¸‹è¼‰æ¨¡å‹æ™‚ï¼‰

---

## ğŸ¯ ä¸‹ä¸€æ­¥

### **æ¸¬è©¦ BGE-M3 é…ç½®**

1. **å•Ÿå‹•æœå‹™å™¨**ï¼š

   ```bash
   cd backend
   source venv/bin/activate
   uvicorn app.main:app --reload
   ```

2. **æ§‹å»º HopRAG åœ–è­œ**ï¼š

   - å‰ç«¯ï¼šé¸æ“‡ "HopRAG å¢å¼·æª¢ç´¢"
   - é»æ“Š "Build HopRAG Graph"
   - è§€å¯Ÿæ—¥èªŒï¼šæ‡‰è©²çœ‹åˆ° embedding ç”Ÿæˆæ™‚é–“ < 1 åˆ†é˜

3. **æ€§èƒ½å°æ¯”**ï¼š
   - **é æœŸ**ï¼šç¸½æ§‹å»ºæ™‚é–“å¾ ~60 åˆ†é˜é™ä½åˆ° ~31 åˆ†é˜
   - **åŠ é€Ÿ**ï¼šç¯€çœ ~29 åˆ†é˜ï¼ˆ48% æå‡ï¼‰

---

## ğŸ“š ç›¸é—œè³‡æº

- [BGE-M3 æ¨¡å‹ä¸»é ](https://huggingface.co/BAAI/bge-m3)
- [Sentence Transformers æ–‡æª”](https://www.sbert.net/)
- [HopRAG API é€Ÿç‡é™åˆ¶ä¿®å¾©èªªæ˜](./HopRAG_APIé€Ÿç‡é™åˆ¶ä¿®å¾©èªªæ˜.md)
- [HopRAG è‡ªå‹•æŒä¹…åŒ–èªªæ˜](./HopRAGè‡ªåŠ¨æŒä¹…åŒ–è¯´æ˜.md)

---

## âœ… ç¸½çµ

| é …ç›®     | ç‹€æ…‹      | èªªæ˜                                       |
| -------- | --------- | ------------------------------------------ |
| ä¾è³´å®‰è£ | âœ… å®Œæˆ   | `sentence-transformers==5.1.1`             |
| ä»£ç¢¼ä¿®æ”¹ | âœ… å®Œæˆ   | `hoprag_clients.py` å„ªå…ˆç´šå·²èª¿æ•´           |
| æ¨¡å‹ä¸‹è¼‰ | â³ å¾…åŸ·è¡Œ | é¦–æ¬¡é‹è¡Œæ™‚è‡ªå‹•ä¸‹è¼‰ï¼ˆ~2.3 GBï¼‰              |
| æ€§èƒ½æå‡ | ğŸ¯ é æœŸ   | Embedding ç”Ÿæˆå¿« 30 å€ï¼ˆ30 åˆ†é˜ â†’ 1 åˆ†é˜ï¼‰ |
| æˆæœ¬ç¯€çœ | ğŸ’° é æœŸ   | é›¶ API èª¿ç”¨ï¼Œç„¡ Gemini é…é¡æ¶ˆè€—            |

**é…ç½®å®Œæˆï¼ğŸ‰ ç¾åœ¨å¯ä»¥å•Ÿå‹•æœå‹™å™¨ä¸¦æ¸¬è©¦ BGE-M3 æœ¬åœ°æ¨¡å‹äº†ï¼**
