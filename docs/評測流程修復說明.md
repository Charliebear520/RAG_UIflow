# 評測流程修復說明

## 問題描述

您提出了一個非常重要的問題：**為什麼沒有先生成問題就能直接進行評測？這是否合理？**

原來的設計確實存在邏輯問題：

1. 評測應該基於針對特定文檔生成的問題
2. 使用預設的通用問題進行評測結果不準確
3. 評測流程缺乏邏輯一致性

## 修復內容

### 1. 更新 DocRecord 模型

```python
@dataclass
class DocRecord:
    # ... 其他字段
    generated_questions: Optional[List[str]] = None  # 新增：存儲生成的問題
```

### 2. 修復問題生成路由

- 生成問題後，將問題文本存儲到文檔記錄中
- 確保問題與特定文檔關聯

### 3. 修復評測路由

- 檢查文檔是否已有生成的問題
- 如果沒有問題，返回錯誤提示用戶先生成問題
- 使用文檔特定的問題進行評測

## 新的評測流程

### 正確的流程順序

1. **上傳 PDF 文檔** → 轉換為文本和結構化數據
2. **選擇分塊策略** → 配置分塊參數
3. **生成問題** → 為特定文檔生成測試問題
4. **開始評測** → 基於生成的問題評估不同分塊配置

### 錯誤處理

如果用戶跳過「生成問題」步驟直接進行評測，系統會返回錯誤：

```json
{
  "detail": "請先使用「生成問題」功能為文檔生成測試問題，然後再進行評測"
}
```

## 為什麼這樣設計更合理？

### 1. 問題針對性

- 生成的問題基於文檔實際內容
- 問題類型和難度符合文檔特性
- 評測結果更準確反映分塊策略的實際效果

### 2. 邏輯一致性

- 評測必須基於已生成的問題
- 避免使用不相關的預設問題
- 確保評測流程的完整性

### 3. 結果可信度

- 問題與文檔內容高度相關
- 評測指標更有意義
- 分塊策略優化更有針對性

## 技術實現細節

### 問題存儲

```python
# 生成問題後存儲
question_texts = [q.question for q in questions]
doc.generated_questions = question_texts
store.add_doc(doc)
```

### 評測前檢查

```python
# 檢查是否已有生成的問題
if not hasattr(doc, 'generated_questions') or not doc.generated_questions:
    raise HTTPException(
        status_code=400,
        detail="請先使用「生成問題」功能為文檔生成測試問題，然後再進行評測"
    )
```

## 用戶體驗改進

### 前端提示

建議在前端添加流程指引：

1. 顯示當前步驟狀態
2. 禁用未完成前置步驟的功能
3. 提供清晰的錯誤提示

### 流程可視化

```
[上傳文檔] → [選擇分塊策略] → [生成問題] → [開始評測]
     ↓              ↓              ↓           ↓
   已完成        已完成        已完成      進行中
```

## 總結

修復後的評測流程更加合理和準確：

- ✅ 確保評測基於文檔特定的問題
- ✅ 提高評測結果的可信度
- ✅ 保持邏輯流程的完整性
- ✅ 提供清晰的錯誤提示

感謝您指出這個重要的設計問題！這讓整個評測系統變得更加嚴謹和可靠。
